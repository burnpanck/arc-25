{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaL4","dataSources":[{"sourceId":91496,"databundleVersionId":11802066,"sourceType":"competition"},{"sourceId":12934548,"sourceType":"datasetVersion","datasetId":8184985},{"sourceId":12934818,"sourceType":"datasetVersion","datasetId":8180294}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install --no-index --find-links=/kaggle/input/yde-arc25-wheelhouse yde-arc25","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:14:28.334420Z","iopub.execute_input":"2025-09-03T07:14:28.335111Z","iopub.status.idle":"2025-09-03T07:14:41.757328Z","shell.execute_reply.started":"2025-09-03T07:14:28.335087Z","shell.execute_reply":"2025-09-03T07:14:41.756598Z"}},"outputs":[{"name":"stdout","text":"Looking in links: /kaggle/input/yde-arc25-wheelhouse\nProcessing /kaggle/input/yde-arc25-wheelhouse/yde_arc25-25.8.1-py3-none-any.whl\nProcessing /kaggle/input/yde-arc25-wheelhouse/nicegui-2.23.3-py3-none-any.whl (from yde-arc25)\nRequirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from yde-arc25) (25.3.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from yde-arc25) (4.9.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from yde-arc25) (3.7.2)\nRequirement already satisfied: platformdirs>=4.3.8 in /usr/local/lib/python3.11/dist-packages (from yde-arc25) (4.3.8)\nRequirement already satisfied: pyyaml>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from yde-arc25) (6.0.2)\nProcessing /kaggle/input/yde-arc25-wheelhouse/watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from yde-arc25)\nProcessing /kaggle/input/yde-arc25-wheelhouse/scipy-1.16.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from yde-arc25)\nRequirement already satisfied: msgpack>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from yde-arc25) (1.1.1)\nProcessing /kaggle/input/yde-arc25-wheelhouse/cbor2-5.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (from yde-arc25)\nRequirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.11/dist-packages (from scipy>=1.16.1->yde-arc25) (1.26.4)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio->yde-arc25) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->yde-arc25) (1.3.1)\nRequirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->yde-arc25) (4.14.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->yde-arc25) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->yde-arc25) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->yde-arc25) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->yde-arc25) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->yde-arc25) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->yde-arc25) (11.2.1)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->yde-arc25) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->yde-arc25) (2.9.0.post0)\nRequirement already satisfied: Pygments<3.0.0,>=2.15.1 in /usr/local/lib/python3.11/dist-packages (from nicegui->yde-arc25) (2.19.2)\nProcessing /kaggle/input/yde-arc25-wheelhouse/aiofiles-24.1.0-py3-none-any.whl (from nicegui->yde-arc25)\nRequirement already satisfied: aiohttp>=3.10.2 in /usr/local/lib/python3.11/dist-packages (from nicegui->yde-arc25) (3.12.13)\nRequirement already satisfied: certifi>=2024.07.04 in /usr/local/lib/python3.11/dist-packages (from nicegui->yde-arc25) (2025.6.15)\nRequirement already satisfied: docutils>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from nicegui->yde-arc25) (0.21.2)\nRequirement already satisfied: fastapi>=0.109.1 in /usr/local/lib/python3.11/dist-packages (from nicegui->yde-arc25) (0.115.13)\nRequirement already satisfied: h11>=0.16.0 in /usr/local/lib/python3.11/dist-packages (from nicegui->yde-arc25) (0.16.0)\nRequirement already satisfied: httpx>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from nicegui->yde-arc25) (0.28.1)\nProcessing /kaggle/input/yde-arc25-wheelhouse/ifaddr-0.2.0-py3-none-any.whl (from nicegui->yde-arc25)\nRequirement already satisfied: itsdangerous<3.0.0,>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from nicegui->yde-arc25) (2.2.0)\nRequirement already satisfied: jinja2<4.0.0,>=3.1.6 in /usr/local/lib/python3.11/dist-packages (from nicegui->yde-arc25) (3.1.6)\nProcessing /kaggle/input/yde-arc25-wheelhouse/markdown2-2.5.4-py3-none-any.whl (from nicegui->yde-arc25)\nRequirement already satisfied: orjson>=3.9.15 in /usr/local/lib/python3.11/dist-packages (from nicegui->yde-arc25) (3.10.18)\nProcessing /kaggle/input/yde-arc25-wheelhouse/python_engineio-4.12.2-py3-none-any.whl (from nicegui->yde-arc25)\nRequirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from nicegui->yde-arc25) (0.0.20)\nProcessing /kaggle/input/yde-arc25-wheelhouse/python_socketio-5.13.0-py3-none-any.whl (from python-socketio[asyncio-client]>=5.10.0->nicegui->yde-arc25)\nRequirement already satisfied: starlette>=0.45.3 in /usr/local/lib/python3.11/dist-packages (from nicegui->yde-arc25) (0.46.2)\nRequirement already satisfied: uvicorn>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.22.0->nicegui->yde-arc25) (0.34.3)\nProcessing /kaggle/input/yde-arc25-wheelhouse/vbuild-0.8.2-py2.py3-none-any.whl (from nicegui->yde-arc25)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.2->nicegui->yde-arc25) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.2->nicegui->yde-arc25) (1.3.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.2->nicegui->yde-arc25) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.2->nicegui->yde-arc25) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.2->nicegui->yde-arc25) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.2->nicegui->yde-arc25) (1.20.1)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.109.1->nicegui->yde-arc25) (2.11.7)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.0->nicegui->yde-arc25) (1.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.6->nicegui->yde-arc25) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.6,>=1.25.2->scipy>=1.16.1->yde-arc25) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.6,>=1.25.2->scipy>=1.16.1->yde-arc25) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.6,>=1.25.2->scipy>=1.16.1->yde-arc25) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.6,>=1.25.2->scipy>=1.16.1->yde-arc25) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.6,>=1.25.2->scipy>=1.16.1->yde-arc25) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.6,>=1.25.2->scipy>=1.16.1->yde-arc25) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->yde-arc25) (1.17.0)\nProcessing /kaggle/input/yde-arc25-wheelhouse/simple_websocket-1.1.0-py3-none-any.whl (from python-engineio>=4.12.0->nicegui->yde-arc25)\nProcessing /kaggle/input/yde-arc25-wheelhouse/bidict-0.23.1-py3-none-any.whl (from python-socketio>=5.10.0->python-socketio[asyncio-client]>=5.10.0->nicegui->yde-arc25)\nRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.22.0->uvicorn[standard]>=0.22.0->nicegui->yde-arc25) (8.2.1)\nProcessing /kaggle/input/yde-arc25-wheelhouse/httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from uvicorn[standard]>=0.22.0->nicegui->yde-arc25)\nProcessing /kaggle/input/yde-arc25-wheelhouse/python_dotenv-1.1.1-py3-none-any.whl (from uvicorn[standard]>=0.22.0->nicegui->yde-arc25)\nProcessing /kaggle/input/yde-arc25-wheelhouse/uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from uvicorn[standard]>=0.22.0->nicegui->yde-arc25)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.22.0->nicegui->yde-arc25) (15.0.1)\nProcessing /kaggle/input/yde-arc25-wheelhouse/pscript-0.7.7-py3-none-any.whl (from vbuild>=0.8.2->nicegui->yde-arc25)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.109.1->nicegui->yde-arc25) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.109.1->nicegui->yde-arc25) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.109.1->nicegui->yde-arc25) (0.4.1)\nProcessing /kaggle/input/yde-arc25-wheelhouse/wsproto-1.2.0-py3-none-any.whl (from simple-websocket>=0.10.0->python-engineio>=4.12.0->nicegui->yde-arc25)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.6,>=1.25.2->scipy>=1.16.1->yde-arc25) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.6,>=1.25.2->scipy>=1.16.1->yde-arc25) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.6,>=1.25.2->scipy>=1.16.1->yde-arc25) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.6,>=1.25.2->scipy>=1.16.1->yde-arc25) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.6,>=1.25.2->scipy>=1.16.1->yde-arc25) (2024.2.0)\nInstalling collected packages: pscript, ifaddr, wsproto, vbuild, uvloop, python-dotenv, markdown2, httptools, cbor2, bidict, aiofiles, watchfiles, simple-websocket, python-engineio, python-socketio, nicegui, scipy, yde-arc25\n  Attempting uninstall: aiofiles\n    Found existing installation: aiofiles 22.1.0\n    Uninstalling aiofiles-22.1.0:\n      Successfully uninstalled aiofiles-22.1.0\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.15.3\n    Uninstalling scipy-1.15.3:\n      Successfully uninstalled scipy-1.15.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.16.1 which is incompatible.\nydata-profiling 4.16.1 requires scipy<1.16,>=1.4.1, but you have scipy 1.16.1 which is incompatible.\nypy-websocket 0.8.4 requires aiofiles<23,>=22.1.0, but you have aiofiles 24.1.0 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed aiofiles-24.1.0 bidict-0.23.1 cbor2-5.7.0 httptools-0.6.4 ifaddr-0.2.0 markdown2-2.5.4 nicegui-2.23.3 pscript-0.7.7 python-dotenv-1.1.1 python-engineio-4.12.2 python-socketio-5.13.0 scipy-1.16.1 simple-websocket-1.1.0 uvloop-0.21.0 vbuild-0.8.2 watchfiles-1.1.0 wsproto-1.2.0 yde-arc25-25.8.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"pip install bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:14:41.758561Z","iopub.execute_input":"2025-09-03T07:14:41.758791Z","iopub.status.idle":"2025-09-03T07:15:47.330409Z","shell.execute_reply.started":"2025-09-03T07:14:41.758769Z","shell.execute_reply":"2025-09-03T07:15:47.329728Z"}},"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nDownloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed bitsandbytes-0.47.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"if False:\n    from huggingface_hub import notebook_login\n\n    notebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:15:47.331156Z","iopub.execute_input":"2025-09-03T07:15:47.331364Z","iopub.status.idle":"2025-09-03T07:15:47.334705Z","shell.execute_reply.started":"2025-09-03T07:15:47.331342Z","shell.execute_reply":"2025-09-03T07:15:47.334212Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import typing\nimport re\nfrom pathlib import Path\nfrom types import SimpleNamespace, MappingProxyType\n\nimport attrs\nimport numpy as np\nimport pandas as pd\nfrom IPython import display\n\nimport arc25.dsl.types\nfrom arc25 import dsl\nimport arc25.tools\nimport arc25.dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:15:47.335954Z","iopub.execute_input":"2025-09-03T07:15:47.336134Z","iopub.status.idle":"2025-09-03T07:15:47.681030Z","shell.execute_reply.started":"2025-09-03T07:15:47.336119Z","shell.execute_reply":"2025-09-03T07:15:47.680443Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from pathlib import Path\nds = await arc25.dataset.Dataset.from_binary(Path(\"/kaggle/input/arc25-training-data/all-challenges.cbor.xz\"))\nsolutions = await arc25.dataset.SolutionDB.load(Path(\"/kaggle/input/arc25-training-data/solutions\"))\nsol_with_code = sorted(k for k,v in solutions.solutions.items() if v.rule)\nprint(len(solutions.solutions), len(sol_with_code))\nprint(sol_with_code)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:15:47.681676Z","iopub.execute_input":"2025-09-03T07:15:47.682035Z","iopub.status.idle":"2025-09-03T07:15:48.284189Z","shell.execute_reply.started":"2025-09-03T07:15:47.682015Z","shell.execute_reply":"2025-09-03T07:15:48.283480Z"}},"outputs":[{"name":"stdout","text":"26 17\n['00576224', '36fdfd69', '46442a0e', '54d82841', '5614dbcf', '642d658d', '6e19193c', '6f8cd79b', '9841fdad', '9f5f939b', 'a740d043', 'ca-00-01', 'ca-03-02', 'ca-03-04', 'ca-10-04', 'ce039d91', 'fd02da9e']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"system_msg = \"You are a careful, code-generating ARC challenge solver assistant.\"\ntask_descr = \"\"\"\n# Task description\nARC challenges require a rule to be found that transforms input grids into output grids.\nYou are given a number of pairs of input and output grids,\nplus a few more input grids only, for which the rule must generate the corresponding outputs.\nThe rule must be expressed as a python function `solver`.\nAnalyse the challenge carefully and in a structured way by:\n 1.) Formulate a `description` of the relevant semantic eneitites in the inputs.\n 2.) Describe the underlying `rule` in natural language or pseudo-code.\n 3.) Create a `plan` on how to implement the rule in python.\n 4.) Output an `implemenetation` in python, implementing that rule.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:15:48.285065Z","iopub.execute_input":"2025-09-03T07:15:48.285265Z","iopub.status.idle":"2025-09-03T07:15:48.288582Z","shell.execute_reply.started":"2025-09-03T07:15:48.285248Z","shell.execute_reply":"2025-09-03T07:15:48.288025Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class FactDefinition:\n    pass\n\n@attrs.frozen\nclass PredicateFact(FactDefinition):\n    descr: str\n    predicate: typing.Callable\n\n    def __call__(self, chal: arc25.dataset.Challenge) -> str | None:\n        p = self.predicate(chal)\n        if p:\n            return self.descr.format(pred=p)\n\ndef single_element_or_none(arg: list|tuple|set):\n    if len(arg) == 1:\n        ret, = arg\n        return ret\n    \ndefault_facts = (\n    PredicateFact(\n        \"Inputs of equal shape: {pred}\",\n        lambda chal:single_element_or_none(set(e.input.shape for e in chal.train+chal.test))\n    ),\n    PredicateFact(\n        \"Output shapes match input shapes\",\n        lambda chal:all(e.output.shape == e.input.shape for e in chal.train)\n    ),\n    PredicateFact(\n        \"Output size uniformly increased by factor {pred}\",\n        lambda chal:single_element_or_none(set(\n            d for d,m in (\n                divmod(e.output.shape[i],e.input.shape[i])\n                for i in range(2)\n                for e in chal.train\n            ) if not m and d>1\n        ))\n    ),\n    PredicateFact(\n        \"Output size uniformly decreased by factor {pred}\",\n        lambda chal:single_element_or_none(set(\n            d for d,m in (\n                divmod(e.input.shape[i],e.output.shape[i])\n                for i in range(2)\n                for e in chal.train\n            ) if not m and d>1\n        ))\n    ),\n    # TODO: facts about colours\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:15:48.289173Z","iopub.execute_input":"2025-09-03T07:15:48.289342Z","iopub.status.idle":"2025-09-03T07:15:49.823857Z","shell.execute_reply.started":"2025-09-03T07:15:48.289326Z","shell.execute_reply":"2025-09-03T07:15:49.823245Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"C = dsl.types.Color\nsingle_char_color_codes = {\n    C.BLACK: \"k\",\n    C.BLUE: \"b\",\n    C.BROWN: \"n\",\n    C.CYAN: \"c\",\n    C.GRAY: \"h\",\n    C.GREEN: \"g\",\n    C.MAGENTA: \"m\",\n    C.ORANGE: \"o\",\n    C.RED: \"r\",\n    C.YELLOW: \"y\",\n}\nparentheses = \"«»‹›〔〕【】〖〗❪❫❲❳❬❭❨❩⟨⟩\"\nlen(set(single_char_color_codes.keys())),len(set(single_char_color_codes.values()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:15:49.824531Z","iopub.execute_input":"2025-09-03T07:15:49.824728Z","iopub.status.idle":"2025-09-03T07:15:50.040566Z","shell.execute_reply.started":"2025-09-03T07:15:49.824712Z","shell.execute_reply":"2025-09-03T07:15:50.040046Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(10, 10)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"@attrs.frozen\nclass ReasonedSolution:\n    input_descr: str | None = None\n    rule_descr: str | None = None\n    impl_plan_descr: str | None = None\n    rule_impl: str | None = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:15:50.041181Z","iopub.execute_input":"2025-09-03T07:15:50.041366Z","iopub.status.idle":"2025-09-03T07:15:50.050504Z","shell.execute_reply.started":"2025-09-03T07:15:50.041350Z","shell.execute_reply":"2025-09-03T07:15:50.050009Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"@attrs.frozen\nclass PromptEncoder:\n    system_msg: str = system_msg\n    task_descr: str = task_descr\n    replace_all_colours: bool = True\n    \n    colour_tokens: tuple[str,...] = tuple(\n        f\"❲{single_char_color_codes[c]}❳\"\n        for c in dsl.types.Color\n    )\n    open_tokens: SimpleNamespace = SimpleNamespace(**{\n        k:f\"<{k}>\" for k in [\"input\",\"example\",\"grid\",\"facts\",\"descr\",\"rule\",\"plan\",\"impl\"]\n    })\n    close_tokens: SimpleNamespace = SimpleNamespace(**{\n        k:f\"</{k}>\" for k in vars(open_tokens)\n    })\n\n    fact_definitions: tuple[FactDefinition] = default_facts\n\n    \n    def encode_grid(self, grid: dsl.types.Canvas) -> str:\n        if isinstance(grid, dsl.types.Canvas):\n            grid = grid.image\n        h,w = grid.shape\n        egrids = [\n            \"\\n\".join(\"\".join(self.colour_tokens[v] for v in row) for row in d)\n            for d in [grid._data,grid._data.T]\n        ]\n        o = self.open_tokens\n        c = self.close_tokens\n        return f\"\"\"\n{o.grid}{h}×{w}\nrows:\n{egrids[0]}\n---\ncols:\n{egrids[1]}\n{c.grid}\n        \"\"\".strip()\n\n    def encode_example(self, example:  dsl.types.IOPair) -> str:\n        o = self.open_tokens\n        c = self.close_tokens\n        body = \"\\n\".join(\n            f\"{k}:{self.encode_grid(v)}\"\n            for k in [\"input\",\"output\"]\n            if (v:=getattr(example,k)) is not None\n        )\n        return f\"\"\"\n{o.example}\n{body}\n{c.example}\n        \"\"\".strip()\n\n    def encode_inputs(self, challenge: arc25.dataset.Challenge) -> str:\n        o = self.open_tokens\n        c = self.close_tokens\n        body = \"\\n\".join(\n            f\"{k}:\\n\"+\"\\n\".join(self.encode_example(e) for e in v)\n            for k in [\"train\",\"test\"]\n            if (v:=getattr(challenge,k))\n        )\n        return f\"\"\"\n{o.input}\n{body}\n{c.input}\n        \"\"\".strip()\n\n    def encode_facts(self, challenge: arc25.dataset.Challenge) -> str:\n        o = self.open_tokens\n        c = self.close_tokens\n        # TODO: handle colour replacement!\n        body = \"\\n\".join(\n            f\"- {descr}\"\n            for fd in self.fact_definitions\n            if (descr:=fd(challenge))\n        )\n        return f\"\"\"\n{o.facts}\n{body}\n{c.facts}\n        \"\"\".strip()\n\n    def encode_prompt(self, challenge: arc25.dataset.Challenge) -> dict[str,str]:\n        user_msg = f\"\"\"\n{self.task_descr}\n\n{self.encode_inputs(challenge)}\n\n{self.encode_facts(challenge)}\n\"\"\".strip()\n        return SimpleNamespace(\n            system = self.system_msg,\n            user = user_msg,\n        )\n\n    def encode_response(self, response: ReasonedSolution) -> str:\n        o = self.open_tokens\n        c = self.close_tokens\n        ret = []\n        for k,v in dict(\n            descr = response.input_descr,\n            rule = response.rule_descr,\n            plan = response.impl_plan_descr,\n            impl = response.rule_impl,\n        ).items():\n            if v is None or not v.strip():\n                continue\n            ret.append(f\"\"\"\n{vars(o)[k]}\n{v}\n{vars(c)[k]}\n            \"\"\".strip())\n        return \"\\n\\n\".join(ret)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:15:50.051070Z","iopub.execute_input":"2025-09-03T07:15:50.051235Z","iopub.status.idle":"2025-09-03T07:15:50.063675Z","shell.execute_reply.started":"2025-09-03T07:15:50.051220Z","shell.execute_reply":"2025-09-03T07:15:50.063187Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"ckey = sol_with_code[-5]\nprint(ckey)\nchal = ds.challenges[ckey]\nsol = solutions.solutions[ckey]\ndisplay.display(display.Markdown(sol.explanation))\n\narc25.tools.show_test_case(\n    chal.train+chal.test,\n    n_train = len(chal.train),\n    width = 8,\n    orientation = \"h\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:15:50.064239Z","iopub.execute_input":"2025-09-03T07:15:50.064419Z","iopub.status.idle":"2025-09-03T07:15:50.421846Z","shell.execute_reply.started":"2025-09-03T07:15:50.064396Z","shell.execute_reply":"2025-09-03T07:15:50.421317Z"}},"outputs":[{"name":"stdout","text":"ca-03-02\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**Hypothesis:**\n- Black background.\n- One horizontal and one vertical colored dotted line.\n- Impossible to say which of the two is painted over the other.\n\n**Rule:**\n- Start either from the input, or a fully black canvas of the same shape.\n- First, paint a solid vertical line at the position and in the color of the dotted vertical line in the input.\n- Second, paint a solid horizontal line at the position and in the color of the dotted horizontal line in the input.\n\n**Plan:**\n- There are no distractions, so we can determine the line positions simply from the count of foreground cells.\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x266.667 with 12 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"header_rex = re.compile(r\"\\*\\*(\\w+):\\*\\*\")\ndef parse_explanation(sol):\n    resp = {}\n    prev = None,0\n    for m in header_rex.finditer(sol.explanation):\n        t,s = prev\n        e = m.start()\n        resp.setdefault(t,[]).append(sol.explanation[s:e].strip())\n        prev = {\n            \"hypothesis\": \"input_descr\",\n            \"rule\": \"rule_descr\",\n            \"plan\": \"impl_plan_descr\",\n        }.get(m.group(1).lower()), m.end()\n    t,s = prev\n    e = len(sol.explanation)\n    resp.setdefault(t,[]).append(sol.explanation[s:e].strip())\n\n    default = resp.pop(None,None)\n    if default is not None and \"rule_descr\" not in resp:\n        resp[\"rule_descr\"] = default\n    \n    return ReasonedSolution(\n        **{k:\"\".join(v) for k,v in resp.items()},\n        rule_impl=sol.rule.strip(),\n    )\nresp = parse_explanation(sol)\nresp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:15:50.422492Z","iopub.execute_input":"2025-09-03T07:15:50.422882Z","iopub.status.idle":"2025-09-03T07:15:50.429893Z","shell.execute_reply.started":"2025-09-03T07:15:50.422864Z","shell.execute_reply":"2025-09-03T07:15:50.429406Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"ReasonedSolution(input_descr='- Black background.\\n- One horizontal and one vertical colored dotted line.\\n- Impossible to say which of the two is painted over the other.', rule_descr='- Start either from the input, or a fully black canvas of the same shape.\\n- First, paint a solid vertical line at the position and in the color of the dotted vertical line in the input.\\n- Second, paint a solid horizontal line at the position and in the color of the dotted horizontal line in the input.', impl_plan_descr='- There are no distractions, so we can determine the line positions simply from the count of foreground cells.', rule_impl='def solution(input: Canvas) -> Canvas:\\n    output = input\\n    h,w = input.shape\\n    # identify foreground cells\\n    fg_mask = ~mask_color(input, BLACK)\\n    # paint all columns with more than one foreground cell\\n    # (there will be just one)\\n    for col in range(w):\\n        col_mask = mask_col(input, col)\\n        mask = col_mask & fg_mask\\n        if mask.count()>1:\\n            c, = most_common_colors(apply_mask(input, mask))\\n            output = fill(output, c, clip=col_mask)\\n    # same for the row\\n    for row in range(h):\\n        row_mask = mask_row(input, row)\\n        mask = row_mask & fg_mask\\n        if mask.count()>1:\\n            c, = most_common_colors(apply_mask(input, mask))\\n            output = fill(output, c, clip=row_mask)\\n    return output')"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"enc = PromptEncoder()\n\nu = enc.encode_prompt(chal).user\nprint(u[:800]+\"\\n...\\n\"+u[-400:])\na = enc.encode_response(resp)\nprint(a)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:15:50.430439Z","iopub.execute_input":"2025-09-03T07:15:50.430608Z","iopub.status.idle":"2025-09-03T07:15:50.446660Z","shell.execute_reply.started":"2025-09-03T07:15:50.430590Z","shell.execute_reply":"2025-09-03T07:15:50.446084Z"}},"outputs":[{"name":"stdout","text":"# Task description\nARC challenges require a rule to be found that transforms input grids into output grids.\nYou are given a number of pairs of input and output grids,\nplus a few more input grids only, for which the rule must generate the corresponding outputs.\nThe rule must be expressed as a python function `solver`.\nAnalyse the challenge carefully and in a structured way by:\n 1.) Formulate a `description` of the relevant semantic eneitites in the inputs.\n 2.) Describe the underlying `rule` in natural language or pseudo-code.\n 3.) Create a `plan` on how to implement the rule in python.\n 4.) Output an `implemenetation` in python, implementing that rule.\n\n\n<input>\ntrain:\n<example>\ninput:<grid>6×6\nrows:\n❲k❳❲k❳❲k❳❲k❳❲k❳❲k❳\n❲k❳❲k❳❲k❳❲k❳❲k❳❲m❳\n❲y❳❲k❳❲y❳❲k❳❲y❳❲k❳\n❲k❳❲k❳❲k❳❲k❳❲k❳❲m❳\n❲k❳❲k❳❲k❳❲k❳❲k\n...\n---\ncols:\n❲k❳❲k❳❲m❳❲k❳❲k❳❲k❳❲k❳❲k❳❲k❳❲k❳\n❲k❳❲k❳❲m❳❲k❳❲k❳❲k❳❲k❳❲k❳❲k❳❲k❳\n❲k❳❲k❳❲m❳❲k❳❲k❳❲k❳❲k❳❲k❳❲k❳❲k❳\n❲k❳❲k❳❲m❳❲k❳❲k❳❲k❳❲k❳❲k❳❲k❳❲k❳\n❲k❳❲k❳❲m❳❲k❳❲k❳❲k❳❲k❳❲k❳❲k❳❲k❳\n❲k❳❲k❳❲m❳❲k❳❲k❳❲k❳❲k❳❲k❳❲k❳❲k❳\n❲k❳❲k❳❲m❳❲k❳❲k❳❲k❳❲k❳❲k❳❲k❳❲k❳\n❲k❳❲k❳❲m❳❲k❳❲k❳❲k❳❲k❳❲k❳❲k❳❲k❳\n❲m❳❲m❳❲m❳❲m❳❲m❳❲m❳❲m❳❲m❳❲m❳❲m❳\n❲k❳❲k❳❲m❳❲k❳❲k❳❲k❳❲k❳❲k❳❲k❳❲k❳\n</grid>\n</example>\n</input>\n\n<facts>\n- Output shapes match input shapes\n</facts>\n<descr>\n- Black background.\n- One horizontal and one vertical colored dotted line.\n- Impossible to say which of the two is painted over the other.\n</descr>\n\n<rule>\n- Start either from the input, or a fully black canvas of the same shape.\n- First, paint a solid vertical line at the position and in the color of the dotted vertical line in the input.\n- Second, paint a solid horizontal line at the position and in the color of the dotted horizontal line in the input.\n</rule>\n\n<plan>\n- There are no distractions, so we can determine the line positions simply from the count of foreground cells.\n</plan>\n\n<impl>\ndef solution(input: Canvas) -> Canvas:\n    output = input\n    h,w = input.shape\n    # identify foreground cells\n    fg_mask = ~mask_color(input, BLACK)\n    # paint all columns with more than one foreground cell\n    # (there will be just one)\n    for col in range(w):\n        col_mask = mask_col(input, col)\n        mask = col_mask & fg_mask\n        if mask.count()>1:\n            c, = most_common_colors(apply_mask(input, mask))\n            output = fill(output, c, clip=col_mask)\n    # same for the row\n    for row in range(h):\n        row_mask = mask_row(input, row)\n        mask = row_mask & fg_mask\n        if mask.count()>1:\n            c, = most_common_colors(apply_mask(input, mask))\n            output = fill(output, c, clip=row_mask)\n    return output\n</impl>\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"MODEL_NAME = \"Qwen/Qwen2.5-Coder-7B-Instruct\"\nMAX_LEN = 4096\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:15:50.447309Z","iopub.execute_input":"2025-09-03T07:15:50.447484Z","iopub.status.idle":"2025-09-03T07:15:50.458112Z","shell.execute_reply.started":"2025-09-03T07:15:50.447469Z","shell.execute_reply":"2025-09-03T07:15:50.457579Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from transformers import  AutoTokenizer\n\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\ntok = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\nadditional_special_tokens = tuple(\n    list(enc.colour_tokens)\n    +list(vars(enc.open_tokens).values())\n    +list(vars(enc.close_tokens).values())\n)\ntok.add_special_tokens(dict(additional_special_tokens=additional_special_tokens))\n\ndef build_chat_text(chal: arc25.dataset.Challenge, resp: ReasonedSolution | None = None):\n    messages = vars(enc.encode_prompt(chal))\n    if sol is not None:\n        messages.update(assistant=enc.encode_response(resp))\n    messages = [\n        dict(role=k,content=v)\n        for k,v in messages.items()\n    ]\n    return tok.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=sol is None,  # False for SFT labels, True for inference\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:15:50.458665Z","iopub.execute_input":"2025-09-03T07:15:50.458830Z","iopub.status.idle":"2025-09-03T07:15:58.186244Z","shell.execute_reply.started":"2025-09-03T07:15:50.458816Z","shell.execute_reply":"2025-09-03T07:15:58.185616Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bb96d0922a74ac19f667093cfddeede"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48327fd4b8404c91893a4749cf2ba2f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d17ff4f5a02b4bde8035189c47e4ccab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48419db23c26429ebbc818cb645e9786"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"text = build_chat_text(chal, resp)\nprint(text[:600] + \"\\n...\\n\" + text[-600:])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:15:58.186940Z","iopub.execute_input":"2025-09-03T07:15:58.187303Z","iopub.status.idle":"2025-09-03T07:15:58.204083Z","shell.execute_reply.started":"2025-09-03T07:15:58.187284Z","shell.execute_reply":"2025-09-03T07:15:58.203554Z"}},"outputs":[{"name":"stdout","text":"<|im_start|>system\nYou are a careful, code-generating ARC challenge solver assistant.<|im_end|>\n<|im_start|>user\n# Task description\nARC challenges require a rule to be found that transforms input grids into output grids.\nYou are given a number of pairs of input and output grids,\nplus a few more input grids only, for which the rule must generate the corresponding outputs.\nThe rule must be expressed as a python function `solver`.\nAnalyse the challenge carefully and in a structured way by:\n 1.) Formulate a `description` of the relevant semantic eneitites in the inputs.\n 2.) Describe the underlyin\n...\nh more than one foreground cell\n    # (there will be just one)\n    for col in range(w):\n        col_mask = mask_col(input, col)\n        mask = col_mask & fg_mask\n        if mask.count()>1:\n            c, = most_common_colors(apply_mask(input, mask))\n            output = fill(output, c, clip=col_mask)\n    # same for the row\n    for row in range(h):\n        row_mask = mask_row(input, row)\n        mask = row_mask & fg_mask\n        if mask.count()>1:\n            c, = most_common_colors(apply_mask(input, mask))\n            output = fill(output, c, clip=row_mask)\n    return output\n</impl><|im_end|>\n\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"token_to_tag = {}\nfor k,v in vars(enc.open_tokens).items():\n    t = tok.convert_tokens_to_ids(v)\n    token_to_tag[t] = \"+\"+k\nfor k,v in vars(enc.close_tokens).items():\n    t = tok.convert_tokens_to_ids(v)\n    token_to_tag[t] = \"-\"+k\n    \nIM_START  = tok.convert_tokens_to_ids(\"<|im_start|>\")\nIM_END    = tok.convert_tokens_to_ids(\"<|im_end|>\")\n\ndef tokenize_with_sections(text):\n    enc = tok(text, truncation=True, max_length=MAX_LEN, return_tensors=\"np\")\n    enc = {k:v[0,:] for k,v in enc.items()}\n    input_ids = enc.pop(\"input_ids\")\n\n    # 1) Find the assistant turn boundaries: <|im_start|>assistant ... <|im_end|>\n    #    We’ll only supervise inside; everything else -> labels = -100\n    # Scan all <|im_start|> occurrences and pick the one where next token piece is \"assistant\"\n    # Qwen template goes: <|im_start|>, \"assistant\", '\\n', content..., <|im_end|>\n    role_tokens = tok.encode(\"assistant\\n\", add_special_tokens=False)\n    starts = np.flatnonzero(input_ids == IM_START)\n    ends = np.flatnonzero(input_ids == IM_END)\n    assistant_sections = []\n    for i in starts:\n        s = input_ids[i+1:][:len(role_tokens)]\n        if np.all(s == role_tokens):\n            j = np.searchsorted(ends,i)\n            if j>=len(ends):\n                j = len(input_ids)\n            else:\n                j = ends[j]\n            assistant_sections.append((i,j))\n\n    # 2) Inside assistant: assign tag weights + section content weights.\n    # Walk tokens and push/pop when we encounter section tags.\n    # Since tags are single tokens, we can index them directly.\n\n    edges = [0]\n    sections = [None]  \n    for s,e in assistant_sections:\n        open_stack = []  # holds section names currently open\n        edges.append(s)\n        sections.append(Ellipsis)\n\n        ids = input_ids[s:e]\n        pos = np.flatnonzero(np.any(ids[:,None] == np.array(list(token_to_tag.keys())),-1))\n        for p in pos:\n            edges.append(s+p)\n            t = token_to_tag[ids[p]]\n            if t.startswith(\"+\"):\n                t = t[1:]\n                sections.append(t)\n                open_stack.append(t)\n            else:\n                assert t.startswith(\"-\")\n                t = t[1:]\n                assert open_stack[-1] == t\n                open_stack.pop()\n                sections.append(Ellipsis)\n\n        edges.append(e)\n        sections.append(None)\n\n    edges.append(len(input_ids))\n    return dict(tokens=input_ids, edges=np.array(edges), sections=tuple(sections), **enc)\n\ntokenised = res = SimpleNamespace(**tokenize_with_sections(text))\nprint(f\"{len(res.tokens)=} {vars(res).keys()}\")\nprint(f\"{len(res.edges)=}: {res.edges}\")\nprint(f\"{len(res.sections)=}: {res.sections}\")\ntsum = {}\nfor s,e,t in zip(res.edges[:-1],res.edges[1:],res.sections):\n    if isinstance(t,str):\n        tsum[t] = tsum.get(v,0) + e-s\nfor k,v in tsum.items():\n    print(f\"Section {k} has {v} tokens\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:15:58.204757Z","iopub.execute_input":"2025-09-03T07:15:58.204968Z","iopub.status.idle":"2025-09-03T07:15:58.232780Z","shell.execute_reply.started":"2025-09-03T07:15:58.204952Z","shell.execute_reply":"2025-09-03T07:15:58.232268Z"}},"outputs":[{"name":"stdout","text":"len(res.tokens)=2163 dict_keys(['tokens', 'edges', 'sections', 'attention_mask'])\nlen(res.edges)=12: [   0 1840 1843 1873 1875 1942 1944 1967 1969 2160 2161 2163]\nlen(res.sections)=11: (None, Ellipsis, 'descr', Ellipsis, 'rule', Ellipsis, 'plan', Ellipsis, 'impl', Ellipsis, None)\nSection descr has 30 tokens\nSection rule has 67 tokens\nSection plan has 23 tokens\nSection impl has 191 tokens\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"def create_labels_and_weights(inp, weight_map=MappingProxyType(dict(\n    descr=0.5, rule=0.6, plan=0.8, impl=1.0\n)), special_weight=0.2, pad_to:int|None=None):\n    toks = inp[\"tokens\"]\n    edg = inp[\"edges\"]\n    sec = inp[\"sections\"]\n    labels = []\n    weights = []\n    for s,e,t in zip(edg[:-1],edg[1:],sec):\n        n = e-s\n        if t is None and not s:\n            # this is the first user section; not supervising the token\n            labels.append(np.tile(-100,n))\n            weights.append(np.zeros(n))\n            continue\n        weights.append([special_weight])\n        w = weight_map.get(t)\n        if w is None:\n            labels.append(toks[s:s+1])\n            labels.append(np.tile(-100,n-1))\n            weights.append(np.zeros(n-1))\n        else:\n            labels.append(toks[s:e])\n            weights.append(np.tile(w,n-1))\n    labels = np.concatenate(labels)\n    weights = np.concatenate(weights)\n    assert labels.shape == weights.shape == toks.shape\n    ret = dict(input_ids=toks, labels=labels, weights=weights, attention_mask=inp[\"attention_mask\"])\n    if pad_to is not None and (n:=pad_to - toks.size) > 0:\n        pad_token = tok.convert_tokens_to_ids(\n            tok.eos_token if tok.pad_token is None else tok.pad_token\n        )\n        padding = dict(\n            input_ids = pad_token,\n            labels = -100,\n            weights = 0.,\n            attention_mask = 0,\n        )\n        ret = {\n            k:np.concatenate([v,np.tile(np.array(padding[k],v.dtype),n)])\n            for k,v in ret.items()\n        }\n\n    return ret\n    \n_ = create_labels_and_weights(vars(tokenised))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:15:58.233384Z","iopub.execute_input":"2025-09-03T07:15:58.233576Z","iopub.status.idle":"2025-09-03T07:15:58.241173Z","shell.execute_reply.started":"2025-09-03T07:15:58.233561Z","shell.execute_reply":"2025-09-03T07:15:58.240668Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"rgen = np.random.default_rng(42)\nsplits = dict(train=[],val=[])\nfor ckey,sol in sorted(solutions.solutions.items(),key=lambda kv:kv[0]):\n    if not (sol.rule and sol.explanation):\n        continue\n    chal = ds.challenges[ckey]\n    resp = parse_explanation(sol)\n    text = build_chat_text(chal, resp)\n    res = tokenize_with_sections(text)\n    lw = create_labels_and_weights(res)\n    split = \"val\" if rgen.random()<0.45 else \"train\"\n    print(f\"{ckey} has {len(lw['weights'])} tokens and goes into {split}\")\n    splits[split].append(lw)\nsplits = {k:pd.DataFrame(v) for k,v in splits.items()}\nsplits[\"train\"].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:15:58.241719Z","iopub.execute_input":"2025-09-03T07:15:58.241910Z","iopub.status.idle":"2025-09-03T07:15:58.357706Z","shell.execute_reply.started":"2025-09-03T07:15:58.241895Z","shell.execute_reply":"2025-09-03T07:15:58.357212Z"}},"outputs":[{"name":"stdout","text":"00576224 has 733 tokens and goes into train\n5614dbcf has 1116 tokens and goes into val\n642d658d has 4096 tokens and goes into train\n9f5f939b has 4096 tokens and goes into train\na740d043 has 872 tokens and goes into val\nca-00-01 has 4057 tokens and goes into train\nca-03-02 has 2163 tokens and goes into train\nca-03-04 has 2562 tokens and goes into train\nca-10-04 has 4096 tokens and goes into val\nce039d91 has 2685 tokens and goes into train\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                                           input_ids  \\\n0  [151644, 8948, 198, 2610, 525, 264, 16585, 11,...   \n1  [151644, 8948, 198, 2610, 525, 264, 16585, 11,...   \n2  [151644, 8948, 198, 2610, 525, 264, 16585, 11,...   \n3  [151644, 8948, 198, 2610, 525, 264, 16585, 11,...   \n4  [151644, 8948, 198, 2610, 525, 264, 16585, 11,...   \n\n                                              labels  \\\n0  [-100, -100, -100, -100, -100, -100, -100, -10...   \n1  [-100, -100, -100, -100, -100, -100, -100, -10...   \n2  [-100, -100, -100, -100, -100, -100, -100, -10...   \n3  [-100, -100, -100, -100, -100, -100, -100, -10...   \n4  [-100, -100, -100, -100, -100, -100, -100, -10...   \n\n                                             weights  \\\n0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n\n                                      attention_mask  \n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_ids</th>\n      <th>labels</th>\n      <th>weights</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[151644, 8948, 198, 2610, 525, 264, 16585, 11,...</td>\n      <td>[-100, -100, -100, -100, -100, -100, -100, -10...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[151644, 8948, 198, 2610, 525, 264, 16585, 11,...</td>\n      <td>[-100, -100, -100, -100, -100, -100, -100, -10...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[151644, 8948, 198, 2610, 525, 264, 16585, 11,...</td>\n      <td>[-100, -100, -100, -100, -100, -100, -100, -10...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[151644, 8948, 198, 2610, 525, 264, 16585, 11,...</td>\n      <td>[-100, -100, -100, -100, -100, -100, -100, -10...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[151644, 8948, 198, 2610, 525, 264, 16585, 11,...</td>\n      <td>[-100, -100, -100, -100, -100, -100, -100, -10...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"import datasets as hf_datasets\n\nfor k,v in splits.items():\n    ds_tok = hf_datasets.Dataset.from_pandas(v)\n    ds_tok.save_to_disk(f\"ds_tok/{k}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:15:58.358348Z","iopub.execute_input":"2025-09-03T07:15:58.358532Z","iopub.status.idle":"2025-09-03T07:15:59.302398Z","shell.execute_reply.started":"2025-09-03T07:15:58.358517Z","shell.execute_reply":"2025-09-03T07:15:59.301868Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/7 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b20463c26aa043b6adc8981a9b679df8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0555fca8f1e04642aebe31e3294e1f56"}},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"from torch import nn\nfrom transformers import TrainingArguments, Trainer\n\nclass WeightedTrainer(Trainer):\n    def compute_loss(self, model, inputs, *, return_outputs=False, num_items_in_batch=None):\n        # forward first\n        outputs = model(**{k: v for k, v in inputs.items() if k not in (\"labels\",\"weights\")})\n        logits = outputs.logits                      # on the model’s last shard device\n        dev = logits.device\n\n        # fetch targets/weights and move to *logits* device (not labels.device!)\n        labels  = inputs[\"labels\"]\n        weights = inputs[\"weights\"]\n        if not torch.is_tensor(weights):\n            weights = torch.tensor(weights, dtype=torch.float32)\n        labels  = labels.to(dev)\n        weights = weights.to(dev, dtype=torch.float32)\n\n        # causal shift\n        shift_logits = logits[:, :-1, :].contiguous()\n        shift_labels = labels[:, 1:].contiguous()\n        shift_wts    = weights[:, 1:].contiguous()\n\n        loss_fct = torch.nn.CrossEntropyLoss(reduction=\"none\")\n        loss_tok = loss_fct(shift_logits.view(-1, shift_logits.size(-1)),\n                            shift_labels.view(-1)).view_as(shift_labels)\n\n        active   = (shift_labels != -100).float()\n        weighted = loss_tok * shift_wts * active\n        denom    = (shift_wts * active).sum().clamp_min(1e-6)\n        loss     = weighted.sum() / denom\n\n        return (loss, outputs) if return_outputs else loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:15:59.303028Z","iopub.execute_input":"2025-09-03T07:15:59.303365Z","iopub.status.idle":"2025-09-03T07:16:19.304178Z","shell.execute_reply.started":"2025-09-03T07:15:59.303347Z","shell.execute_reply":"2025-09-03T07:16:19.303559Z"}},"outputs":[{"name":"stderr","text":"2025-09-03 07:16:05.954936: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756883766.176389     100 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756883766.238856     100 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch.nn.utils.rnn import pad_sequence\n\nclass FastSectionCollator:\n    def __init__(self, tokenizer, pad_to_multiple_of=8):\n        self.tok = tokenizer\n        self.pad_to_multiple_of = pad_to_multiple_of\n        self._pad_token_id = tok.convert_tokens_to_ids(self.tok.eos_token if self.tok.pad_token is None else self.tok.pad_token)\n\n    def __call__(self, features):\n        # features[i][k] are already torch tensors thanks to set_format(...)\n        ids     = [f[\"input_ids\"]     for f in features]\n        attn    = [f[\"attention_mask\"]for f in features]\n        labels  = [f[\"labels\"]        for f in features]\n        weights = [f[\"weights\"]       for f in features]\n\n        input_ids      = pad_sequence(ids,     batch_first=True, padding_value=self._pad_token_id)\n        attention_mask = pad_sequence(attn,    batch_first=True, padding_value=0)\n        labels         = pad_sequence(labels,  batch_first=True, padding_value=-100)\n        weights        = pad_sequence(weights, batch_first=True, padding_value=0.0)\n\n        if self.pad_to_multiple_of:\n            L, m = input_ids.size(1), self.pad_to_multiple_of\n            if L % m:\n                pad = (0, m - (L % m))\n                input_ids      = F.pad(input_ids,      pad, value=self._pad_token_id)\n                attention_mask = F.pad(attention_mask, pad, value=0)\n                labels         = F.pad(labels,         pad, value=-100)\n                weights        = F.pad(weights,        pad, value=0.0)\n\n        return {\n            \"input_ids\": input_ids,            # keep on CPU; Trainer/Accelerate moves them\n            \"attention_mask\": attention_mask,\n            \"labels\": labels,\n            \"weights\": weights,\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:16:19.304891Z","iopub.execute_input":"2025-09-03T07:16:19.305413Z","iopub.status.idle":"2025-09-03T07:16:19.312422Z","shell.execute_reply.started":"2025-09-03T07:16:19.305386Z","shell.execute_reply":"2025-09-03T07:16:19.311800Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, Trainer, BitsAndBytesConfig\nfrom peft import LoraConfig, get_peft_model\n\n\nbnb_cfg = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=torch.bfloat16,  # or torch.float16 if no bf16\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    quantization_config=bnb_cfg,\n    device_map=\"auto\",\n)\n\n# make the embedding fit the extra tokens\nmodel.resize_token_embeddings(\n    len(tok),\n    pad_to_multiple_of=8,\n    mean_resizing=True,\n)\n\nlora = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"],\n    trainable_token_indices={'embed_tokens': tok.convert_tokens_to_ids(additional_special_tokens)},\n)\nmodel = get_peft_model(model, lora)\n\n# memory savers\nmodel.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\": False})\nmodel.config.use_cache = False\nmodel.enable_input_require_grads()\nmodel.config.attn_implementation = \"sdpa\"  # or \"flash_attention_2\" if installed\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:24:06.542132Z","iopub.execute_input":"2025-09-03T07:24:06.542933Z","iopub.status.idle":"2025-09-03T07:24:14.669056Z","shell.execute_reply.started":"2025-09-03T07:24:06.542908Z","shell.execute_reply":"2025-09-03T07:24:14.668405Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be2a0e66921d471294e84a6943b8bb1d"}},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds = hf_datasets.load_from_disk(\"ds_tok/train\")\nval_ds = hf_datasets.load_from_disk(\"ds_tok/val\")\n\ncols = [\"input_ids\", \"attention_mask\", \"labels\", \"weights\"]\ntrain_ds.set_format(type=\"torch\", columns=cols, output_all_columns=False)\nval_ds.set_format(type=\"torch\", columns=cols, output_all_columns=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:24:14.670181Z","iopub.execute_input":"2025-09-03T07:24:14.670493Z","iopub.status.idle":"2025-09-03T07:24:14.686374Z","shell.execute_reply.started":"2025-09-03T07:24:14.670472Z","shell.execute_reply":"2025-09-03T07:24:14.685815Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"from transformers import TrainingArguments, DataCollatorForLanguageModeling\n\ncollator = FastSectionCollator(tok, pad_to_multiple_of=8)\n# collator = DataCollatorForLanguageModeling(tok, mlm=False, pad_to_multiple_of=8)\n\nargs = TrainingArguments(\n    output_dir=\"ckpt\",\n    bf16=True,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=16,\n    learning_rate=2e-4,\n    num_train_epochs=10,\n    logging_steps=5,\n    eval_strategy=\"steps\",\n    eval_steps=5,\n    save_steps=500,\n    save_total_limit=2,\n    dataloader_num_workers=1,\n    dataloader_persistent_workers=True,\n    dataloader_pin_memory=True,\n    report_to=\"none\",\n    remove_unused_columns=False,  # keep custom 'weights'\n    label_names=\"labels\",\n)\n\ntrainer = WeightedTrainer(\n    model=model,\n    args=args,\n    train_dataset=train_ds,\n    eval_dataset=val_ds,\n    data_collator=collator,\n    processing_class=tok,\n)\n\nprint(f\"World size: {trainer.args.world_size}, local_rank: {trainer.args.local_rank}\")\nprint(\"Using DDP:\", trainer.args.world_size > 1)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T07:24:14.687023Z","iopub.execute_input":"2025-09-03T07:24:14.687262Z"}},"outputs":[{"name":"stdout","text":"World size: 1, local_rank: 0\nUsing DDP: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10/10 06:00, Epoch 9/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>5</td>\n      <td>9.255600</td>\n      <td>No log</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"from IPython.display import Javascript\nprint(\"Shutdown\")\nJavascript(\"Ipython.notebook.session.delete()\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
