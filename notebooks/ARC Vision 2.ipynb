{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e92cc294-fc57-4ca6-a250-317eeeba70b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import lzma\n",
    "import os\n",
    "from importlib import reload\n",
    "from pathlib import Path\n",
    "from types import MappingProxyType, SimpleNamespace\n",
    "\n",
    "import cbor2\n",
    "import attrs\n",
    "import tqdm.auto\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import nnx\n",
    "import optax\n",
    "import jaxtyping as jt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from arc25 import symmetry\n",
    "from arc25.symmetry import D4, transform_vector\n",
    "from arc25 import serialisation\n",
    "from arc25.dsl.types import Vector, Dir4\n",
    "from arc25.vision2.symrep import SymDecompBase, SplitSymDecomp, SymDecompDims, standard_rep, RepSpec\n",
    "from arc25.vision2.linear import SpaceSymmetricLinear, SpaceSymmetricTensor, SymmetryMappingSpec, SymDecompLinear\n",
    "from arc25.vision2 import attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62411ecc-c33b-4af9-b2b6-71b6674fd2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"XLA_FLAGS\"]=\"--xla_force_host_platform_device_count=2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b090806-d291-4fa3-adfd-da0e9594a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# helper functions\n",
    "#----------------------\n",
    "def pytree_structure(pytree, title='pytree structure'):\n",
    "  print(f\"{title}:\")\n",
    "  for path, value in jax.tree.leaves_with_path(pytree):\n",
    "    print(f\"- pytree{jax.tree_util.keystr(path)} = {value.shape!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "917e421c-16fc-4fa0-964a-c112de2d1cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quant(key, shape, dtype):\n",
    "    seed = np.array(jax.random.key_data(key)).astype(\"u4\")\n",
    "    seed = (seed[0] ^ seed[1])&0x7fff_ffff\n",
    "    rng = np.random.RandomState(seed)\n",
    "    return rng.randint(-3, 4, size=shape).astype(dtype) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "34d49584-d458-47a7-a1c8-fe0161d7fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(attention)\n",
    "\n",
    "# prepare an example attention module with prime dimensions\n",
    "inpf = SymDecompDims(17, 11, 5)\n",
    "outf = SymDecompDims(19, 13, 7)\n",
    "\n",
    "atn = attention.AxialAttention(\n",
    "    num_heads=6,\n",
    "    num_groups=2,\n",
    "    in_features=inpf,\n",
    "    out_features=outf,\n",
    "    qk_head_width=SymDecompDims(\n",
    "        13 * 2, 23 * 2, 3 * 2, rep=RepSpec(symmetry.TrivialRep, 10)\n",
    "    ),\n",
    "    v_head_width=SymDecompDims(5, 4, 2),\n",
    "    use_chirality_rep=False,\n",
    "    kernel_init=quant,\n",
    "    bias_init=quant,\n",
    "    per_head_rope_freq=False,\n",
    "    dtype=np.float32,\n",
    "    activation=jax.nn.relu,\n",
    "    use_bias=False,\n",
    "    rngs=nnx.Rngs(42),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d8b6f154-40e4-43a4-8e63-e6f6c14c6d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invariant (13, 2) <class 'flax.nnx.variablelib.Param'>\n",
      "space (23, 2) <class 'flax.nnx.variablelib.Param'>\n",
      "flavour (3, 2) <class 'flax.nnx.variablelib.Param'>\n"
     ]
    }
   ],
   "source": [
    "for k,v in atn.rope_freq_params.items():\n",
    "    print(k,v.shape,type(v))\n",
    "    v.value *= 0\n",
    "#    v.value += np.pi/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c96949e8-7a15-43ee-ac96-afde500c9899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q.invariant: (2,y=13,x=7,D=2,d=2,v=1,f=1,m=3,k=2,d=13,p=2) ->  (2,y=13,x=7,d=2,v=1,f=1,m=3,k=2,d=13,p=2)\n",
      "rot: (y=13,x=1,d=2,m=1,k=1,h=13,p=2,q=2)\n",
      "q.space: (2,y=13,x=7,D=2,d=2,v=1,f=1,m=3,k=2,d=23,p=2) ->  (2,y=13,x=7,d=2,v=1,f=1,m=3,k=2,d=23,p=2)\n",
      "rot: (y=13,x=1,d=2,m=1,k=1,h=23,p=2,q=2)\n",
      "q.flavour: (2,y=13,x=7,D=2,d=2,v=1,f=10,m=3,k=2,d=3,p=2) ->  (2,y=13,x=7,d=2,v=1,f=10,m=3,k=2,d=3,p=2)\n",
      "rot: (y=13,x=1,d=2,m=1,k=1,h=3,p=2,q=2)\n",
      "k.invariant: (2,y=13,x=7,D=2,d=2,v=1,f=1,m=1,k=2,d=13,p=2) ->  (2,y=13,x=7,d=2,v=1,f=1,m=1,k=2,d=13,p=2)\n",
      "rot: (y=13,x=1,d=2,m=1,k=1,h=13,p=2,q=2)\n",
      "k.space: (2,y=13,x=7,D=2,d=2,v=1,f=1,m=1,k=2,d=23,p=2) ->  (2,y=13,x=7,d=2,v=1,f=1,m=1,k=2,d=23,p=2)\n",
      "rot: (y=13,x=1,d=2,m=1,k=1,h=23,p=2,q=2)\n",
      "k.flavour: (2,y=13,x=7,D=2,d=2,v=1,f=10,m=1,k=2,d=3,p=2) ->  (2,y=13,x=7,d=2,v=1,f=10,m=1,k=2,d=3,p=2)\n",
      "rot: (y=13,x=1,d=2,m=1,k=1,h=3,p=2,q=2)\n",
      "q.invariant: (2,y=13,x=7,D=2,d=2,v=1,f=1,m=3,k=2,d=13,p=2) ->  (2,y=13,x=7,d=2,v=1,f=1,m=3,k=2,d=13,p=2)\n",
      "rot: (y=1,x=7,d=2,m=1,k=1,h=13,p=2,q=2)\n",
      "q.space: (2,y=13,x=7,D=2,d=2,v=1,f=1,m=3,k=2,d=23,p=2) ->  (2,y=13,x=7,d=2,v=1,f=1,m=3,k=2,d=23,p=2)\n",
      "rot: (y=1,x=7,d=2,m=1,k=1,h=23,p=2,q=2)\n",
      "q.flavour: (2,y=13,x=7,D=2,d=2,v=1,f=10,m=3,k=2,d=3,p=2) ->  (2,y=13,x=7,d=2,v=1,f=10,m=3,k=2,d=3,p=2)\n",
      "rot: (y=1,x=7,d=2,m=1,k=1,h=3,p=2,q=2)\n",
      "k.invariant: (2,y=13,x=7,D=2,d=2,v=1,f=1,m=1,k=2,d=13,p=2) ->  (2,y=13,x=7,d=2,v=1,f=1,m=1,k=2,d=13,p=2)\n",
      "rot: (y=1,x=7,d=2,m=1,k=1,h=13,p=2,q=2)\n",
      "k.space: (2,y=13,x=7,D=2,d=2,v=1,f=1,m=1,k=2,d=23,p=2) ->  (2,y=13,x=7,d=2,v=1,f=1,m=1,k=2,d=23,p=2)\n",
      "rot: (y=1,x=7,d=2,m=1,k=1,h=23,p=2,q=2)\n",
      "k.flavour: (2,y=13,x=7,D=2,d=2,v=1,f=10,m=1,k=2,d=3,p=2) ->  (2,y=13,x=7,d=2,v=1,f=10,m=1,k=2,d=3,p=2)\n",
      "rot: (y=1,x=7,d=2,m=1,k=1,h=3,p=2,q=2)\n"
     ]
    }
   ],
   "source": [
    "# prepare field inputs with prime spatial dimensions\n",
    "Y, X = 13, 7  # prime dimensions for spatial field\n",
    "inp = SplitSymDecomp.empty(inpf, batch=(2, Y, X))\n",
    "n_batch_dims = 1\n",
    "for k, v in inp.representations.items():\n",
    "    s = dict(invariant=1, space=8, flavour=10)[k]\n",
    "    s = dict(invariant=0, space=8, flavour=0)[k]\n",
    "    v[...] = s * jax.random.randint(atn.rngs.params(), v.shape, -3, 4) / 2\n",
    "    v[:,4:,:] = 0\n",
    "    v[:,:,4:] = 0\n",
    "    v[:,:,:,1:] = 0\n",
    "\n",
    "\n",
    "# prepare coordinate grid\n",
    "coords = attention.CoordinateGrid.from_shape(*inp.batch_shape[-2:])\n",
    "\n",
    "out,atnw = atn(inp, coords, return_attention_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3a8b4447-e84e-48a2-b205-193b52d0382a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D4.r: axis:0->1 t:⇅ s:⇅ d:[1 0] v:[0] T\n",
      "D4.r: axis:1->0 y:⇅ d:[0 1] v:[0] T\n",
      "q.invariant: (2,y=7,x=13,D=2,d=2,v=1,f=1,m=3,k=2,d=13,p=2) ->  (2,y=7,x=13,d=2,v=1,f=1,m=3,k=2,d=13,p=2)\n",
      "rot: (y=7,x=1,d=2,m=1,k=1,h=13,p=2,q=2)\n",
      "q.space: (2,y=7,x=13,D=2,d=2,v=1,f=1,m=3,k=2,d=23,p=2) ->  (2,y=7,x=13,d=2,v=1,f=1,m=3,k=2,d=23,p=2)\n",
      "rot: (y=7,x=1,d=2,m=1,k=1,h=23,p=2,q=2)\n",
      "q.flavour: (2,y=7,x=13,D=2,d=2,v=1,f=10,m=3,k=2,d=3,p=2) ->  (2,y=7,x=13,d=2,v=1,f=10,m=3,k=2,d=3,p=2)\n",
      "rot: (y=7,x=1,d=2,m=1,k=1,h=3,p=2,q=2)\n",
      "k.invariant: (2,y=7,x=13,D=2,d=2,v=1,f=1,m=1,k=2,d=13,p=2) ->  (2,y=7,x=13,d=2,v=1,f=1,m=1,k=2,d=13,p=2)\n",
      "rot: (y=7,x=1,d=2,m=1,k=1,h=13,p=2,q=2)\n",
      "k.space: (2,y=7,x=13,D=2,d=2,v=1,f=1,m=1,k=2,d=23,p=2) ->  (2,y=7,x=13,d=2,v=1,f=1,m=1,k=2,d=23,p=2)\n",
      "rot: (y=7,x=1,d=2,m=1,k=1,h=23,p=2,q=2)\n",
      "k.flavour: (2,y=7,x=13,D=2,d=2,v=1,f=10,m=1,k=2,d=3,p=2) ->  (2,y=7,x=13,d=2,v=1,f=10,m=1,k=2,d=3,p=2)\n",
      "rot: (y=7,x=1,d=2,m=1,k=1,h=3,p=2,q=2)\n",
      "q.invariant: (2,y=7,x=13,D=2,d=2,v=1,f=1,m=3,k=2,d=13,p=2) ->  (2,y=7,x=13,d=2,v=1,f=1,m=3,k=2,d=13,p=2)\n",
      "rot: (y=1,x=13,d=2,m=1,k=1,h=13,p=2,q=2)\n",
      "q.space: (2,y=7,x=13,D=2,d=2,v=1,f=1,m=3,k=2,d=23,p=2) ->  (2,y=7,x=13,d=2,v=1,f=1,m=3,k=2,d=23,p=2)\n",
      "rot: (y=1,x=13,d=2,m=1,k=1,h=23,p=2,q=2)\n",
      "q.flavour: (2,y=7,x=13,D=2,d=2,v=1,f=10,m=3,k=2,d=3,p=2) ->  (2,y=7,x=13,d=2,v=1,f=10,m=3,k=2,d=3,p=2)\n",
      "rot: (y=1,x=13,d=2,m=1,k=1,h=3,p=2,q=2)\n",
      "k.invariant: (2,y=7,x=13,D=2,d=2,v=1,f=1,m=1,k=2,d=13,p=2) ->  (2,y=7,x=13,d=2,v=1,f=1,m=1,k=2,d=13,p=2)\n",
      "rot: (y=1,x=13,d=2,m=1,k=1,h=13,p=2,q=2)\n",
      "k.space: (2,y=7,x=13,D=2,d=2,v=1,f=1,m=1,k=2,d=23,p=2) ->  (2,y=7,x=13,d=2,v=1,f=1,m=1,k=2,d=23,p=2)\n",
      "rot: (y=1,x=13,d=2,m=1,k=1,h=23,p=2,q=2)\n",
      "k.flavour: (2,y=7,x=13,D=2,d=2,v=1,f=10,m=1,k=2,d=3,p=2) ->  (2,y=7,x=13,d=2,v=1,f=10,m=1,k=2,d=3,p=2)\n",
      "rot: (y=1,x=13,d=2,m=1,k=1,h=3,p=2,q=2)\n"
     ]
    }
   ],
   "source": [
    "op = D4.r\n",
    "\n",
    "# transform representation index for FullRep in space\n",
    "ftfo = symmetry.transform_rep_idx(op, symmetry.FullRep)\n",
    "\n",
    "def tfo_image(image):\n",
    "    # make sure we have batch dimensions respected\n",
    "    return symmetry.transform_image(op, image, ydim=n_batch_dims,xdim=n_batch_dims+1)\n",
    "\n",
    "def tfo_field(field, dim):\n",
    "    ret = attrs.evolve(\n",
    "        field,\n",
    "        invariant=tfo_image(field.invariant),\n",
    "        flavour=tfo_image(field.flavour),\n",
    "        space=tfo_image(field.space)[..., ftfo, :],\n",
    "    )\n",
    "    assert dim.validate(ret), dim.validation_problems(ret)\n",
    "    return ret\n",
    "\n",
    "# transform spatial field\n",
    "tinp = tfo_field(inp, inpf)\n",
    "\n",
    "# rebuild coordinate grid for transformed shape\n",
    "tcoords = attention.CoordinateGrid.from_shape(*tinp.batch_shape[-2:])\n",
    "\n",
    "# expected attention weights:\n",
    "eatnw = [None]*2\n",
    "for axis, (aw,dims) in enumerate(zip(atnw,[\"tsxdvmk\",\"ytsdvmk\"])):\n",
    "    # first, prepare the token representation\n",
    "    d = np.array([symmetry.AxialDirRep(v).apply(op).index for v in [\"↓↑\",\"→←\"][axis]])\n",
    "    v = np.array([v.apply(op).index for v in symmetry.ChiralityRep])\n",
    "    v = np.r_[0]\n",
    "    naxis = d//2\n",
    "    assert np.all(naxis == naxis.flat[0])\n",
    "    naxis = naxis.flat[0]\n",
    "    assert (naxis == axis) == (not op.value&D4.t.value)\n",
    "    d = d%2\n",
    "    # now, apply all the representations per dimension (excluding the final spatial transpose)\n",
    "    info = []\n",
    "    for i,dim in enumerate(dims):\n",
    "        match dim:\n",
    "            case \"t\"|\"s\":\n",
    "                tfo = bool(op.value&[D4.y,D4.x][axis].value)\n",
    "            case \"x\":\n",
    "                tfo = bool(op.value&D4.x.value)\n",
    "            case \"y\":\n",
    "                tfo = bool(op.value&D4.y.value)\n",
    "            case \"d\":\n",
    "                tfo = d\n",
    "            case \"v\":\n",
    "                tfo = v\n",
    "            case _:\n",
    "                continue\n",
    "        if isinstance(tfo, bool):\n",
    "            if not tfo:\n",
    "                continue\n",
    "            tfo = np.s_[::-1]\n",
    "            info.append(f\"{dim}:⇅\")\n",
    "        else:\n",
    "            info.append(f\"{dim}:{tfo}\")\n",
    "        i = -len(dims)+i\n",
    "        aw = np.moveaxis(np.moveaxis(aw,i,0)[tfo],0,i)\n",
    "    # final spatial transpose\n",
    "    if op.value&D4.t.value:\n",
    "        if axis:\n",
    "            aw = np.moveaxis(aw, -7, -5)\n",
    "        else:\n",
    "            aw = np.moveaxis(aw, -5, -7)\n",
    "        info.append(\"T\")\n",
    "    print(f\"{op}: axis:{axis}->{naxis} {\" \".join(info)}\")\n",
    "    eatnw[naxis] = aw\n",
    "\n",
    "# expected output: transform the original output\n",
    "expected = tfo_field(out, outf)\n",
    "\n",
    "# actual output: apply attention to transformed input with rebuilt coordinates\n",
    "actual,tatnw = atn(tinp, tcoords, return_attention_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5acad267-facb-4196-94ef-b0ddc10f9a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axis=0 di=0 v.shape=(2, 13, 13, 7, 2, 1, 3, 2)\n",
      "axis=0 di=0 v.shape=(2, 7, 7, 13, 2, 1, 3, 2)\n",
      "axis=0 di=0 v.shape=(2, 7, 7, 13, 2, 1, 3, 2)\n",
      "axis=0 di=1 v.shape=(2, 13, 13, 7, 2, 1, 3, 2)\n",
      "axis=0 di=1 v.shape=(2, 7, 7, 13, 2, 1, 3, 2)\n",
      "axis=0 di=1 v.shape=(2, 7, 7, 13, 2, 1, 3, 2)\n",
      "axis=1 di=0 v.shape=(2, 13, 7, 7, 2, 1, 3, 2)\n",
      "axis=1 di=0 v.shape=(2, 7, 13, 13, 2, 1, 3, 2)\n",
      "axis=1 di=0 v.shape=(2, 7, 13, 13, 2, 1, 3, 2)\n",
      "axis=1 di=1 v.shape=(2, 13, 7, 7, 2, 1, 3, 2)\n",
      "axis=1 di=1 v.shape=(2, 7, 13, 13, 2, 1, 3, 2)\n",
      "axis=1 di=1 v.shape=(2, 7, 13, 13, 2, 1, 3, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 24 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,axes = plt.subplots(3,8,figsize=(12,5))\n",
    "axes = axes.T.reshape(2,2,2,3)\n",
    "for corner,axe0 in zip([0,-1],axes):\n",
    "    for axis,axe1 in enumerate(axe0):\n",
    "        for di,axe2 in enumerate(axe1):\n",
    "            for i,(v,ax) in enumerate(zip([atnw,eatnw,tatnw],axe2)):\n",
    "                v = v[axis]\n",
    "                vi = 0\n",
    "                if not corner:\n",
    "                    print(f\"{axis=} {di=} {v.shape=}\")\n",
    "                v = v[0,:,:,:,di,vi,0,0]\n",
    "                if axis:\n",
    "                    v = v[corner,:,:]\n",
    "                else:\n",
    "                    v = v[:,:,corner]\n",
    "                ax.pcolormesh(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "01092571-66b7-4f5e-beeb-e8a8a079c9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 13, 7, 8, 11)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "eee293f2-3776-46b3-84a9-6e3103c679fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxialDirRep:\n",
      "     e x y i t l r d\n",
      "d    \u001b[30m↓\u001b[0m \u001b[30m↓\u001b[0m \u001b[31m↑\u001b[0m \u001b[31m↑\u001b[0m \u001b[32m→\u001b[0m \u001b[32m→\u001b[0m \u001b[33m←\u001b[0m \u001b[33m←\u001b[0m\n",
      "u    \u001b[31m↑\u001b[0m \u001b[31m↑\u001b[0m \u001b[30m↓\u001b[0m \u001b[30m↓\u001b[0m \u001b[33m←\u001b[0m \u001b[33m←\u001b[0m \u001b[32m→\u001b[0m \u001b[32m→\u001b[0m\n",
      "r    \u001b[32m→\u001b[0m \u001b[33m←\u001b[0m \u001b[32m→\u001b[0m \u001b[33m←\u001b[0m \u001b[30m↓\u001b[0m \u001b[31m↑\u001b[0m \u001b[30m↓\u001b[0m \u001b[31m↑\u001b[0m\n",
      "l    \u001b[33m←\u001b[0m \u001b[32m→\u001b[0m \u001b[33m←\u001b[0m \u001b[32m→\u001b[0m \u001b[31m↑\u001b[0m \u001b[30m↓\u001b[0m \u001b[31m↑\u001b[0m \u001b[30m↓\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(symmetry.AxialDirRep.fmt_action_table()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "aec17cce-11bb-41c0-b3ee-fe52d0ebe06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullRep:\n",
      "     e x y i t l r d\n",
      "lu   \u001b[30m⦨\u001b[0m \u001b[32m⦩\u001b[0m \u001b[31m⦪\u001b[0m \u001b[33m⦫\u001b[0m \u001b[34m⦯\u001b[0m \u001b[36m⦭\u001b[0m \u001b[35m⦮\u001b[0m \u001b[37m⦬\u001b[0m\n",
      "ld   \u001b[31m⦪\u001b[0m \u001b[33m⦫\u001b[0m \u001b[30m⦨\u001b[0m \u001b[32m⦩\u001b[0m \u001b[35m⦮\u001b[0m \u001b[37m⦬\u001b[0m \u001b[34m⦯\u001b[0m \u001b[36m⦭\u001b[0m\n",
      "ru   \u001b[32m⦩\u001b[0m \u001b[30m⦨\u001b[0m \u001b[33m⦫\u001b[0m \u001b[31m⦪\u001b[0m \u001b[36m⦭\u001b[0m \u001b[34m⦯\u001b[0m \u001b[37m⦬\u001b[0m \u001b[35m⦮\u001b[0m\n",
      "rd   \u001b[33m⦫\u001b[0m \u001b[31m⦪\u001b[0m \u001b[32m⦩\u001b[0m \u001b[30m⦨\u001b[0m \u001b[37m⦬\u001b[0m \u001b[35m⦮\u001b[0m \u001b[36m⦭\u001b[0m \u001b[34m⦯\u001b[0m\n",
      "ul   \u001b[34m⦯\u001b[0m \u001b[35m⦮\u001b[0m \u001b[36m⦭\u001b[0m \u001b[37m⦬\u001b[0m \u001b[30m⦨\u001b[0m \u001b[31m⦪\u001b[0m \u001b[32m⦩\u001b[0m \u001b[33m⦫\u001b[0m\n",
      "ur   \u001b[35m⦮\u001b[0m \u001b[34m⦯\u001b[0m \u001b[37m⦬\u001b[0m \u001b[36m⦭\u001b[0m \u001b[31m⦪\u001b[0m \u001b[30m⦨\u001b[0m \u001b[33m⦫\u001b[0m \u001b[32m⦩\u001b[0m\n",
      "dl   \u001b[36m⦭\u001b[0m \u001b[37m⦬\u001b[0m \u001b[34m⦯\u001b[0m \u001b[35m⦮\u001b[0m \u001b[32m⦩\u001b[0m \u001b[33m⦫\u001b[0m \u001b[30m⦨\u001b[0m \u001b[31m⦪\u001b[0m\n",
      "dr   \u001b[37m⦬\u001b[0m \u001b[36m⦭\u001b[0m \u001b[35m⦮\u001b[0m \u001b[34m⦯\u001b[0m \u001b[33m⦫\u001b[0m \u001b[32m⦩\u001b[0m \u001b[31m⦪\u001b[0m \u001b[30m⦨\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(symmetry.FullRep.fmt_action_table()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "887b2644-9b58-4f8d-a979-b2f526da20a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 0, 1, 5, 4, 7, 6])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symmetry.transform_rep_idx(D4.x, symmetry.FullRep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "65f9b9e7-39b1-4132-93b3-2038bb3a9d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+QAAAINCAYAAAC3YbXvAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOl1JREFUeJzt3Q+QlPV9P/DPccgdIEKJBjg9FBPQaCqkWC50cGoi6YVkHHEao6kxxCQyaZs2hogdUgXqjwmNNpbYodJ0aijJdNRmWs2khiYyKTYBdYSxjemfgMF6ioixBQ70DuH2N7stjCSQuA93+9397us18wi78L3n6773u9z7nmf3aSmVSqUAAAAAampYbXcHAAAAlCnkAAAAkIBCDgAAAAko5AAAAJCAQg4AAAAJKOQAAACQgEIOAAAACSjkAAAAkMDwyNzAwEDs3LkzxowZEy0tLamn09RKpVL09vZGR0dHDBt28j8Lkm2e2cq1fliz+ZJtvmSbJ7nmS7b5eqPZZl/Iy0/Izs7O1NPgdXp6euKss8466a8j2zyzlWv9sWbzJdt8yTZPcs2XbJs32+wLefmnQ2UdX/hcDBvZnno6TW3g1b7Y+QefP5rJyZJtntke+RpTPrs0hrXJNaWB/r7Y8cXbBn3NyjbfbDvuWOL1uB5ejxevlG1mhirXKYu8HtfF6/GdQ/BvrWwbJtvsC/mRUzXK/4j4h6Q+DNbpM7LNM9ujuba1R2u7XLNcs7KtG16P8yXbPHk9zpdsmzdbH+oGAAAACSjkAAAAkIBCDgAAAAko5AAAAJCAQg4AAAAJKOQAAACQgEIOAAAACSjkAAAAkIBCDgAAAAko5AAAAJCAQg4AAAAJKOQAAACQgEIOAAAACSjkAAAAkIBCDgAAAAko5AAAANBshfyRRx6Jyy+/PDo6OqKlpSUeeOCBY/68VCrF0qVLY9KkSTFy5MiYO3dubNu2Ldl8AQAAIItCfuDAgZg+fXqsXr36uH9+++23x1133RVr1qyJxx57LEaPHh3d3d3R19dX87kCAADAYBoeCc2bN6+yHU/56PiqVavilltuiSuuuKJy37p162LChAmVI+nXXHNNjWcLAAAAmRTyn2fHjh2xa9euymnqR4wdOza6urpi8+bNJyzk/f39le2Iffv21WS+DD3Z5kmu+ZJtvmSbL9nmSa75km3jq9sPdSuX8bLyEfHXK98+8mfHs3LlykpxP7J1dnYO+VypDdnmSa75km2+ZJsv2eZJrvmSbeOr20Je1JIlS2Lv3r1Ht56entRTYpDINk9yzZds8yXbfMk2T3LNl2wbX92esj5x4sTKry+++GLlU9aPKN+eMWPGCce1tbVVNvIj2zzJNV+yzZds8yXbPMk1X7JtfHV7hHzKlCmVUr5hw4Zj3hNR/rT12bNnJ50bAAAANPQR8v3798f27duP+SC3J598MsaPHx+TJ0+OG2+8MVasWBFTp06tFPRbb721cs3y+fPnp5w2AAAANHYhf+KJJ+Jd73rX0duLFi2q/LpgwYJYu3Zt3HzzzZVrlS9cuDD27NkTc+bMifXr10d7e3vCWQMAAECDF/JLL720cr3xE2lpaYnbbrutsgEAAEBO6vY95AAAAJAzhRwAAAASUMgBAAAgAYUcAAAAElDIAQAAIAGFHAAAABJQyAEAACABhRwAAAASUMgBAAAgAYUcAAAAElDIAQAAIAGFHAAAABJQyAEAACABhRwAAAASUMgBAAAgAYUcAAAAElDIAQAAIAGFHAAAABJQyAEAACABhRwAAAAavZDv3r07li1bNphfEgAAALI0qIW8r68vvva1r8WCBQuiVCoN5pcGAACArAyvdsDLL78cDz744An//LrrrosVK1bEwMBAfPWrXz3Z+QEAAECWChXyr3zlKyf88yNHxh955JE4dOhQDB9e9S4AAAAge1W35WnTpsU///M/n/DPP/nJT8azzz4b3/3ud5VxAAAAOIFBbcxPPPFEPPzww7Fx48aYMmXKYH5pAAAAyMqgFvKLL744/v3f/z1OOeWUwfyyAAAAkJ1Bvw75YJbx5cuXR0tLyzHb+eefP2hfHwAAAFKp+zd5X3jhhZXT4I/wvnQAAAByUPfttlzAJ06cmHoaAAAAUN+nrA+2bdu2RUdHR5x77rlx7bXXVj7BHQAAABpdXR8h7+rqirVr18Z5550XL7zwQvzRH/1RXHLJJfHUU0/FmDFjjjumv7+/sh2xb9++Gs6YoSTbPMk1X7LNl2zzJds8yTVfsm18dX2EfN68eXHVVVfFRRddFN3d3fHQQw/Fnj174v777z/hmJUrV8bYsWOPbp2dnTWdM0NHtnmSa75kmy/Z5ku2eZJrvmTb+Oq6kP+0cePGxbRp02L79u0n/DtLliyJvXv3Ht16enpqOkeGjmzzJNd8yTZfss2XbPMk13zJtvHV9SnrP23//v3x9NNPx3XXXXfCv9PW1lbZyI9s8yTXfMk2X7LNl2zzJNd8ybbx1fUR8ptuuik2btwYzzzzTGzatCmuvPLKaG1tjQ996EOppwYAAAD5HiF/7rnnKuX75ZdfjjPOOCPmzJkTjz76aOX3AAAA0MjqupDfe++9qacAAAAAzXfKOgAAAOSqro+QD6a3/v6WGN5ySlVjfvTlWYX2NbKn2MP6Sz8aKDRu52XFxuVCtnn61nVfijFjqvuZ4bv/fHHh/T31e3cXGveZF2YWGrf+m8WegzmoZba1zrXZsx0/oTdaRx2sasxnpj5caF/rzit2aZ9/3PkvhcZNeegT0cxkm6cRvRGt1cUas695svD+vv3DCwqNa2kt9v3QiB+3R7OqZba1zjW3bB0hBwAAgAQUcgAAAEhAIQcAAIAEFHIAAABIQCEHAACABBRyAAAASEAhBwAAgASa5jrkL3y6K1rbqrte3bSFmwrt679W/Fqhcd/84p8WGvcrD306mpls87Ru7/RoP1zd9eXb/7v4/t5/8XsLjRv39b7iO21StcxWrrU1/qptMbylumyX3/HBQvsa8zsthcYtfG50oXHNTrZ5Gv3u3TF8dFtVY3bMeqX4Dr9SbNhAX9NUlsbMVq4nxRFyAAAASEAhBwAAgAQUcgAAAEhAIQcAAIAEFHIAAABIQCEHAACABBRyAAAASKBpLv4284qnYsSpI6oa0/PoOwrt6/r53yk0bt6/fqTQuGYn2zx9750jq77m7d47SoX3N6HguOsmFLum/dZ4WzSrWmZb61ybPdtnVsyKYe3tVY3Zdu2aQvvq/sCCQuM2PTC90Lg497VoZrLNU9+33hytI6rLddeXzii+w1eKvZbvuPLLhca97cu/Hc2qptnWONfcsnWEHAAAABJQyAEAACABhRwAAAASUMgBAAAgAYUcAAAAElDIAQAAIIGmuezZll2To3VUW3WDFh0stK/z2l4oNO7RGdsLjZvy3A3RzGSbp52f7YrWtuou13G4faDw/gYmji80bvnyjxXb4VujadUy25rn2uTZnv5kKYafUt3lb6bGJwvta9Q7WwqNe9NThwqNO3BuNDXZ5qn7o5ui7dTqLkP5rdWXFN7fuB/3Fxo3bX+x51JrNK9aZlvrXHPL1hFyAAAASEAhBwAAgAQUcgAAAEigIQr56tWr45xzzon29vbo6uqKxx9/PPWUAAAAIO9Cft9998WiRYti2bJlsXXr1pg+fXp0d3fH7t27U08NAAAA8i3kd955Z9xwww1x/fXXxwUXXBBr1qyJUaNGxT333JN6agAAAJDnZc8OHjwYW7ZsiSVLlhy9b9iwYTF37tzYvHnzccf09/dXtiP27t1b+fXwK8U+jr+IV3oPFxq3b6DYuIFX+6IRHJlnqVTdZVOOkG2e2Z4w1/7q/98HXi1+2bNDh4s9jw4fLJbR4b5il/WppYH+IVqzNcy21rlGs2f7WoFsCz5eh/uLjTv0WrFLYw28WuyxyubfWtlmmWv/gddq+vp46FCx1+SBvoL/vjfx63Ets615rrllW6pjzz//fHn2pU2bNh1z/+LFi0uzZs067phly5ZVxtjqd+vp6Sn0fJBtntnKtf43azbfTbb5brLNc5Nrvptso2mzbSn/J+rUzp0748wzz4xNmzbF7Nmzj95/8803x8aNG+Oxxx77hT8l2rNnT5x99tnx7LPPxtixY2s290awb9++6OzsjJ6enjjttNOGfH/lp1pvb290dHRUznSolmzrM9eTzVaub5w1my/Z5qnRXo/LZPvGWLP5km2+9tVptnV9yvrpp58era2t8eKLLx5zf/n2xIkTjzumra2tsv208hOyVv8YNpry41Krx+ZkXhhkW7+5nky2cq2eNZsv2eapUV6Py2RbHWs2X7LN12l1lm1df6jbiBEjYubMmbFhw4aj9w0MDFRuv/6IOQAAADSauj5CXla+5NmCBQvi4osvjlmzZsWqVaviwIEDlU9dBwAAgEZV94X86quvjpdeeimWLl0au3btihkzZsT69etjwoQJb2h8+RSO8jXMj3cqR7Nr9Mem0ec/VBr9cWn0+Q+lRn9sGn3+Q6nRH5tGn/9QyeFxyeH/YSg0+uPS6PMfSo3+2DT6/JvxsanrD3UDAACAXNX1e8gBAAAgVwo5AAAAJKCQAwAAQAIKOQAAACSgkAMAAEACCjkAAAAkoJADAABAAgo5AAAAJKCQAwAAQAIKOQAAACSgkAMAAEACCjkAAAAkMDwyNzAwEDt37owxY8ZES0tL6uk0tVKpFL29vdHR0RHDhp38z4Jkm2e2cq0f1my+ZJsv2eZJrvmSbb7eaLbZF/LyE7KzszP1NHidnp6eOOuss07668g2z2zlWn+s2XzJNl+yzZNc8yXb5s02+0Je/ulQ2ZTPLo1hbe2pp9PUBvr7YscXbzuaycmSbZ7ZHvkaHV/4XAwbKdeUBl7ti51/8PlBX7OyTW+osp2yyOtxXbwe3zkE/9bKNstcO+5Y4vW4Hl6PF6+UbRNnm30hP3KqRvkfkdZ2T8p6MFinz8g2z2yP5jqy3T8kua5Z2dYNr8f5km2evB7nS7bNm60PdQMAAIAEFHIAAABIQCEHAACABBRyAAAASEAhBwAAgAQUcgAAAEhAIQcAAIAEFHIAAABIQCEHAACABBRyAAAASEAhBwAAgAQUcgAAAEhAIQcAAIAEFHIAAABIQCEHAACABBRyAAAAaLZC/sgjj8Tll18eHR0d0dLSEg888MAxf14qlWLp0qUxadKkGDlyZMydOze2bduWbL4AAACQRSE/cOBATJ8+PVavXn3cP7/99tvjrrvuijVr1sRjjz0Wo0ePju7u7ujr66v5XAEAAGAwDY+E5s2bV9mOp3x0fNWqVXHLLbfEFVdcUblv3bp1MWHChMqR9GuuuabGswUAAIBMCvnPs2PHjti1a1flNPUjxo4dG11dXbF58+YTFvL+/v7KdsS+fftqMl+GnmzzJNd8yTZfss2XbPMk13zJtvHV7Ye6lct4WfmI+OuVbx/5s+NZuXJlpbgf2To7O4d8rtSGbPMk13zJNl+yzZds8yTXfMm28dVtIS9qyZIlsXfv3qNbT09P6ikxSGSbJ7nmS7b5km2+ZJsnueZLto2vbk9ZnzhxYuXXF198sfIp60eUb8+YMeOE49ra2iob+ZFtnuSaL9nmS7b5km2e5Jov2Ta+uj1CPmXKlEop37BhwzHviSh/2vrs2bOTzg0AAAAa+gj5/v37Y/v27cd8kNuTTz4Z48ePj8mTJ8eNN94YK1asiKlTp1YK+q233lq5Zvn8+fNTThsAAAAau5A/8cQT8a53vevo7UWLFlV+XbBgQaxduzZuvvnmyrXKFy5cGHv27Ik5c+bE+vXro729PeGsAQAAoMEL+aWXXlq53viJtLS0xG233VbZAAAAICd1+x5yAAAAyJlCDgAAAAko5AAAAJCAQg4AAAAJKOQAAACQgEIOAAAACSjkAAAAkIBCDgAAAAko5AAAAJCAQg4AAAAJKOQAAACQgEIOAAAACSjkAAAAkIBCDgAAAAko5AAAAJCAQg4AAAAJKOQAAACQgEIOAAAACSjkAAAAkIBCDgAAAAko5AAAANBIhby3tzf+8A//MA4dOjS4MwIAAIAmMLzIoL1790Z3d3eceuqplUI+fHihLwMAAABNq+omvW/fvnjPe94T27ZtixUrVsTf/M3fnPDvfuxjHzvZ+QEAAECWqi7ku3btih/+8IdxyimnxH333RelUum4f6+lpUUhBwAAgMEq5NOmTYsHH3ww5s+fHx/+8Idj4cKF1X4JAAAAaHqFPtRt7ty5lVL+x3/8x5X3kwMAAADVKfxpbJdddln853/+Z+XUdQAAAKCG1yEf6jK+fPnyynvRX7+df/75Q7pPAAAAqIW6v17ZhRdeGA8//PDR2y6xBgAAQA7qvt2WC/jEiRNTTwMAAACaq5CXr3fe0dER7e3tMXv27Fi5cmVMnjz5hH+/v7+/sr3+uunkQbZ5kmu+ZJsv2eZLtnmSa75k2+TvIR9qXV1dsXbt2li/fn3cfffdsWPHjrjkkkuit7f3hGPKhX3s2LFHt87OzprOmaEj2zzJNV+yzZds8yXbPMk1X7JtfHVdyOfNmxdXXXVVXHTRRdHd3R0PPfRQ7NmzJ+6///4TjlmyZEnlUmxHtp6enprOmaEj2zzJNV+yzZds8yXbPMk1X7JtfHV/yvrrjRs3LqZNmxbbt28/4d9pa2urbORHtnmSa75kmy/Z5ku2eZJrvmTb+Or6CPlP279/fzz99NMxadKk1FMBAACAfAv5TTfdFBs3boxnnnkmNm3aFFdeeWW0trbGhz70odRTAwAAgHxPWX/uuecq5fvll1+OM844I+bMmROPPvpo5fcAAADQyOq6kN97772ppwAAAADNd8o6AAAA5Kquj5APpm9d96UYM6a6nz+8+88XF9rXU793d6Fxn3lhZqFx6785K5qZbPP01t/fEsNbTqlqzI++XPzxGtlT7OXwl340UGjczsuKjctBLbOtda7Nnu2I3ojWg9WNmX3Nk4X29e0fXlBoXEtrsXxG/Lg9mpls8zR+Qm+0jqou2M9Mfbjw/tadV+wa2f+4818KjZvy0CeiWdUy21rnmlu2jpADAABAAgo5AAAAJKCQAwAAQAIKOQAAACSgkAMAAEACCjkAAAAkoJADAABAAk1zHfJ1e6dH++Hqrnvb/t/F9vX+i99baNy4r/cV22GTk22eXvh0V7S2VXdt2GkLNxXe33+t+LVC4775xT8tNO5XHvp0NKtaZlvrXJs929Hv3h3DR7dVNWbHrFeK7ewrxYYN9DXNtz6DSrZ5Gn/VthjeUt33UMvv+GDh/Y35nZZC4xY+N7rwPptVLbOV68lxhBwAAAASUMgBAAAgAYUcAAAAElDIAQAAIAGFHAAAABJQyAEAACCBprk+xPfeObLqj/7fe0ep0L4mFBoVcd2EYpf12Rpvi2Ym2zzNvOKpGHHqiKrG9Dz6jsL7u37+dwqNm/evHym8z2ZVy2zlWlt933pztI6o7pJ2u750RrGdvVLsdXzHlV8uNO5tX/7taGayzdMzK2bFsPbqct127ZrC++v+wIJC4zY9ML3YDs99LZpVLbOtea6ZZesIOQAAACSgkAMAAEACCjkAAAAkoJADAABAAgo5AAAAJKCQAwAAQAIKOQAAACTQNNch3/nZrmhtq+5afIfbBwrta2Di+ELjli//WKFx8dZoarLN05Zdk6N1VFt1gxYdLLy/89peKDTu0RnbC42b8twN0axqmW2tc232bLs/uinaTj2lqjHfWn1JoX2N+3F/oXHT9n+y0LjWaG6yzdPpT5Zi+CnVXfd9ahR7nMtGvbOl0Lg3PXWo0LgD50bTqmW2tc41t2wdIQcAAIAEFHIAAABIoCEK+erVq+Occ86J9vb26Orqiscffzz1lAAAACDvQn7ffffFokWLYtmyZbF169aYPn16dHd3x+7du1NPDQAAAPIt5HfeeWfccMMNcf3118cFF1wQa9asiVGjRsU999yTemoAAACQZyE/ePBgbNmyJebOnXv0vmHDhlVub968OencAAAAINvLnv3kJz+Jw4cPx4QJE465v3z7P/7jP447pr+/v7IdsXfv3sqvh/v7qt7/wKvFLo116HCxy3UcPthXbFxfsUsN1NrA/2VQKlV3CYYjZJtntifM9ZVij3VRr/QeLjRu30CxcQOvFntO1NKROQ76mq1htrXOtdmz7T/wWs1eHw8dKvY8Gugr9vofTfB6XCbbJvse6rUC30OdxON1uL/Y2EOvFbs81sCrxR6vLP6trWG2tc41u2xLdez5558vz760adOmY+5fvHhxadasWccds2zZssoYW/1uPT09hZ4Pss0zW7nW/2bN5rvJNt9Ntnlucs13k200bbYt5f9EHZ+yXn6/+Ne//vWYP3/+0fsXLFgQe/bsiQcffPAX/pSo/PfOPvvsePbZZ2Ps2LE1m3sj2LdvX3R2dkZPT0+cdtppQ76/8lOtt7c3Ojo6Km89qJZs6zPXk81Wrm+cNZsv2eap0V6Py2T7xliz+ZJtvvbVabZ1fcr6iBEjYubMmbFhw4ajhXxgYKBy+1Of+tRxx7S1tVW2n1Z+QtbqH8NGU35cavXYnMwLg2zrN9eTyVau1bNm8yXbPDXK63GZbKtjzeZLtvk6rc6yretCXla+5Fn5iPjFF18cs2bNilWrVsWBAwcqn7oOAAAAjaruC/nVV18dL730UixdujR27doVM2bMiPXr1//MB70BAABAI6n7Ql5WPj39RKeo/yLlUziWLVt23FM5ml2jPzaNPv+h0uiPS6PPfyg1+mPT6PMfSo3+2DT6/IdKDo9LDv8PQ6HRH5dGn/9QavTHptHn34yPTV1/qBsAAADkqvqP8gMAAABOmkIOAAAACSjkAAAAkIBCDgAAAAko5AAAAJCAQg4AAAAJKOQAAACQgEIOAAAACSjkAAAAkIBCDgAAAAko5AAAAJCAQg4AAAAJDI/MDQwMxM6dO2PMmDHR0tKSejpNrVQqRW9vb3R0dMSwYSf/syDZ5pmtXOuHNZsv2eZLtnmSa75km683mm32hbz8hOzs7Ew9DV6np6cnzjrrrJP+OrLNM1u51h9rNl+yzZds8yTXfMm2ebPNvpCXfzpU1nHHkhg2sj31dJrawKt9sXPxyqOZnKwjX2fKoqUxrE22KQ3098WOO28blGyt2fphzeZrMNfsMev2C5+zbuth3f7B5wd/3X7Wuk2+Zr9ozebIms3XG1232RfyI6dqlF9svODUh8E6feZotm3t0dou21yytWbrjzWbr0HP1rqtG9ZtnqzZfFmzzZutD3UDAACABBRyAAAASEAhBwAAgAQUcgAAAEhAIQcAAIAEFHIAAABIQCEHAACABBRyAAAASEAhBwAAgAQUcgAAAEhAIQcAAIAEFHIAAABIQCEHAACABBRyAAAASEAhBwAAgAQUcgAAAGi2Qv7II4/E5ZdfHh0dHdHS0hIPPPDAMX9eKpVi6dKlMWnSpBg5cmTMnTs3tm3blmy+AAAAkEUhP3DgQEyfPj1Wr1593D+//fbb46677oo1a9bEY489FqNHj47u7u7o6+ur+VwBAABgMA2PhObNm1fZjqd8dHzVqlVxyy23xBVXXFG5b926dTFhwoTKkfRrrrmmxrMFAACATAr5z7Njx47YtWtX5TT1I8aOHRtdXV2xefPmExby/v7+ynbEvn37ajJfhp5s8yTXfMk2X7LNl2zzJNd8ybbx1e2HupXLeFn5iPjrlW8f+bPjWblyZaW4H9k6OzuHfK7UhmzzJNd8yTZfss2XbPMk13zJtvHVbSEvasmSJbF3796jW09PT+opMUhkmye55ku2+ZJtvmSbJ7nmS7aNr25PWZ84cWLl1xdffLHyKetHlG/PmDHjhOPa2toqG/mRbZ7kmi/Z5ku2+ZJtnuSaL9k2vro9Qj5lypRKKd+wYcMx74kof9r67Nmzk84NAAAAGvoI+f79+2P79u3HfJDbk08+GePHj4/JkyfHjTfeGCtWrIipU6dWCvqtt95auWb5/PnzU04bAAAAGruQP/HEE/Gud73r6O1FixZVfl2wYEGsXbs2br755sq1yhcuXBh79uyJOXPmxPr166O9vT3hrAEAAKDBC/mll15aud74ibS0tMRtt91W2QAAACAndfsecgAAAMiZQg4AAAAJKOQAAACQgEIOAAAACSjkAAAAkIBCDgAAAAko5AAAAJCAQg4AAAAJKOQAAACQgEIOAAAACSjkAAAAkIBCDgAAAAko5AAAAJCAQg4AAAAJKOQAAACQgEIOAAAAjVTIt27dGlOnTo0HH3xwcGcEAAAATaBQIX/iiSfisssui6effjo++MEPxt///d8P/swAAAAgY1UX8v/4j/+I97znPbF48eJoaWmJW265JT784Q/Hd77znaGZIQAAAGSo6kI+bdq0WLduXXzuc5+LUqkUV199deW09dmzZw/NDAEAACBDw6sdMGzYsLj88suPuW/u3LmDOScAAADInk9ZBwAAgAQUcgAAAEhAIQcAAIAEFHIAAABIQCEHAACARivk3/3ud2Py5MmDNxsAAABoEidVyH/913892tvbY6gsX748WlpajtnOP//8IdsfAAAA1O11yGvtwgsvjIcffvjo7eHD637KAAAA8AvVfbstF/CJEyemngYAAAA014e6bdu2LTo6OuLcc8+Na6+9Np599tnUUwIAAIC8j5B3dXXF2rVr47zzzosXXngh/uiP/iguueSSeOqpp2LMmDHHHdPf31/Zjti3b18NZ8xQkm2e5Jov2eZLtvmSbZ7kmi/ZNr66PkI+b968uOqqq+Kiiy6K7u7ueOihh2LPnj1x//33n3DMypUrY+zYsUe3zs7Oms6ZoSPbPMk1X7LNl2zzJds8yTVfsm18dV3If9q4ceNi2rRpsX379hP+nSVLlsTevXuPbj09PTWdI0NHtnmSa75kmy/Z5ku2eZJrvmTb+Or6lPWftn///nj66afjuuuuO+HfaWtrq2zkR7Z5kmu+ZJsv2eZLtnmSa75k2/jq+gj5TTfdFBs3boxnnnkmNm3aFFdeeWW0trbGhz70odRTAwAAgHyPkD/33HOV8v3yyy/HGWecEXPmzIlHH3208nsAAABoZHVdyO+9997UUwAAAIDmO2UdAAAAclXXR8gH0/gJvdE66mBVYz4z9eFC+1p3XrHLDfzjzn8pNG7KQ5+IZjaiN6K1umhj9jVPFtrXt394QaFxLa0DhcaN+HF7NKtartky67Z2cl6zzb5u3/r7W2J4yylVjfnRl2cV2tfInmLfwvzSj4plu/Oy4s+JHHzrui/FmDHVHcd5958vLrSvp37v7kLjPvPCzELj1n+z2HMwB7Vcs2XWbe3kvGZzW7eOkAMAAEACCjkAAAAkoJADAABAAgo5AAAAJKCQAwAAQAIKOQAAACSgkAMAAEACzXMd8qu2VX2dxeV3fLDQvsb8TkuhcQufG11oXLMb/e7dMXx0W1Vjdsx6pdjOvlJs2EBf0yy1hlyzZdZt7Viz+Xrh013R2lbdddinLdxUaF//teLXCo375hf/tNC4X3no09HM1u2dHu2Hq3tNbv/vYvt6/8XvLTRu3Nf7iu2widVyzZZZt7VjzTYOR8gBAAAgAYUcAAAAElDIAQAAIAGFHAAAABJQyAEAACABhRwAAAASUMgBAAAggaa50OozK2bFsPbqrrO47do1hfbV/YEFhcZtemB6oXFx7mvRzPq+9eZoHVFdtru+dEaxnb1SKjRsx5VfLjTubV/+7WhWtVyzZdZt7eS8Zpt93c684qkYceqIqsb0PPqOQvu6fv53Co2b968fKTSu2X3vnSNjeEt11zTee0ex9Teh0KiI6yYUuz721nhbNKtartky67Z2cl6zua1bR8gBAAAgAYUcAAAAElDIAQAAIAGFHAAAABJQyAEAACABhRwAAAASaJrLnp3+ZCmGn1LdR/lPjU8W2teod7YUGvempw4VGnfg3Ghq3R/dFG2nVndZh2+tvqTQvsb9uL/QuGn7iz2XWqN51XLNllm3tZPzmm32dbtl1+RoHdVW3aBFBwvt67y2FwqNe3TG9kLjpjx3QzSznZ/tita26i5XeLh9oNC+BiaOLzRu+fKPFRoXb42mVcs1W2bd1k7WazazdesIOQAAACSgkAMAAEACCjkAAAAk0BCFfPXq1XHOOedEe3t7dHV1xeOPP556SgAAAJB3Ib/vvvti0aJFsWzZsti6dWtMnz49uru7Y/fu3amnBgAAAPkW8jvvvDNuuOGGuP766+OCCy6INWvWxKhRo+Kee+5JPTUAAADI87JnBw8ejC1btsSSJUuO3jds2LCYO3dubN68+bhj+vv7K9sRe/furfx6+LW+qvc/0FfsMkiH+4uNO/RascsnDbxa3aWhUhl49X8zKJWKzfdE2fYfeK3qr3X4YPXPh7JDh4pdQmmgr9hlJKLgc7DWBvqLZ1sPa7ayP+v2Z1izke26PZk1+3PX7SvFHu8iXuk9XGjcvoHDJ7UemnXdHv6/50x1cym2jg4dLvY8Kvo6cdiarRnr9mdZs8VktW5Ldez5558vz760adOmY+5fvHhxadasWccds2zZssoYW/1uPT09hZ4Pss0zW7nW/2bN5rvJNt9Ntnlucs13k200bbYt5f9Endq5c2eceeaZsWnTppg9e/bR+2+++ebYuHFjPPbYY7/wp0R79uyJs88+O5599tkYO3ZszebeCPbt2xednZ3R09MTp5122pDvr/xU6+3tjY6OjsqZDtWSbX3merLZyvWNs2bzJds8NdrrcZls3xhrNl+yzde+Os22rk9ZP/3006O1tTVefPHFY+4v3544ceJxx7S1tVW2n1Z+QtbqH8NGU35cavXYnMwLg2zrN9eTyVau1bNm8yXbPDXK63GZbKtjzeZLtvk6rc6yresPdRsxYkTMnDkzNmzYcPS+gYGByu3XHzEHAACARlPXR8jLypc8W7BgQVx88cUxa9asWLVqVRw4cKDyqesAAADQqOq+kF999dXx0ksvxdKlS2PXrl0xY8aMWL9+fUyYMOENjS+fwlG+hvnxTuVodo3+2DT6/IdKoz8ujT7/odToj02jz38oNfpj0+jzHyo5PC45/D8MhUZ/XBp9/kOp0R+bRp9/Mz42df2hbgAAAJCrun4POQAAAORKIQcAAIAEFHIAAABIQCEHAACABBRyAAAASEAhBwAAgAQUcgAAAEhAIQcAAIAEFHIAAABIQCEHAACABBRyAAAASEAhBwAAgASGR+YGBgZi586dMWbMmGhpaUk9naZWKpWit7c3Ojo6Ytiwk/9ZkGzzzFau9cOazZds8yXbPMk1X7LN1xvNNvtCXn5CdnZ2pp4Gr9PT0xNnnXXWSX8d2eaZrVzrjzWbL9nmS7Z5kmu+ZNu82WZfyMs/HSqbsmhpDGtrTz2dpjbQ3xc77rztaCYn68jX6bhjSQwbKduUBl7ti52LVw5KttZs/bBm8zWYa/aYdftZ67Yu1u0Xh2DdfuFz1m3qNfsHn7dmM2TN5uuNrtvsC/mRUzXKLzat7Z6U9WCwTp85mu3Idi84GWVrzdYfazZfg56tdVs3rNs8WbP5smabN1sf6gYAAAAJKOQAAACQgEIOAAAACSjkAAAAkIBCDgAAAAko5AAAAJCAQg4AAAAJKOQAAACQgEIOAAAACSjkAAAAkIBCDgAAAAko5AAAAJCAQg4AAAAJKOQAAACQgEIOAAAACSjkAAAA0GyF/JFHHonLL788Ojo6oqWlJR544IFj/rxUKsXSpUtj0qRJMXLkyJg7d25s27Yt2XwBAAAgi0J+4MCBmD59eqxevfq4f3777bfHXXfdFWvWrInHHnssRo8eHd3d3dHX11fzuQIAAMBgGh4JzZs3r7IdT/no+KpVq+KWW26JK664onLfunXrYsKECZUj6ddcc02NZwsAAACZFPKfZ8eOHbFr167KaepHjB07Nrq6umLz5s0nLOT9/f2V7Yh9+/bVZL4MPdnmSa75km2+ZJsv2eZJrvmSbeOr2w91K5fxsvIR8dcr3z7yZ8ezcuXKSnE/snV2dg75XKkN2eZJrvmSbb5kmy/Z5kmu+ZJt46vbQl7UkiVLYu/evUe3np6e1FNikMg2T3LNl2zzJdt8yTZPcs2XbBtf3Z6yPnHixMqvL774YuVT1o8o354xY8YJx7W1tVU28iPbPMk1X7LNl2zzJds8yTVfsm18dXuEfMqUKZVSvmHDhmPeE1H+tPXZs2cnnRsAAAA09BHy/fv3x/bt24/5ILcnn3wyxo8fH5MnT44bb7wxVqxYEVOnTq0U9FtvvbVyzfL58+ennDYAAAA0diF/4okn4l3vetfR24sWLar8umDBgli7dm3cfPPNlWuVL1y4MPbs2RNz5syJ9evXR3t7e8JZAwAAQIMX8ksvvbRyvfETaWlpidtuu62yAQAAQE7q9j3kAAAAkDOFHAAAABJQyAEAACABhRwAAAASUMgBAAAgAYUcAAAAElDIAQAAIAGFHAAAABJQyAEAACABhRwAAAASUMgBAAAgAYUcAAAAElDIAQAAIAGFHAAAABJQyAEAACABhRwAAAASUMgBAACg0Qr5ueeeGzt27Bi82QAAAECTOKlC/swzz8Rrr702eLMBAACAJuGUdQAAAEhAIQcAAIAEFHIAAABIQCEHAACARinkfX19P/c2AAAAMMiF/Kmnnoq3vOUt8YMf/CBaWlpi586d8Y53vCO+8Y1vVPulAAAAoGlVXcjf/va3x4c//OG47LLLKrc/+MEPxoUXXhjvf//7h2J+AAAAkKVCp6x/4QtfiE984hNRKpXi3e9+d9x3333R2to6+LMDAACATA0vOvDzn/98vO9974vZs2cr4wAAAFDLT1mfM2fOkJbx5cuXV96n/vrt/PPPH7L9AQAAQN0fIa+V8vvTH3744aO3hw+v+ykDAADAL1T37bZcwCdOnJh6GgAAANBchXzbtm3R0dER7e3tlferr1y5MiZPnnzCv9/f31/Zjti3b1+NZspQk22e5Jov2eZLtvmSbZ7kmi/ZNvl7yIdaV1dXrF27NtavXx9333137NixIy655JLo7e094ZhyYR87duzRrbOzs6ZzZujINk9yzZds8yXbfMk2T3LNl2wbX10X8nnz5sVVV10VF110UXR3d8dDDz0Ue/bsifvvv/+EY5YsWRJ79+49uvX09NR0zgwd2eZJrvmSbb5kmy/Z5kmu+ZJt46v7U9Zfb9y4cTFt2rTYvn37Cf9OW1tbZSM/ss2TXPMl23zJNl+yzZNc8yXbxlfXR8h/2v79++Ppp5+OSZMmpZ4KAAAA5FvIb7rppti4cWM888wzsWnTprjyyisr1z3/0Ic+lHpqAAAAkO8p688991ylfL/88stxxhlnxJw5c+LRRx+t/B4AAAAaWV0X8nvvvTf1FAAAAKD5TlkHAACAXNX1EfLBNKI3ovVgdWNmX/NkoX19+4cXFBrX0jpQaNyIH7dHMxs/oTdaR1UX7memPlxoX+vOK3Ztx3/c+S+Fxk156BPRrGq5Zsus29rJec02+7r91nVfijFjqvtZ/7v/fHGhfT31e3cXGveZF2YWGrf+m7Oimb3197fE8JZTqhrzoy8Xe8xG9hT79vSXflTs9XjnZcXG5aCWa7bMuq2dnNdsbuvWEXIAAABIQCEHAACABBRyAAAASEAhBwAAgAQUcgAAAEhAIQcAAIAEFHIAAABIoGmuQz763btj+Oi2qsbsmPVKsZ19pdiwgb6miWNQjb9qW9XXWVx+xwcL7WvM77QUGrfwudGFxjWzmq7ZMuu2ZqzZfK3bOz3aD1eXbft/F9vX+y9+b6Fx477eV2yHTe6FT3dFa1t7VWOmLdxUaF//teLXCo375hf/tNC4X3no09Gsarlmy6zb2sl5zea2bh0hBwAAgAQUcgAAAEhAIQcAAIAEFHIAAABIQCEHAACABBRyAAAASKBprtfT9603R+uI6j76f9eXzii2s1dKhYbtuPLLhca97cu/Hc3smRWzYlh7ddluu3ZNoX11f2BBoXGbHpheaFyc+1o0q5qu2TLrtmayXrNNvm6/986RVV/Sbu8dxdbehEKjIq6bUOyyPlvjbdHMZl7xVIw4dURVY3oefUehfV0//zuFxs37148UGtfMarlmy6zb2rFmG4cj5AAAAJCAQg4AAAAJKOQAAACQgEIOAAAACSjkAAAAkIBCDgAAAAko5AAAAJBA01yHvPujm6Lt1Oqus/it1ZcU2te4H/cXGjdt/ycLjWuN5nb6k6UYfkp118ScGsUe61HvbCk07k1PHSo07sC50bRquWbLrNvayXnNNvu63fnZrmhtq+4a84fbBwrta2Di+ELjli//WKFx8dZoalt2TY7WUW3VDVp0sNC+zmt7odC4R2dsLzRuynM3RLOq5Zots25rJ+c1m9u6dYQcAAAAElDIAQAAIAGFHAAAABJoiEK+evXqOOecc6K9vT26urri8ccfTz0lAAAAyLuQ33fffbFo0aJYtmxZbN26NaZPnx7d3d2xe/fu1FMDAACAfAv5nXfeGTfccENcf/31ccEFF8SaNWti1KhRcc8996SeGgAAAOR52bODBw/Gli1bYsmSJUfvGzZsWMydOzc2b9583DH9/f2V7Yi9e/f+7/0HXqt6/4cP9hWa96FDxS6fNNBX8DISfcUu61NrA/3/+3iWStVd7ugXZXv4tepzGij4mB3uLzbu0GvFLqE08Gqxx6rWBl4tnm09rNky6/ZnWbOR7bo9mTX7c7P9v+dMdXMptoYOHS62Zou+ThxugDU7pOv2lWKPdxGv9B4uNG7fwOGTWg/1LIc1W2bd/ixrtpis1m2pjj3//PPl2Zc2bdp0zP2LFy8uzZo167hjli1bVhljq9+tp6en0PNBtnlmK9f636zZfDfZ5rvJNs9Nrvluso2mzbal/J+oUzt37owzzzwzNm3aFLNnzz56/8033xwbN26Mxx577Bf+lGjPnj1x9tlnx7PPPhtjx46t2dwbwb59+6KzszN6enritNNOG/L9lZ9qvb290dHRUTnToVqyrc9cTzZbub5x1my+ZJunRns9LpPtG2PN5ku2+dpXp9nW9Snrp59+erS2tsaLL754zP3l2xMnTjzumLa2tsr208pPyFr9Y9hoyo9LrR6bk3lhkG395noy2cq1etZsvmSbp0Z5PS6TbXWs2XzJNl+n1Vm2df2hbiNGjIiZM2fGhg0bjt43MDBQuf36I+YAAADQaOr6CHlZ+ZJnCxYsiIsvvjhmzZoVq1atigMHDlQ+dR0AAAAaVd0X8quvvjpeeumlWLp0aezatStmzJgR69evjwkTJryh8eVTOMrXMD/eqRzNrtEfm0af/1Bp9Mel0ec/lBr9sWn0+Q+lRn9sGn3+QyWHxyWH/4eh0OiPS6PPfyg1+mPT6PNvxsemrj/UDQAAAHJV1+8hBwAAgFwp5AAAAJCAQg4AAAAJKOQAAACQQNaFfPXq1XHOOedEe3t7dHV1xeOPPx7Nbvny5dHS0nLMdv7550ejke3Pkm2+ZJsnueZLtvmSbb5yyFaujZlrtoX8vvvuq1zDvPzR9lu3bo3p06dHd3d37N69O5rdhRdeGC+88MLR7Xvf+140EtmemGzzJds8yTVfss2XbPPVyNnKtYFzLWVq1qxZpd/93d89evvw4cOljo6O0sqVK5POK7Vly5aVpk+fXmpksj0+2eZLtnmSa75kmy/Z5qvRs5Vr4+aa5RHygwcPxpYtW2Lu3LlH7xs2bFjl9ubNm6PZbdu2LTo6OuLcc8+Na6+9Np599tloFLL9+WSbL9nmSa75km2+ZJuvRs1Wro2da5aF/Cc/+UkcPnw4JkyYcMz95du7du2KZlZ+P8natWtj/fr1cffdd8eOHTvikksuid7e3mgEsj0x2eZLtnmSa75kmy/Z5quRs5VrY+c6PPUEqK158+Yd/f1FF11UeZKeffbZcf/998fHP/7xpHPj5Mg2X7LNk1zzJdt8yTZfss3TvAbINcsj5Keffnq0trbGiy++eMz95dsTJ05MNq96NG7cuJg2bVps3749GoFs3zjZ5ku2eZJrvmSbL9nmq5GylWtj55plIR8xYkTMnDkzNmzYcPS+gYGByu3Zs2cnnVu92b9/fzz99NMxadKkaASyfeNkmy/Z5kmu+ZJtvmSbr0bKVq4NnmspU/fee2+pra2ttHbt2tK//du/lRYuXFgaN25cadeuXaVm9tnPfrb0T//0T6UdO3aUvv/975fmzp1bOv3000u7d+8uNQrZHp9s8yXbPMk1X7LNl2zz1ejZyrVxc822kJf92Z/9WWny5MmlESNGVC4F8Oijj5aa3dVXX12aNGlS5TE588wzK7e3b99eajSy/VmyzZds8yTXfMk2X7LNVw7ZyrUxc20p/yf1UXoAAABoNlm+hxwAAADqnUIOAAAACSjkAAAAkIBCDgAAAAko5AAAAJCAQg4AAAAJKOQAAACQgEIOAFW49NJL48Ybb0w9DeANsmahsV2a+RoennoCANBI/u7v/i5OOeWU1NNgCL7hmzFjRqxatSr1VABoIgo5AFRh/PjxqacAwE85ePBgjBgxIvU0oGpOWa9zAwMDsXLlypgyZUqMHDkypk+fHl//+tdTT4uT8NJLL8XEiRPj85///NH7Nm3aVPlHZMOGDUnnxslZt25dvOlNb4r+/v5j7p8/f35cd911yebF4Mr91Llm9NGPfjQ2btwYX/rSl6KlpaWyPfPMM6mnBfyC1+JPfepTldfj008/Pbq7u1NPiUFw4MCB+MhHPhKnnnpqTJo0Kb74xS9G7hTyOlcu4+Vv8tesWRM//OEP4zOf+Ux8+MMfrnzjQGM644wz4p577only5fHE088Eb29vZWyVv5H5bLLLks9PU7CVVddFYcPH45vfOMbR+/bvXt3/MM//EN87GMfSzo34MTKRXz27Nlxww03xAsvvFDZOjs7U08L+AX++q//unJA4/vf/37le2Ua3+LFiys958EHH4xvf/vb8U//9E+xdevWyJlT1utY+Shb+Sjqww8/XPlGoezcc8+N733ve/EXf/EX8eu//uupp0hB73vf+yrf+F177bVx8cUXx+jRoys/fKGxlc9i+a3f+q34yle+UinnZV/72tdi8uTJlZ/kA/Vp7NixlW/qR40aVTmDCWgMU6dOjdtvvz31NBgk+/fvj7/6q7+qfO905CBV+YcuZ511VuRMIa9j27dvj1deeSXe8573/Mx7ZN7xjnckmxeD40/+5E/i7W9/e/zt3/5tbNmyJdra2lJPiUFQ/kHLr/7qr8bzzz8fZ555Zqxdu7ZyOmz5FFgAYPDMnDkz9RQYRE8//XSl53R1dR3zuS3nnXde5Ewhr/OfEpWVT3ctf2P/espbHi86O3furHxOQPm9ir/8y7+cekoMgvIPy8qf9VB+q8lv/MZvVN5qUl7DAMDgKp9hCI1OIa9jF1xwQaV4P/vss05Pz0z5p3/lzwK4+uqrKz/1+8QnPhE/+MEP4s1vfnPqqTEIynmWL51UPko+d+5c70WFBlA+Zb38GRAApPGWt7ylclnRxx57rPJ2v7L/+Z//iR/96EdZdyGFvI6NGTMmbrrppsoHuZWPos6ZMyf27t1b+eCK0047LRYsWJB6ihT0h3/4h5Us77rrrsqnSD700EOVD/365je/mXpqDILy+8jLa/cv//IvK0fKgfp3zjnnVL4JLJ+xVH5dLp8mOWyYz74FqJVTTz01Pv7xj1c+2K181Zrygary98y5vxbn/X+Xgf/3//5f3HrrrZUP/Hrb294W733veyunv5Yvg0ZjKn9aZPno6Ve/+tXKD1bKLzLl3//zP/9z3H333amnxyB9QNRv/uZvVv5hKV/yDKh/5R+itba2Vs5OK18No3x2GgC1dccdd8Qll1wSl19+eeUsw/IBydw/K6ClVCqVUk8CIDflTwe98MILK2dBAADA8SjkAIOo/F6n8lkQH/jAB+Lf/u3fsv9kUAAAivMecoBB/pT1cin/whe+oIwDAPBzOUIOAAAACfhQNwAAAEhAIQcAAIAEFHIAAABIQCEHAACABBRyAAAASEAhBwAAgAQUcgAAAEhAIQcAAIAEFHIAAACI2vv/G5Ceyat3LgUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x600 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,axes = plt.subplots(4,8,figsize=(12,6),sharex=True,sharey=True)\n",
    "for op,axe in zip(D4,axes.T):\n",
    "    ftfo = symmetry.transform_rep_idx(op, symmetry.FullRep)\n",
    "    q = atn.q(attrs.evolve(inp,space=inp.space[...,ftfo,:])).invariant[0,:,:,:,0]\n",
    "    for k,ax in enumerate(axe):\n",
    "        ax.pcolormesh(q[:,:,k])\n",
    "        if op==D4.e:\n",
    "            ax.set_ylabel(list(symmetry.AxialDirRep)[k].symbol)\n",
    "    ax.set_xlabel(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a4ada91a-6b02-47a3-8390-dcb1b74b97cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D4.i @invariant: max_diff=1.200e+01, rel_diff=0.00013\n",
      "D4.i @space: max_diff=1.600e+01, rel_diff=0.00084\n",
      "D4.i @flavour: max_diff=6.000e+00, rel_diff=0.00032\n"
     ]
    }
   ],
   "source": [
    "# verify the attention-weights match\n",
    "for axis, v in enumerate(eatnw):\n",
    "    a = tatnw[axis]\n",
    "    max_diff = np.abs(a - v).max()\n",
    "    rel_diff = (np.abs(a - v) / (np.abs(v) + 1e-8)).max()\n",
    "    bad = np.abs(a - v) > 1e-4*np.abs(v) + 1e-3\n",
    "    n_failed = int(bad.sum())\n",
    "    assert np.allclose(a, v, rtol=1e-4, atol=1e-3), (\n",
    "        f\"{op} @{axis} attention weights: {max_diff=:.3e}, {rel_diff=:.5f}, {n_failed=}/{v.size}\"\n",
    "    )\n",
    "\n",
    "# verify all representations match\n",
    "for k, v in expected.representations.items():\n",
    "    a = getattr(actual, k)\n",
    "    max_diff = np.abs(a - v).max()\n",
    "    rel_diff = (np.abs(a - v) / (np.abs(v) + 1e-8)).max()\n",
    "    bad = np.abs(a - v) > 1e-4*np.abs(v) + 1e-3\n",
    "    n_failed = int(bad.sum())\n",
    "    bad_idx = np.array(np.nonzero(bad)).T[:4]\n",
    "    bad_info = []\n",
    "    for idx in bad_idx:\n",
    "        idx = tuple(int(v) for v in idx)\n",
    "        av = a[idx]\n",
    "        ev = v[idx]\n",
    "        b, idx = idx[:n_batch_dims],idx[n_batch_dims:]\n",
    "        y,x = idx[:2]\n",
    "        c = idx[-1]\n",
    "        f = idx[2:-1]\n",
    "        match k:\n",
    "            case \"invariant\":\n",
    "                assert not f\n",
    "                f = \"\"\n",
    "            case \"space\":\n",
    "                f, = f\n",
    "                f = list(outf.rep.space)[f].symbol\n",
    "            case \"flavour\":\n",
    "                f, = f\n",
    "                f = str(f)\n",
    "        bad_info.append(f\"{b=} {y=} {x=} {f=} {c=}: expected {ev}, actual {av}, error {abs(ev-av)} ({abs(av-ev)/(abs(ev)+1e-8)} relative)\")\n",
    "    assert np.allclose(a, v, rtol=3e-3, atol=1e-3), (\n",
    "        f\"{op} @{k}: {max_diff=:.3e}, {rel_diff=:.5f}, {n_failed=}/{v.size}, bad:\\n{\"\\n\".join(bad_info)}\"\n",
    "    )\n",
    "    print(f\"{op} @{k}: {max_diff=:.3e}, {rel_diff=:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fdf704a1-33f5-4495-84b6-a3a8ec330fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symmetry.transform_rep_idx(op, symmetry.AxialDirRep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dd4ddb2f-c603-4331-95c8-97539c1413ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 0, 1]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[symmetry.AxialDirRep(v).apply(op).index for p in [\"↓↑\",\"→←\"]  for v in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a07c2ea3-ea41-497e-9d86-4b757a766599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SymDecompLinear( # Param: 28,104 (112.4 KB), RngState: 2 (12 B), Total: 28,106 (112.4 KB)\n",
       "  in_features=SymDecompDims(invariant=17, space=11, flavour=5, rep=RepSpec(space=<enum 'FullRep'>, n_flavours=10, symmetry_group=<enum 'D4'>)),\n",
       "  extra_in_reps=(),\n",
       "  out_features=SymDecompDims(invariant=156, space=276, flavour=36, rep=RepSpec(space=<enum 'TrivialRep'>, n_flavours=10, symmetry_group=<enum 'D4'>)),\n",
       "  extra_out_reps=(AxialDirRep,),\n",
       "  use_bias=False,\n",
       "  dtype=float32,\n",
       "  param_dtype=float32,\n",
       "  precision=None,\n",
       "  kernel_init=<function quant at 0x11e0bcae0>,\n",
       "  bias_init=<function quant at 0x11e0bcae0>,\n",
       "  dot_general=<function dot_general at 0x10cc27d80>,\n",
       "  promote_dtype=<function promote_dtype at 0x10ece11c0>,\n",
       "  rngs=Rngs( # RngState: 2 (12 B)\n",
       "    default=RngStream( # RngState: 2 (12 B)\n",
       "      tag='default',\n",
       "      key=RngKey( # 1 (8 B)\n",
       "        value=Array((), dtype=key<fry>) overlaying:\n",
       "        [ 0 42],\n",
       "        tag='default'\n",
       "      ),\n",
       "      count=RngCount( # 1 (4 B)\n",
       "        value=Array(38, dtype=uint32),\n",
       "        tag='default'\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       "  bias=None,\n",
       "  flavour_invariant=Dict({\n",
       "    'invariant': Dict({\n",
       "      'invariant': SpaceSymmetricLinear( # Param: 2,652 (10.6 KB)\n",
       "        in_reps=(),\n",
       "        in_features=17,\n",
       "        out_reps=(AxialDirRep,),\n",
       "        out_features=156,\n",
       "        symmetry_group=D4,\n",
       "        use_bias=False,\n",
       "        dtype=float32,\n",
       "        param_dtype=float32,\n",
       "        precision=None,\n",
       "        kernel_init=<function quant at 0x11e0bcae0>,\n",
       "        bias_init=<function quant at 0x11e0bcae0>,\n",
       "        dot_general=<function dot_general at 0x10cc27d80>,\n",
       "        promote_dtype=<function promote_dtype at 0x10ece11c0>,\n",
       "        bias=None,\n",
       "        kernel=SpaceSymmetricTensor( # Param: 2,652 (10.6 KB)\n",
       "          representations=(17, AxialDirRep, 156),\n",
       "          covariant=(True, False, False),\n",
       "          symmetry_group=D4,\n",
       "          dtype=float32,\n",
       "          init=<function quant at 0x11e0bcae0>,\n",
       "          mapping_info=SymmetryMappingSpec(symmetry_group=<enum 'D4'>, axes=(AxisSymmetryInfo(rep=AxialDirRep, covariant=False),), permutation_index=(4,), n_free_subspaces=1, fully_independent=False, fully_coupled=True),\n",
       "          transpose_dims=(1, 0, 2),\n",
       "          trivial_shape=(17, 156),\n",
       "          params=Param( # 2,652 (10.6 KB)\n",
       "            value=Array(shape=(1, 17, 156), dtype=dtype('float32'))\n",
       "          )\n",
       "        )\n",
       "      ),\n",
       "      'space': SpaceSymmetricLinear( # Param: 4,692 (18.8 KB)\n",
       "        in_reps=(),\n",
       "        in_features=17,\n",
       "        out_reps=(AxialDirRep, TrivialRep),\n",
       "        out_features=276,\n",
       "        symmetry_group=D4,\n",
       "        use_bias=False,\n",
       "        dtype=float32,\n",
       "        param_dtype=float32,\n",
       "        precision=None,\n",
       "        kernel_init=<function quant at 0x11e0bcae0>,\n",
       "        bias_init=<function quant at 0x11e0bcae0>,\n",
       "        dot_general=<function dot_general at 0x10cc27d80>,\n",
       "        promote_dtype=<function promote_dtype at 0x10ece11c0>,\n",
       "        bias=None,\n",
       "        kernel=SpaceSymmetricTensor( # Param: 4,692 (18.8 KB)\n",
       "          representations=(17, AxialDirRep, TrivialRep, 276),\n",
       "          covariant=(True, False, False, False),\n",
       "          symmetry_group=D4,\n",
       "          dtype=float32,\n",
       "          init=<function quant at 0x11e0bcae0>,\n",
       "          mapping_info=SymmetryMappingSpec(symmetry_group=<enum 'D4'>, axes=(AxisSymmetryInfo(rep=AxialDirRep, covariant=False), AxisSymmetryInfo(rep=TrivialRep, covariant=False)), permutation_index=(4, 1), n_free_subspaces=1, fully_independent=False, fully_coupled=True),\n",
       "          transpose_dims=(2, 0, 1, 3),\n",
       "          trivial_shape=(17, 276),\n",
       "          params=Param( # 4,692 (18.8 KB)\n",
       "            value=Array(shape=(1, 17, 276), dtype=dtype('float32'))\n",
       "          )\n",
       "        )\n",
       "      ),\n",
       "      'flavour': SpaceSymmetricLinear( # Param: 612 (2.4 KB)\n",
       "        in_reps=(),\n",
       "        in_features=17,\n",
       "        out_reps=(AxialDirRep,),\n",
       "        out_features=36,\n",
       "        symmetry_group=D4,\n",
       "        use_bias=False,\n",
       "        dtype=float32,\n",
       "        param_dtype=float32,\n",
       "        precision=None,\n",
       "        kernel_init=<function quant at 0x11e0bcae0>,\n",
       "        bias_init=<function quant at 0x11e0bcae0>,\n",
       "        dot_general=<function dot_general at 0x10cc27d80>,\n",
       "        promote_dtype=<function promote_dtype at 0x10ece11c0>,\n",
       "        bias=None,\n",
       "        kernel=SpaceSymmetricTensor( # Param: 612 (2.4 KB)\n",
       "          representations=(17, AxialDirRep, 36),\n",
       "          covariant=(True, False, False),\n",
       "          symmetry_group=D4,\n",
       "          dtype=float32,\n",
       "          init=<function quant at 0x11e0bcae0>,\n",
       "          mapping_info=SymmetryMappingSpec(symmetry_group=<enum 'D4'>, axes=(AxisSymmetryInfo(rep=AxialDirRep, covariant=False),), permutation_index=(4,), n_free_subspaces=1, fully_independent=False, fully_coupled=True),\n",
       "          transpose_dims=(1, 0, 2),\n",
       "          trivial_shape=(17, 36),\n",
       "          params=Param( # 612 (2.4 KB)\n",
       "            value=Array(shape=(1, 17, 36), dtype=dtype('float32'))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    }),\n",
       "    'space': Dict({\n",
       "      'invariant': SpaceSymmetricLinear( # Param: 6,864 (27.5 KB)\n",
       "        in_reps=(FullRep,),\n",
       "        in_features=11,\n",
       "        out_reps=(AxialDirRep,),\n",
       "        out_features=156,\n",
       "        symmetry_group=D4,\n",
       "        use_bias=False,\n",
       "        dtype=float32,\n",
       "        param_dtype=float32,\n",
       "        precision=None,\n",
       "        kernel_init=<function quant at 0x11e0bcae0>,\n",
       "        bias_init=<function quant at 0x11e0bcae0>,\n",
       "        dot_general=<function dot_general at 0x10cc27d80>,\n",
       "        promote_dtype=<function promote_dtype at 0x10ece11c0>,\n",
       "        bias=None,\n",
       "        kernel=SpaceSymmetricTensor( # Param: 6,864 (27.5 KB)\n",
       "          representations=(FullRep, 11, AxialDirRep, 156),\n",
       "          covariant=(True, True, False, False),\n",
       "          symmetry_group=D4,\n",
       "          dtype=float32,\n",
       "          init=<function quant at 0x11e0bcae0>,\n",
       "          mapping_info=SymmetryMappingSpec(symmetry_group=<enum 'D4'>, axes=(AxisSymmetryInfo(rep=FullRep, covariant=True), AxisSymmetryInfo(rep=AxialDirRep, covariant=False)), permutation_index=(8, 4), n_free_subspaces=4, fully_independent=False, fully_coupled=False),\n",
       "          transpose_dims=(0, 2, 1, 3),\n",
       "          trivial_shape=(11, 156),\n",
       "          params=Param( # 6,864 (27.5 KB)\n",
       "            value=Array(shape=(4, 11, 156), dtype=dtype('float32'))\n",
       "          )\n",
       "        )\n",
       "      ),\n",
       "      'space': SpaceSymmetricLinear( # Param: 12,144 (48.6 KB)\n",
       "        in_reps=(FullRep,),\n",
       "        in_features=11,\n",
       "        out_reps=(AxialDirRep, TrivialRep),\n",
       "        out_features=276,\n",
       "        symmetry_group=D4,\n",
       "        use_bias=False,\n",
       "        dtype=float32,\n",
       "        param_dtype=float32,\n",
       "        precision=None,\n",
       "        kernel_init=<function quant at 0x11e0bcae0>,\n",
       "        bias_init=<function quant at 0x11e0bcae0>,\n",
       "        dot_general=<function dot_general at 0x10cc27d80>,\n",
       "        promote_dtype=<function promote_dtype at 0x10ece11c0>,\n",
       "        bias=None,\n",
       "        kernel=SpaceSymmetricTensor( # Param: 12,144 (48.6 KB)\n",
       "          representations=(FullRep, 11, AxialDirRep, TrivialRep, 276),\n",
       "          covariant=(True, True, False, False, False),\n",
       "          symmetry_group=D4,\n",
       "          dtype=float32,\n",
       "          init=<function quant at 0x11e0bcae0>,\n",
       "          mapping_info=SymmetryMappingSpec(symmetry_group=<enum 'D4'>, axes=(AxisSymmetryInfo(rep=FullRep, covariant=True), AxisSymmetryInfo(rep=AxialDirRep, covariant=False), AxisSymmetryInfo(rep=TrivialRep, covariant=False)), permutation_index=(8, 4, 1), n_free_subspaces=4, fully_independent=False, fully_coupled=False),\n",
       "          transpose_dims=(0, 3, 1, 2, 4),\n",
       "          trivial_shape=(11, 276),\n",
       "          params=Param( # 12,144 (48.6 KB)\n",
       "            value=Array(shape=(4, 11, 276), dtype=dtype('float32'))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    }),\n",
       "    'flavour': Dict({\n",
       "      'invariant': SpaceSymmetricLinear( # Param: 780 (3.1 KB)\n",
       "        in_reps=(),\n",
       "        in_features=5,\n",
       "        out_reps=(AxialDirRep,),\n",
       "        out_features=156,\n",
       "        symmetry_group=D4,\n",
       "        use_bias=False,\n",
       "        dtype=float32,\n",
       "        param_dtype=float32,\n",
       "        precision=None,\n",
       "        kernel_init=<function quant at 0x11e0bcae0>,\n",
       "        bias_init=<function quant at 0x11e0bcae0>,\n",
       "        dot_general=<function dot_general at 0x10cc27d80>,\n",
       "        promote_dtype=<function promote_dtype at 0x10ece11c0>,\n",
       "        bias=None,\n",
       "        kernel=SpaceSymmetricTensor( # Param: 780 (3.1 KB)\n",
       "          representations=(5, AxialDirRep, 156),\n",
       "          covariant=(True, False, False),\n",
       "          symmetry_group=D4,\n",
       "          dtype=float32,\n",
       "          init=<function quant at 0x11e0bcae0>,\n",
       "          mapping_info=SymmetryMappingSpec(symmetry_group=<enum 'D4'>, axes=(AxisSymmetryInfo(rep=AxialDirRep, covariant=False),), permutation_index=(4,), n_free_subspaces=1, fully_independent=False, fully_coupled=True),\n",
       "          transpose_dims=(1, 0, 2),\n",
       "          trivial_shape=(5, 156),\n",
       "          params=Param( # 780 (3.1 KB)\n",
       "            value=Array(shape=(1, 5, 156), dtype=dtype('float32'))\n",
       "          )\n",
       "        )\n",
       "      ),\n",
       "      'flavour': SpaceSymmetricLinear( # Param: 180 (720 B)\n",
       "        in_reps=(),\n",
       "        in_features=5,\n",
       "        out_reps=(AxialDirRep,),\n",
       "        out_features=36,\n",
       "        symmetry_group=D4,\n",
       "        use_bias=False,\n",
       "        dtype=float32,\n",
       "        param_dtype=float32,\n",
       "        precision=None,\n",
       "        kernel_init=<function quant at 0x11e0bcae0>,\n",
       "        bias_init=<function quant at 0x11e0bcae0>,\n",
       "        dot_general=<function dot_general at 0x10cc27d80>,\n",
       "        promote_dtype=<function promote_dtype at 0x10ece11c0>,\n",
       "        bias=None,\n",
       "        kernel=SpaceSymmetricTensor( # Param: 180 (720 B)\n",
       "          representations=(5, AxialDirRep, 36),\n",
       "          covariant=(True, False, False),\n",
       "          symmetry_group=D4,\n",
       "          dtype=float32,\n",
       "          init=<function quant at 0x11e0bcae0>,\n",
       "          mapping_info=SymmetryMappingSpec(symmetry_group=<enum 'D4'>, axes=(AxisSymmetryInfo(rep=AxialDirRep, covariant=False),), permutation_index=(4,), n_free_subspaces=1, fully_independent=False, fully_coupled=True),\n",
       "          transpose_dims=(1, 0, 2),\n",
       "          trivial_shape=(5, 36),\n",
       "          params=Param( # 180 (720 B)\n",
       "            value=Array(shape=(1, 5, 36), dtype=dtype('float32'))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    })\n",
       "  }),\n",
       "  flavour_pointwise=SpaceSymmetricLinear( # Param: 180 (720 B)\n",
       "    in_reps=(),\n",
       "    in_features=5,\n",
       "    out_reps=(AxialDirRep,),\n",
       "    out_features=36,\n",
       "    symmetry_group=D4,\n",
       "    use_bias=False,\n",
       "    dtype=float32,\n",
       "    param_dtype=float32,\n",
       "    precision=None,\n",
       "    kernel_init=<function quant at 0x11e0bcae0>,\n",
       "    bias_init=<function quant at 0x11e0bcae0>,\n",
       "    dot_general=<function dot_general at 0x10cc27d80>,\n",
       "    promote_dtype=<function promote_dtype at 0x10ece11c0>,\n",
       "    bias=None,\n",
       "    kernel=SpaceSymmetricTensor( # Param: 180 (720 B)\n",
       "      representations=(5, AxialDirRep, 36),\n",
       "      covariant=(True, False, False),\n",
       "      symmetry_group=D4,\n",
       "      dtype=float32,\n",
       "      init=<function quant at 0x11e0bcae0>,\n",
       "      mapping_info=SymmetryMappingSpec(symmetry_group=<enum 'D4'>, axes=(AxisSymmetryInfo(rep=AxialDirRep, covariant=False),), permutation_index=(4,), n_free_subspaces=1, fully_independent=False, fully_coupled=True),\n",
       "      transpose_dims=(1, 0, 2),\n",
       "      trivial_shape=(5, 36),\n",
       "      params=Param( # 180 (720 B)\n",
       "        value=Array(shape=(1, 5, 36), dtype=dtype('float32'))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atn.q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1eba8ff-0ba4-4a4d-aa69-2ded76d14cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[32m/Users/yves/.pyenv/versions/3.13.7/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/jax/_src/numpy/array_methods.py\u001b[39m(\u001b[92m467\u001b[39m)\u001b[36m_compute_newshape\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[32m    465\u001b[39m     if (all(isinstance(d, int) for d in (*arr.shape, *other_sizes)) and\n",
      "\u001b[32m    466\u001b[39m         arr.size % math.prod(other_sizes) != \u001b[32m0\u001b[39m):\n",
      "\u001b[32m--> 467\u001b[39m       raise TypeError(f\"cannot reshape array of shape {arr.shape} (size {arr.size}) \"\n",
      "\u001b[32m    468\u001b[39m                       f\"into shape {orig_newshape} because the product of \"\n",
      "\u001b[32m    469\u001b[39m                       f\"specified axis sizes ({math.prod(other_sizes)}) does \"\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e61ec063-a0bf-427f-b094-6bbc3fdf08c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43masdf\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'asdf' is not defined"
     ]
    }
   ],
   "source": [
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5511f113-eba2-4ac1-8dd3-746f91e94dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "8*6+10*1-80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c81310f-dac0-4e78-8b1c-4a4071a66768",
   "metadata": {},
   "outputs": [],
   "source": [
    "qk = SymDecompLinear(\n",
    "    SymDecompDims(22*8,16,8),\n",
    "    SymDecompDims(22*4*3,24*3,4*3,rep=RepSpec(space=symmetry.AxialDirRep,n_flavours=10)),\n",
    "    use_bias=False,\n",
    "    rngs=nnx.Rngs(0),\n",
    ")\n",
    "pytree_structure(qk)\n",
    "\n",
    "v = SymDecompLinear(\n",
    "    SymDecompDims(22*8,16,8),\n",
    "    SymDecompDims(6*8,16,8),\n",
    "    extra_out_reps=(symmetry.AxialDirRep,),\n",
    "    rngs=nnx.Rngs(0),\n",
    ")\n",
    "pytree_structure(v)\n",
    "\n",
    "out = SymDecompLinear(\n",
    "    SymDecompDims(6*8,16,8),\n",
    "    SymDecompDims(22*8,16,8),\n",
    "    extra_in_reps=(symmetry.AxialDirRep,),\n",
    "    use_bias=False,\n",
    "    rngs=nnx.Rngs(0),\n",
    ")\n",
    "pytree_structure(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d05b34-c0d9-4ba4-8134-de9cb50818c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for spec in SymmetryMappingSpec._cache.values():\n",
    "    print(\n",
    "        f\"{\"[\"+\",\".join(f\"{ax.rep.__name__}:{\"co\" if ax.covariant else \"contra\"}\" for ax in spec.axes)+\"]\":64s}\"\n",
    "        f\" = {str(spec.permutation_index.shape):12s} {spec.n_free_subspaces:3d} ({spec.fully_coupled=:1} {spec.fully_independent=:1})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc87dae-dc9a-4644-83fa-362591a0f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_root = Path(\"..\").resolve()\n",
    "data_root = proj_root / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c231a9-b644-4e2c-8b58-0390f28bb7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with lzma.LZMAFile(data_root/\"repack/re-arc.cbor.xz\",\"rb\") as fh:\n",
    "    src_data = serialisation.deserialise(cbor2.load(fh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeadae7-4ff1-442f-94c9-993d49290d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "size_counts = np.zeros((31,31),int)\n",
    "for k,v in src_data.items():\n",
    "    for i,iop in enumerate(v):\n",
    "        for kk in [\"input\",\"output\"]:\n",
    "            vv = getattr(iop,kk)\n",
    "            if any(s>30 for s in vv.shape):\n",
    "                continue \n",
    "            h,w = vv.shape\n",
    "            size_counts[h,w] += 1\n",
    "\n",
    "plt.pcolormesh(size_counts,norm=\"log\")\n",
    "plt.axis(\"square\")\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b055ff8c-79ed-4e26-84a5-a2db1dd88d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "\n",
    "def brute(size_counts,N=4):\n",
    "    i = np.arange(0,31)\n",
    "    ccounts = np.cumsum(np.cumsum(size_counts,axis=0),axis=1)\n",
    "    ncells = i[:,None]*i\n",
    "    total_cells = size_counts*ncells\n",
    "    ccells = np.cumsum(np.cumsum(total_cells,axis=0),axis=1)\n",
    "    mx = 30\n",
    "    useful = ccells[mx,mx]\n",
    "    best, bestb = brute_impl(ccounts,mx,N)\n",
    "    return useful, best, bestb\n",
    "    \n",
    "@numba.njit\n",
    "def brute_impl(ccounts,mx,N):\n",
    "    best = 30**2*ccounts[-1,-1]\n",
    "    bestb = np.zeros(N,dtype=np.int_)\n",
    "    j = np.arange(N+1, dtype=np.int64)\n",
    "    j[-1] = mx\n",
    "    while True:\n",
    "        cc = ccounts[j,:][:,j]\n",
    "        bc = cc[1:]-cc[:-1]\n",
    "        bcnt = bc[:,1:]-bc[:,:-1]\n",
    "        bsz = j[1:,None]*j[1:]\n",
    "        spent = np.sum(bcnt*bsz)\n",
    "        if spent < best:\n",
    "            best = spent\n",
    "            bestb = j[1:].copy()\n",
    "\n",
    "        i = N-1\n",
    "        # find rightmost position that can be incremented\n",
    "        while i > 0 and j[i]+1 == j[i+1]:\n",
    "            i -= 1\n",
    "        if i <= 0:\n",
    "            # already at the last combination\n",
    "            break\n",
    "        j[i] += 1\n",
    "        # reset the tail to the minimal ascending values\n",
    "        while i+1<N:\n",
    "            j[i+1] = j[i] + 1\n",
    "            i += 1\n",
    "        \n",
    "    return best, bestb\n",
    "\n",
    "for N in range(2,8):\n",
    "    n_useful, n_spent, best = brute(size_counts, N=N)\n",
    "    print(f\"With {N=}, waste {(n_spent-n_useful)/1e6:.1f}/{n_spent/1e6:.1f} M (efficiency {100*n_useful/n_spent:.1f} %) with {best}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d849b25-dad7-461b-a0e4-97af2114f58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "#size_cuts = np.r_[11,17,24,30]\n",
    "size_cuts = np.r_[16,30]\n",
    "skipped = []\n",
    "for k,v in tqdm.auto.tqdm(src_data.items()):\n",
    "    for i,iop in enumerate(v):\n",
    "        for kk in [\"input\",\"output\"]:\n",
    "            vv = getattr(iop,kk)\n",
    "            if any(s>30 for s in vv.shape):\n",
    "                skipped.append(vv)\n",
    "                continue\n",
    "            gs = tuple(int(size_cuts[np.searchsorted(size_cuts,s)]) for s in vv.shape)\n",
    "            dataset.append(dict(\n",
    "                image = vv._data,\n",
    "                shape = vv.shape,\n",
    "                size = int(np.prod(vv.shape)),\n",
    "                grouping_shape = gs,\n",
    "                challenge = k,\n",
    "                type = kk,\n",
    "            ))\n",
    "print(f\"Skipped {len(skipped)} out of {len(skipped)+len(dataset)} due to out-of-range shape\")\n",
    "datasrc = pd.DataFrame(dataset)\n",
    "datasrc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8caa81-c37b-4578-a2ad-20eccd1d2b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_waste = 0\n",
    "total_cells = 0\n",
    "min_grp = 1000000\n",
    "for gs,grp in datasrc.groupby(\"grouping_shape\"):\n",
    "    s = gs[0]*gs[1]*grp.shape[0]\n",
    "    n = grp[\"size\"].sum()\n",
    "    util = n/s\n",
    "    waste = s-n\n",
    "    total_waste += waste\n",
    "    total_cells += n\n",
    "    min_grp = min(min_grp, grp.shape[0])\n",
    "    print(f\"Group {str(gs):8s} has {grp.shape[0]:6} with an average utilisation of {util*100:.0f} %, wasting {waste*1e-3:.1f}k cells\")\n",
    "print(f\"Total waste: {total_waste*1e-6:.1f}M cells vs {total_cells*1e-6:.1f}M useful cells\")\n",
    "print(f\"Maximum batch size / minimum group size: {min_grp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5953f000-c97a-4105-a73f-45d82ae9bf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xa\n",
    "\n",
    "challenge_index = pd.CategoricalIndex(sorted(datasrc.challenge.unique()))\n",
    "itype_index = pd.CategoricalIndex(sorted(datasrc.type.unique()))\n",
    "challenge_index, itype_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d45510-d366-4989-843e-73bc629dcbe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "padded_data = {}\n",
    "for gs,grp in datasrc.groupby(\"grouping_shape\"):\n",
    "    n = grp.shape[0]\n",
    "    images = np.zeros((n,)+gs,\"i1\")\n",
    "    sizes = np.zeros((n,2),int)\n",
    "    challenges = np.zeros((n,),int)\n",
    "    itype = np.zeros((n,),int)\n",
    "    for i,(_,row) in enumerate(grp.iterrows()):\n",
    "        h,w = row[\"shape\"]\n",
    "        images[i,:h,:w] = row.image\n",
    "        sizes[i,:] = h,w\n",
    "        challenges[i] = challenge_index.get_loc(row.challenge)\n",
    "        itype[i] = itype_index.get_loc(row.type)\n",
    "    data = xa.Dataset(\n",
    "        dict(\n",
    "            images = ((\"idx\",\"row\",\"col\"), images),\n",
    "            sizes = ((\"idx\",\"dim\"), sizes),\n",
    "            challenges = ((\"idx\",),challenges),\n",
    "            itype = ((\"idx\",),itype),\n",
    "        ),\n",
    "        coords = dict(\n",
    "            dim = pd.Index([\"row\",\"col\"]),\n",
    "        ),\n",
    "    )\n",
    "    padded_data[gs] = data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441c05cc-d8ec-4bdb-a8de-3d2333b0eda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(batch_size: int, rngs:nnx.Rngs):\n",
    "    weights = {}\n",
    "    for gs,data in padded_data.items():\n",
    "        weights[gs] = data.idx.size\n",
    "    logits = np.log(np.array(list(weights.values())))\n",
    "    keys = tuple(weights.keys())\n",
    "    rng = rngs\n",
    "    seen = set()\n",
    "    while True:\n",
    "        gs = keys[rng.categorical(logits)]\n",
    "        is_first_of_kind = gs not in seen\n",
    "        seen.add(gs)\n",
    "        data = padded_data[gs]\n",
    "        assert data.idx.size >= batch_size\n",
    "        i = set()\n",
    "        while len(i) < batch_size:\n",
    "            j = rng.randint((batch_size-len(i),),0,data.idx.size)\n",
    "            i.update(int(v) for v in j)\n",
    "        i = np.array(sorted(i))\n",
    "        images = data.images.to_numpy()[i]\n",
    "        sizes = data[\"sizes\"].to_numpy()[i]\n",
    "        labels = data.challenges.to_numpy()[i]\n",
    "        yield dict(\n",
    "            inputs = dict(image=images, size=sizes),\n",
    "            label = labels,\n",
    "        ), is_first_of_kind, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beebdf2-e4ab-4908-943a-21cc6826bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2820c741-633e-4a27-b768-8aca53432dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class ModelConfig:\n",
    "    num_classes: int = 1000\n",
    "    embed_dim: int = 256\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainConfig:\n",
    "    \"\"\"Configuration for the training script.\"\"\"\n",
    "    seed: int = 42\n",
    "    global_batch_size: int = 128  # across all devices\n",
    "    ref_batch: int = 1024 # all learning rates refer to this batch size\n",
    "    ref_epoch: int = 800000 # number of images that we call one epoch in reporting\n",
    "    # Optimiser\n",
    "    learning_rate: float = 3e-4\n",
    "    betas: tuple[float, float] = (0.9, 0.999)\n",
    "    eps: float = 1e-8\n",
    "    weight_decay: float = 0.05\n",
    "    grad_clip_norm: float = 1.0\n",
    "    # Schedule    \n",
    "    # in units of ref_batch images!\n",
    "    num_train_steps: int = 1000\n",
    "    warmup_steps: float = 10\n",
    "    log_every_steps: int = 50\n",
    "\n",
    "    # TODO: EMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9fef38-c371-43f1-a1c5-0b8850239c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TrainState(nnx.Module):\n",
    "    \"\"\"A frozen dataclass to hold the training state.\"\"\"\n",
    "    config: TrainConfig = dataclasses.field(metadata=dict(static=True))\n",
    "    model: nnx.Module\n",
    "    optimizer: nnx.Optimizer\n",
    "    # ema_params: nnx.Params\n",
    "\n",
    "    @classmethod\n",
    "    def make(\n",
    "        cls,\n",
    "        model: nnx.Module,\n",
    "        config: TrainConfig,\n",
    "        *,\n",
    "        rngs: nnx.Rngs,\n",
    "    ) -> typing.Self:\n",
    "        \"\"\"Initializes the model, optimizer, and the combined training state.\"\"\"\n",
    "\n",
    "        step_scale = config.ref_batch / config.global_batch_size\n",
    "        epoch_scale = config.ref_epoch / config.global_batch_size\n",
    "        # Create the learning rate schedule (warmup + cosine decay is standard for ViTs)\n",
    "        # with Linear LR scaling\n",
    "        lr = config.learning_rate / step_scale\n",
    "        zero_lr = lr * 0.001\n",
    "        lr_schedule = optax.warmup_cosine_decay_schedule(\n",
    "            init_value=zero_lr,\n",
    "            peak_value=config.learning_rate,\n",
    "            warmup_steps=int(round(config.warmup_steps*step_scale)),\n",
    "            decay_steps=int(round((config.num_train_steps - config.warmup_steps)*step_scale)),\n",
    "            end_value=zero_lr,\n",
    "        )\n",
    "    \n",
    "        # Create the AdamW optimizer with gradient clipping\n",
    "        tx = optax.chain(\n",
    "            optax.clip_by_global_norm(config.grad_clip_norm),\n",
    "            optax.adamw(\n",
    "                learning_rate=lr_schedule,\n",
    "                weight_decay=config.weight_decay,\n",
    "                b1=config.betas[0],\n",
    "                b2=config.betas[1], \n",
    "                eps=config.eps,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self = cls()\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.optimizer = nnx.Optimizer(model, tx, wrt=nnx.Param)\n",
    "        self.stats = {k:nnx.Variable(0) for k in [\"steps\",\"examples\"]}\n",
    "\n",
    "        return self\n",
    "\n",
    "    def model_stats(self):\n",
    "        stats = {}\n",
    "        for k in [\"model\",\"optimizer\"]:\n",
    "            _, v = nnx.split(getattr(self, k))\n",
    "            leaves = jax.tree_util.tree_leaves(v)\n",
    "            total_params = sum((leaf.size for leaf in leaves), start=0)\n",
    "            total_bytes = sum((leaf.nbytes for leaf in leaves), start=0)\n",
    "            stats[k] = SimpleNamespace(params=total_params,bytes=total_bytes)\n",
    "        \n",
    "        return SimpleNamespace(**stats)\n",
    "\n",
    "    @classmethod\n",
    "    def loss_fn(cls, model, batch, **kw):\n",
    "        inputs = batch[\"inputs\"]\n",
    "        logits = model(inputs[\"image\"], inputs[\"size\"], **kw)\n",
    "        loss = optax.softmax_cross_entropy_with_integer_labels(\n",
    "            logits=logits, labels=batch[\"label\"],\n",
    "            #label_smoothing=cfg.label_smoothing,\n",
    "        ).mean()\n",
    "        accuracy = jnp.mean(jnp.argmax(logits, axis=-1) == batch[\"label\"])\n",
    "        return loss, dict(loss=loss, accuracy=accuracy)\n",
    "\n",
    "    def batch_stats(self, batch_size:int|None=None,shape:tuple[int,int] = (30,30)):\n",
    "        graph, state = nnx.split(self)\n",
    "        def inference(state, batch):\n",
    "            state = nnx.merge(graph, state)\n",
    "            model = state.model\n",
    "            model.eval()\n",
    "            inputs = batch[\"inputs\"]\n",
    "            return model(inputs[\"image\"], inputs[\"size\"])\n",
    "        def train(state, batch):\n",
    "            state = nnx.merge(graph, state)\n",
    "            model = state.model\n",
    "            model.train()\n",
    "            def loss_fn(model):\n",
    "                return self.loss_fn(model, batch)\n",
    "            grad_fn = nnx.value_and_grad(loss_fn, has_aux=True)\n",
    "            (_, stats), grads = grad_fn(model)\n",
    "\n",
    "            # Update optimizer state and compute new parameters\n",
    "            state.optimizer.update(state.model, grads)\n",
    "            _, state = nnx.split(state)\n",
    "            return state, stats\n",
    "            \n",
    "        if batch_size is None:\n",
    "            batch_size = self.config.global_batch_size\n",
    "        batch = dict(\n",
    "            inputs = dict(\n",
    "                image = np.zeros((batch_size,)+shape,\"i1\"),\n",
    "                size = np.tile(shape,(batch_size,1)),\n",
    "            ),\n",
    "            # TODO: num classes!\n",
    "            label = np.arange(batch_size,dtype=int)%400,\n",
    "        )\n",
    "        stats = {}\n",
    "        for k,fun in dict(\n",
    "            inference=inference,\n",
    "            train=train,\n",
    "        ).items():\n",
    "            # Analyze the forward pass function\n",
    "            jfun = jax.jit(fun)\n",
    "            tfun = jfun.trace(state, batch)\n",
    "            cfun = tfun.lower()#.compile()\n",
    "            cost = cfun.cost_analysis()\n",
    "            stats[k] = SimpleNamespace(\n",
    "                flops = cost.get(\"flops\"),\n",
    "                bytes_accessed = cost.get(\"bytes accessed\"),\n",
    "                bytes_out = cost.get(\"bytes accessedout\"),\n",
    "            )\n",
    "            \n",
    "        return SimpleNamespace(**stats)\n",
    "\n",
    "    def train_step(self, batch, num_devices, **kw):\n",
    "        @nnx.split_rngs(splits=num_devices)\n",
    "        def wrapper(state, batch):\n",
    "            return state._parallel_train_step(batch, tuple(sorted(kw.items())))\n",
    "\n",
    "        batch = jax.tree.map(lambda x:x.reshape(num_devices,-1,*x.shape[1:]), batch)\n",
    "        stats = wrapper(self, batch)\n",
    "\n",
    "        # TODO: this one probably defeats latency hiding\n",
    "        stats = jax.device_get(jax.tree.map(lambda x: x[0], stats))\n",
    "        self.stats[\"steps\"] += 1\n",
    "        self.stats[\"examples\"] += batch[\"label\"].shape[0]\n",
    "        stats.update({k:v.value for k,v in self.stats.items()})\n",
    "        return stats\n",
    "\n",
    "        \n",
    "    @nnx.pmap(\n",
    "        axis_name=\"data\",\n",
    "        in_axes=(nnx.StateAxes({('data',nnx.RngKey,nnx.RngCount): 0, ...: None}),0,None),\n",
    "        static_broadcasted_argnums=2,\n",
    "    )\n",
    "    def _parallel_train_step(self, batch, kw):\n",
    "        def loss_fn(model):\n",
    "            return self.loss_fn(model, batch, **dict(kw))\n",
    "\n",
    "        grad_fn = nnx.value_and_grad(loss_fn, has_aux=True)\n",
    "        (_, stats), grads = grad_fn(self.model)\n",
    "\n",
    "        grads = jax.lax.pmean(grads, axis_name='data')\n",
    "        stats = jax.lax.pmean(stats, axis_name='data')\n",
    "        \n",
    "        self.optimizer.update(self.model, grads)\n",
    "        return stats        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7de7ffd-0929-4f3e-b4c7-909087fa4e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "def main(model, config: TrainConfig, **kw):\n",
    "    \"\"\"The main entry point for the training script.\"\"\"\n",
    "    # Detect available devices (GPUs/TPUs)\n",
    "    num_devices = jax.local_device_count()\n",
    "    is_multi_device = num_devices > 1\n",
    "\n",
    "    per_device_batch_size = config.global_batch_size // num_devices\n",
    "    config = dataclasses.replace(config, global_batch_size=per_device_batch_size*num_devices)\n",
    "\n",
    "    step_scale = config.ref_batch / config.global_batch_size\n",
    "    epoch_scale = config.ref_epoch / config.global_batch_size\n",
    "    \n",
    "    print(f\"--- ARC ViT Pre-training ---\")\n",
    "    print(f\"Detected {num_devices} devices: {jax.devices()}\")\n",
    "    print(f\"Mode: {'Single-device' if not is_multi_device else 'Multi-device (DDP)'}\")\n",
    "    print(f\"Per-device batch size: {per_device_batch_size}\")\n",
    "    print(f\"Global batch size: {config.global_batch_size}\")\n",
    "    print(\"----------------------------\\n\")\n",
    "\n",
    "    # Setup PRNG key\n",
    "    rngs = nnx.Rngs(config.seed)\n",
    "\n",
    "    # 1. Setup Data Pipeline\n",
    "    # ...\n",
    "\n",
    "    # 2. Initialize Training State\n",
    "    state = TrainState.make(\n",
    "        model,\n",
    "        config,\n",
    "        rngs=rngs,\n",
    "    )\n",
    "    \n",
    "    # 4. Start the training loop\n",
    "    print(\"Starting training...\")\n",
    "    start_time = time.monotonic()\n",
    "    prev_images = jit_imgs = 0\n",
    "    prev_elapsed = jit_time = 0\n",
    "    \n",
    "    # Get an iterator for the dataset\n",
    "    ds_iter = iter(make_dataset(config.global_batch_size, rngs=rngs))\n",
    "\n",
    "    try:\n",
    "        was_warmup = True\n",
    "        stats = {}\n",
    "        for step in (pbar := tqdm.auto.trange(int(round(config.num_train_steps*step_scale)))):\n",
    "            # Fetch the next batch of data\n",
    "            batch,is_first_of_kind,epoch = next(ds_iter)\n",
    "            \n",
    "            # Execute one parallel training step\n",
    "            s = state.train_step(batch, num_devices, **kw)\n",
    "    \n",
    "            elapsed_time = time.monotonic() - start_time\n",
    "            images = (step+1)*config.global_batch_size\n",
    "            if is_first_of_kind:\n",
    "                jit_time += elapsed_time - prev_elapsed\n",
    "                jit_imgs += images - prev_images\n",
    "            prev_elapsed = elapsed_time\n",
    "            prev_images = images\n",
    "            images_per_sec = (images-jit_imgs) / (elapsed_time-jit_time) if elapsed_time>jit_time+1 else images/elapsed_time\n",
    "            info = dict(\n",
    "                #step=step,\n",
    "                epoch = epoch,\n",
    "                refstep = images/config.ref_batch,\n",
    "                refepoch= images/config.ref_epoch,\n",
    "                images = images,\n",
    "                images_per_sec=images_per_sec,\n",
    "                seconds_per_epoch=config.ref_epoch/images_per_sec,\n",
    "                **s\n",
    "            )\n",
    "            for k,v in info.items():\n",
    "                stats.setdefault(k,[]).append(v)\n",
    "            pbar.set_postfix(**{\n",
    "                dict(images_per_sec=\"ips\").get(k,k):f\"{info[k]:.{v}f}\"\n",
    "                for k,v in dict(\n",
    "                    loss=2,\n",
    "                    accuracy=3,\n",
    "                    images_per_sec=2,\n",
    "                    refepoch=2,\n",
    "                    epoch=0,\n",
    "                    refstep=2,\n",
    "                ).items()\n",
    "            })\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    print(\"\\n--- Training Finished ---\")\n",
    "    stats = {k:np.array(v) for k,v in stats.items()}\n",
    "    stats = pd.DataFrame(stats)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b712b82e-10cd-4da2-befa-6ce1d0914c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc25.lib.attrs import AttrsModule\n",
    "\n",
    "class Latents(AttrsModule):\n",
    "    mono: SymDecomp  # shape ... N R? Cm\n",
    "    colour: SymDecomp  # shape ... M F R? Cf\n",
    "\n",
    "    @property\n",
    "    def projections(self):\n",
    "        return dict(mono=self.mono,colour=self.colour)\n",
    "\n",
    "    def map_projections(\n",
    "        self, fun: typing.Callable[[SymDecomp], SymDecomp], *other: Self, **kw\n",
    "    ) -> Self:\n",
    "        return attrs.evolve(\n",
    "            self,\n",
    "            **{\n",
    "                k: fun(v, *[getattr(o, k) for o in other], **kw)\n",
    "                for k, v in self.projections.items()\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def map_representations(\n",
    "        self, fun: typing.Callable[[jt.Float], jt.Float], *other: Self, **kw\n",
    "    ) -> Self:\n",
    "        return attrs.evolve(\n",
    "            self,\n",
    "            **{\n",
    "                k: v.map_representations(fun, *[getattr(o, k) for o in other], **kw)\n",
    "                for k, v in self.projections.items()\n",
    "            },\n",
    "        )\n",
    "\n",
    "class PerceiverXAttnLayer(nnx.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_heads: int,\n",
    "        hidden_size: FieldDims,\n",
    "        latent_size: SymDecompDims,\n",
    "        qkv_features: int,\n",
    "        *,\n",
    "        global_mix_reduction: int = 4,\n",
    "        num_groups: int | None = None,\n",
    "        dtype: Dtype | None = None,\n",
    "        param_dtype: Dtype = jnp.float32,\n",
    "        attention_dtype: Dtype | None = None,\n",
    "        # broadcast_dropout: bool = True,\n",
    "        dropout_rate: float = 0.0,\n",
    "        deterministic: bool = False,\n",
    "        precision: PrecisionLike = None,\n",
    "        kernel_init: Initializer = default_kernel_init,\n",
    "        # out_kernel_init: Initializer | None = None,\n",
    "        bias_init: Initializer = default_bias_init,\n",
    "        # out_bias_init: Initializer | None = None,\n",
    "        use_bias: bool = True,\n",
    "        hdrs_attend: bool = False,\n",
    "        # attention_fn: Callable[..., Array] = dot_product_attention,\n",
    "        normalize_qk: bool = False,\n",
    "        keep_rngs: bool = True,\n",
    "        rngs: rnglib.Rngs,        \n",
    "    ):\n",
    "        def make_linear(inf, outf, *, cls=SymmetricLinear):\n",
    "            # TODO: do we have all relevant parameters?\n",
    "            return cls(\n",
    "                inf,\n",
    "                outf,\n",
    "                dtype=dtype,\n",
    "                param_dtype=param_dtype,\n",
    "                kernel_init=kernel_init,\n",
    "                bias_init=bias_init,\n",
    "                use_bias=use_bias,\n",
    "                precision=precision,\n",
    "                rngs=rngs,\n",
    "            )\n",
    "        self.n_features = n_features = qkv_features // num_heads\n",
    "        nkv = 2 * num_groups * n_features\n",
    "        nv = num_groups * n_features\n",
    "        self.kv = hidden_size.map_projections(\n",
    "            lambda k, v: make_linear(\n",
    "                v,\n",
    "                attrs.evolve(v, inv=nkv, equiv=nv),\n",
    "            ),\n",
    "            cls=dict,\n",
    "        )\n",
    "        nq = num_heads * n_features\n",
    "        self.q = latent_size.map_projections(\n",
    "            lambda k, v: make_linear(\n",
    "                v,\n",
    "                attrs.evolve(v, inv=nq, equiv=0),\n",
    "            ),\n",
    "            cls=dict,\n",
    "        )\n",
    "\n",
    "    def __call__(self, hidden: Field, latent: Latents) -> Latents:\n",
    "        assert self.hidden_size.validate(\n",
    "            hidden\n",
    "        ), self.hidden_size.validation_problems(features)\n",
    "        assert hidden.context.rep == hidden.cells.rep\n",
    "\n",
    "        R = hidden.cells.rep.dim\n",
    "        batch = hidden.cells.equiv.shape[:-5]\n",
    "        B = int(np.prod(batch))\n",
    "        Y, X, F = hidden.cells.equiv.shape[-5:-2]\n",
    "        H = self.n_features\n",
    "        D = H\n",
    "        K = self.num_groups\n",
    "        N = self.num_heads\n",
    "\n",
    "        inputs = [\n",
    "            r for p in hidden.projections.values() for r in p.representations.values()\n",
    "        ] + [\n",
    "            r for p in latent.projections.values() for r in p.representations.values()\n",
    "        ]\n",
    "        dtype = nnx.nn.dtypes.canonicalize_dtype(*inputs, dtype=self.dtype)\n",
    "        attention_dtype = nnx.nn.dtypes.canonicalize_dtype(\n",
    "            *inputs, dtype=self.attention_dtype\n",
    "        )\n",
    "        attention_dtype = jnp.promote_types(attention_dtype, jnp.float32)\n",
    "\n",
    "        precision = self.precision\n",
    "\n",
    "        # first; input projections\n",
    "        qkv = {}\n",
    "        for proj,src,tgt in [(self.q, latent, \"Q\"),(self.kv, hidden, \"KV\")]:\n",
    "            for k, v in proj.items():\n",
    "                inp = getattr(src, k)\n",
    "                out = v(inp)\n",
    "                rep = out.rep\n",
    "                equiv = out.equiv\n",
    "                inv = out.inv\n",
    "    \n",
    "                d = qkv.setdefault(k,{})\n",
    "                for kk in tgt:\n",
    "                    n = dict(Q=N * H, K=K * H, V=K * D)[kk]\n",
    "                    if kk in \"QK\":\n",
    "                        maybe_cast = lambda v: v.astype(attention_dtype)\n",
    "                    else:\n",
    "                        # jax.nn.dot_product_attention does not support mixed precision\n",
    "                        maybe_cast = lambda v: v.astype(attention_dtype)\n",
    "                    e = maybe_cast(equiv[..., :n])\n",
    "                    # print(f\"equiv {k}.{kk}.shape = {d[kk].shape}\")\n",
    "                    equiv = equiv[..., n:]\n",
    "                    i = maybe_cast(inv[..., :n])\n",
    "                    # print(f\"inv {k}.{kk}.shape = {di[kk].shape}\")\n",
    "                    inv = inv[..., n:]\n",
    "                    d[kk] = SymDecomp(inv=i,equiv=e,rep=rep)\n",
    "                assert not inv.size, f\"{k}: {inv.shape=}\"\n",
    "                assert not equiv.size\n",
    "        qkv = SimpleNamespace(**{k:SimpleNamespace(**v) for k,v in qkv.items()})\n",
    "\n",
    "        # second; X-attn to row/col headers (only mono)\n",
    "        hdr_attn = []\n",
    "        for axis in range(2):\n",
    "            hdr = [qkv.cols, qkv.rows][axis]\n",
    "            out = jax.nn.dot_product_attention(\n",
    "                query=jnp.swapaxes(qkv.mono.Q.inv[:, :1, :, :, :], -3, -4).reshape(\n",
    "                    B * F, 1, N, 2 * H\n",
    "                ),\n",
    "                key=jnp.swapaxes(efc.K, -3, -4).reshape(B * F, Y * X + 1, K, 2 * H),\n",
    "                value=jnp.swapaxes(efc.V, -3, -4).reshape(B * F, Y * X + 1, K, D),\n",
    "                mask=jnp.concatenate(\n",
    "                    [\n",
    "                        # TODO: should we self-attend here?\n",
    "                        jnp.zeros((B * F, 1, 1, 1), bool),\n",
    "                        jnp.tile(features.mask, (F, 1)).reshape(-1, 1, 1, Y * X),\n",
    "                    ],\n",
    "                    axis=-1,\n",
    "                ),\n",
    "            ).astype(dtype)\n",
    "            hdr_attn.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847c36d2-3558-4cec-91b0-2beeec1703a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = FieldDims.make(\n",
    "    inv_fac = 2,\n",
    "    context = 32,\n",
    "    hdrs = 16,\n",
    "    cells = 16,\n",
    ")\n",
    "arc_cls = ARCClassifier(\n",
    "    hidden_size = dims,\n",
    "    mha_features = 24*2,\n",
    "    mlp_width_factor = 2,\n",
    "    num_heads = 2,\n",
    "    num_groups = 1,\n",
    "    num_classes = 400,\n",
    "    num_layers = 8,\n",
    "    rngs = nnx.Rngs(0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cf7fff-a6e3-4c39-ba76-d99006f0bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TrainConfig(\n",
    "    global_batch_size = 16,\n",
    "    num_train_steps = 1000,\n",
    "    warmup_steps = 5,\n",
    "    learning_rate = 3e-4,\n",
    "    weight_decay = 0.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d1c7bd-c02c-47cd-a987-f9ea1c19a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import humanize\n",
    "\n",
    "if True:\n",
    "    layer = arc_cls.encoder.blocks\n",
    "    gs,state = nnx.split(layer)\n",
    "    state = jax.tree.map(lambda v:v[0],state)\n",
    "    layer = nnx.merge(gs,state)\n",
    "    \n",
    "    x = dims.make_empty(batch=(1,),shape=(30,30),flavours=11)\n",
    "    def test_fun(model,x,**kw):\n",
    "        return model(x,**kw)\n",
    "    def unpack(obj,path=()):\n",
    "        match obj:\n",
    "            case SimpleNamespace():\n",
    "                yield from unpack(vars(obj),path)\n",
    "            case dict():\n",
    "                for k,v in obj.items():\n",
    "                    yield from unpack(v,path+(k,))\n",
    "            case SymmetricLinear():\n",
    "                yield path,obj.approximate_flops\n",
    "            case nnx.Linear():\n",
    "                yield path,obj.kernel.size\n",
    "            case _:\n",
    "                print(f\"Ignoring {type(obj).__name__}\")\n",
    "    attn = layer.attn\n",
    "    tot = 0\n",
    "    for k,v in unpack(dict(mix=attn.cell_global_mix,qkv=attn.qkv,out=attn.out)):\n",
    "        F = 11\n",
    "        N = 30\n",
    "        fac = dict(\n",
    "            mix=F,\n",
    "            context=F,\n",
    "            rows=F*N,\n",
    "            cols=F*N,\n",
    "            cells=F*N*N,\n",
    "        ).get(k[-1])\n",
    "        tot += v*fac\n",
    "        print(f\"{'.'.join(k)}: {humanize.naturalsize(v*fac)}\")\n",
    "    print(f\"Total attention projections: {humanize.naturalsize(tot)}\")\n",
    "    compiled = nnx.jit(test_fun).trace(layer.attn,x,deterministic=True).lower().compile()\n",
    "    print(f\"Total attn: {humanize.naturalsize(compiled.cost_analysis()[\"flops\"])}\")\n",
    "    compiled = nnx.jit(test_fun).trace(layer.mlp,x,rngs=nnx.Rngs(0)).lower().compile()\n",
    "    print(f\"Total MLP: {humanize.naturalsize(compiled.cost_analysis()[\"flops\"])}\")\n",
    "    compiled = nnx.jit(test_fun).trace(layer,x,rngs=nnx.Rngs(0)).lower().compile()\n",
    "    print(f\"Total Layer: {humanize.naturalsize(compiled.cost_analysis()[\"flops\"])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254284da-1dac-4958-8642-041bea326a38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import humanize\n",
    "\n",
    "def print_stats(stats,path=()):\n",
    "    for k,v in vars(stats).items():\n",
    "        p = path+(k,)\n",
    "        if isinstance(v, SimpleNamespace):\n",
    "            print_stats(v, p)\n",
    "            continue\n",
    "        if v is None:\n",
    "            continue\n",
    "        if p[0] == \"model\":\n",
    "            va = {\"\":v}\n",
    "        else:\n",
    "            va = dict(batch=v,example=v/config.global_batch_size)\n",
    "        msg = []\n",
    "        for kk,vv in va.items():\n",
    "            if \"bytes\" in k:\n",
    "                n = humanize.naturalsize(vv,binary=True)\n",
    "            else:\n",
    "                n = humanize.naturalsize(vv,gnu=True,format=\"%.1f \")\n",
    "                if n.endswith(\"B\"):\n",
    "                    n = n[:-1]+\" \"\n",
    "            if \"flops\" in k:\n",
    "                n += \"FLOPs\"\n",
    "            if kk:\n",
    "                n += f\" ({kk})\"\n",
    "            msg.append(n)\n",
    "        n = \"\".join(f\"{n:25s}\" for n in msg)\n",
    "        print(f\"{'.'.join(p):32s}: {n}\")\n",
    "\n",
    "\n",
    "ts = TrainState.make(model=arc_cls, config=config, rngs=nnx.Rngs(0))\n",
    "stats = SimpleNamespace(model=ts.model_stats(),batch=ts.batch_stats())\n",
    "leaves = [\n",
    "    a for p in dims.make_empty(\n",
    "        batch=(config.global_batch_size,),\n",
    "        shape=(30,30),\n",
    "        flavours=11,\n",
    "    ).projections.values() for a in p.representations.values()\n",
    "]\n",
    "stats.fields = SimpleNamespace(params=sum(a.size for a in leaves),bytes=sum(a.nbytes for a in leaves))\n",
    "print_stats(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb2cae-8adb-437a-ae5a-6eed6451f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = main(arc_cls, config, remat=True, unroll=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4fd383-a3ff-46ac-8965-c906a4d0f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "\n",
    "def filt(signal, filter_width = 50):\n",
    "    signal = ndimage.uniform_filter1d(signal, filter_width, mode=\"constant\")\n",
    "    signal /= ndimage.uniform_filter1d(np.ones_like(signal), filter_width, mode=\"constant\")\n",
    "    return signal\n",
    "\n",
    "fig,axes = plt.subplots(2,1,figsize=(8,8))\n",
    "ax = axes[0]\n",
    "ax.semilogy(stats.refstep, filt(stats.loss))\n",
    "ax = axes[1]\n",
    "ax.plot(stats.refstep, filt(stats.accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ac2226-c964-49c9-b435-7bde74ee485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import msgpack\n",
    "import lzma\n",
    "import anyio\n",
    "import pickle\n",
    "\n",
    "asdfasd\n",
    "\n",
    "async with await anyio.open_file(data_root/\"arc-vision-model.msgpack.xz\",\"wb\") as fh:\n",
    "    compressor = lzma.LZMACompressor()\n",
    "    \n",
    "    async def write(*data):\n",
    "        serialised = msgpack.dumps(tuple(data))\n",
    "        compressed = await anyio.to_thread.run_sync(compressor.compress,serialised)\n",
    "        await fh.write(compressed)\n",
    "    \n",
    "    graphdef,flatstate = nnx.graph.flatten(nnx.pure(nnx.state(arc_cls, nnx.Param)))\n",
    "    await write(\"G\",pickle.dumps(graphdef))\n",
    "    pointer = ()\n",
    "    for path,s in tqdm.auto.tqdm(flatstate):\n",
    "        pstr = \".\".join(str(v) for v in path)\n",
    "        assert isinstance(s, jaxlib._jax.ArrayImpl)\n",
    "        d = np.asarray(jax.device_get(s))\n",
    "        neq = 0\n",
    "        for i,(a,b) in enumerate(zip(pointer, path)):\n",
    "            neq = i\n",
    "            if a != b:\n",
    "                break\n",
    "        key = (neq,path[neq:])\n",
    "        await write(\"A\",neq,path[neq:],d.shape,str(d.dtype),bytes(d.data))\n",
    "        pointer = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a405c6-492d-44cd-8b07-68638528ad0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
