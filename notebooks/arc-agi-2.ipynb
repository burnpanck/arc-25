{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import typing\n",
    "import contextlib\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# Available: https://github.com/kaggle/docker-python\n",
    "import jax\n",
    "from flax import nnx\n",
    "import attrs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import kagglehub\n",
    "import IPython\n",
    "from kauldron import kd\n",
    "\n",
    "ipython = IPython.get_ipython()\n",
    "# Avoid memory fragmentation on JAX backend.\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CpuDevice(id=0)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n"
     ]
    }
   ],
   "source": [
    "def detect_run_env() -> typing.Literal[\"interactive\", \"batch\", \"local\", \"unknown\"]:\n",
    "    if not Path(\"/kaggle\").exists():\n",
    "        return \"local\"\n",
    "\n",
    "    run_type = os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\", \"\").strip().lower()\n",
    "    if run_type in {\"interactive\",\"batch\"}:\n",
    "        return run_type\n",
    "    raise KeyError(f\"Unknown kaggle run type {run_type!r}\")\n",
    "\n",
    "run_env = detect_run_env()\n",
    "print(run_env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_env != \"local\":\n",
    "    ipython.magic('pip install \"git+https://github.com/google-deepmind/gemma.git@v3.1.0\" \"etils[etree]>=1.13\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "match run_env:\n",
    "    case \"local\":\n",
    "        proj_root = Path(\"..\").resolve()\n",
    "        data_dir = proj_root/\"data\"\n",
    "        inputs = data_dir/\"repack/arc-prize-2025.zip\"\n",
    "    case _:\n",
    "        inputs = Path(\"/kaggle/input/arc-prize-2025/\")\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def load_file(root, relative, mode=\"r\"):\n",
    "    match root.suffix:\n",
    "        case \".zip\":\n",
    "            with zipfile.ZipFile(root, \"r\") as zfh:\n",
    "                fh = zfh.open(relative)\n",
    "                yield fh\n",
    "        case \"\":\n",
    "            with open(root/relative, mode) as fh:\n",
    "                yield fh\n",
    "        case _:\n",
    "            raise KeyError(f\"Uknown suffix {root.suffix!r}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_inputs(v,had_list=False):\n",
    "    match v:\n",
    "        case dict():\n",
    "            return SimpleNamespace(**{kk:parse_inputs(vv) for kk,vv in v.items()})\n",
    "        case list():\n",
    "            if not had_list:\n",
    "                return tuple(parse_inputs(vv,True) for vv in v)\n",
    "            else:\n",
    "                return np.array(v,dtype=\"i1\")\n",
    "        case _:\n",
    "            raise TypeError(f\"Unsupported type {type(v).__name__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to model files: /Users/yves/.cache/kagglehub/models/google/gemma-3/flax/gemma3-1b-it/1\n"
     ]
    }
   ],
   "source": [
    "gemma_variant = \"v3-1b-it\".split(\"-\")\n",
    "\n",
    "gemma_src_name = {\n",
    "    \"v3-270m\": \"gemma-3-270m\",\n",
    "    \"v3-1b\": \"gemma3-1b\",\n",
    "    \"v3-4b\": \"gemma3-4b\",\n",
    "}[\"-\".join(gemma_variant[:2])] + {\n",
    "    \"it\": \"-it\"\n",
    "}[gemma_variant[2]]\n",
    "\n",
    "gemma_src_version = 1\n",
    "\n",
    "if run_env == \"local\":\n",
    "        # Download latest version\n",
    "    gemma_dir = Path(kagglehub.model_download(f\"google/gemma-3/flax/{gemma_src_name}\"))\n",
    "    \n",
    "    print(\"Path to model files:\", gemma_dir)\n",
    "else:\n",
    "    gemma_dir = Path(f\"/kaggle/input/gemma-3/flax/{gemma_src_name}/{gemma_src_version}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gemma import gm\n",
    "\n",
    "if gemma_variant[1] == \"270m\" and not hasattr(gm.nn,\"Gemma3_270M\"):\n",
    "    from gemma.gm.nn import _transformer, _config\n",
    "\n",
    "    print(\"Patching Gemma 270M!\")\n",
    "    \n",
    "    _NUM_LAYERS_GEMMA3_270M = 18\n",
    "    \n",
    "    class Gemma3_270M(_transformer.Transformer):  # pylint: disable=invalid-name\n",
    "        \"\"\"Gemma3 transformer architecture.\"\"\"\n",
    "    \n",
    "        config: _config.TransformerConfig = _config.TransformerConfig(\n",
    "            final_logit_softcap=None,\n",
    "            num_embed=262144,\n",
    "            embed_dim=640,  # modifiued from 1b\n",
    "            hidden_dim=2048,  # modified from 1b\n",
    "            num_heads=4,\n",
    "            head_dim=256,\n",
    "            num_kv_heads=1,\n",
    "            use_post_attn_norm=True,\n",
    "            use_post_ffw_norm=True,\n",
    "            use_qk_norm=True,\n",
    "            attention_types=_config.make_attention_layers_types(\n",
    "                gm.nn.config.GEMMA3_ATTENTION_PATTERN,\n",
    "                num_layers=_NUM_LAYERS_GEMMA3_270M,  # modified from 1b\n",
    "            ),\n",
    "            query_pre_attn_norm=_config.QueryPreAttentionNormalisation.BY_ONE_OVER_SQRT_HEAD_DIM,\n",
    "            attn_logits_soft_cap=None,\n",
    "            sliding_window_size=512,\n",
    "            transpose_gating_einsum=True,\n",
    "            local_base_frequency=10_000,\n",
    "            global_base_frequency=1_000_000,\n",
    "            vision_encoder=None,\n",
    "        )\n",
    "    \n",
    "        INFO = _transformer.ModelInfo(\n",
    "            tokenizer_version=3,\n",
    "            # default_ckpt=_paths.CheckpointPath.GEMMA3_1B_IT,\n",
    "        )\n",
    "    gm.nn.Gemma3_270M = Gemma3_270M\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asdfasd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43masdfasd\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'asdfasd' is not defined"
     ]
    }
   ],
   "source": [
    "asdfasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONVERBOSE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gemma.gm.nn._gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gemma.gm.nn._gemma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdfasdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = getattr(gm.nn,\"Gemma\"+\"_\".join(gemma_variant[:2])[1:].upper())()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = gm.ckpts.load_params(gemma_dir/gemma_dir.parent.name)\n",
    "tokenizer = gm.text.Gemma3Tokenizer(gemma_dir / \"tokenizer.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = gm.text.ChatSampler(\n",
    "    model=model,\n",
    "    params=params,\n",
    "    multi_turn=True,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "turn0 = chatbot.chat(\"Write a poem about the Kraken\")\n",
    "print(turn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11802066,
     "isSourceIdPinned": false,
     "sourceId": 91496,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 222398,
     "modelInstanceId": 237758,
     "sourceId": 277801,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 222398,
     "modelInstanceId": 237774,
     "sourceId": 277797,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
