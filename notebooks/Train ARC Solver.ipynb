{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ee69f0d-7d82-4e20-af16-ec5052013a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import lzma\n",
    "import os\n",
    "import dataclasses\n",
    "import itertools\n",
    "import functools\n",
    "from importlib import reload\n",
    "from pathlib import Path\n",
    "from types import MappingProxyType, SimpleNamespace\n",
    "\n",
    "import cbor2\n",
    "import attrs\n",
    "import tqdm.auto\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import nnx\n",
    "import optax\n",
    "import jaxtyping as jt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from arc25 import symmetry, tools as arc25_tools\n",
    "from arc25.symmetry import D4, transform_vector\n",
    "from arc25 import serialisation\n",
    "from arc25.dsl.types import Vector, Dir4\n",
    "from arc25.vision2.symrep import SymDecompBase, SplitSymDecomp, SymDecompDims, standard_rep, RepSpec\n",
    "from arc25.vision2.fields import FieldDims, CoordinateGrid\n",
    "from arc25.vision2.linear import SpaceSymmetricLinear, SpaceSymmetricTensor, SymmetryMappingSpec, SymDecompLinear\n",
    "from arc25.vision2 import fields, attention, encoder, transformer, mae, swiglu, arc_solver\n",
    "from arc25.training import saving, dataset, mae as mae_trainer, knn_eval, linear_probe, arc_solver as solver_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb29360-f3d7-4c0c-ba88-5665a46f757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"XLA_FLAGS\"]=\"--xla_force_host_platform_device_count=2\"\n",
    "os.environ[\"EPATH_USE_TF\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37284a09-443f-485a-a794-b50d8b83fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_root = Path(\"..\").resolve()\n",
    "data_root = proj_root / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bbf64f7-671a-40cd-a2e4-a0db869710ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518152\n"
     ]
    }
   ],
   "source": [
    "src_dataset = dataset.ImagesDataset.load_compressed_cbor(\n",
    "    data_root/\"repack/re-arc.cbor.xz\",\n",
    "    filter=lambda iop,ex:  iop.input.shape == iop.output.shape,\n",
    ")\n",
    "print(len(src_dataset.examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cce5211c-a5c4-482f-95e5-989244474b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ds, output_ds = [src_dataset.filtered(lambda img: img.example_type==k) for k in [\"input\",\"output\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acef2d93-6c79-439d-be0f-3f2435f0a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_order = tuple(sorted(src_dataset.challenges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e366fceb-b11e-497f-839b-d112dec8623a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arc25.training.dataset.ImagesDataset"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(src_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c4ef52b-7baf-4de0-8898-1cc3dcb7fd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_ds: {(30, 30): 69, (21, 30): 134, (21, 21): 87, (12, 12): 39, (12, 21): 107, (12, 30): 90}\n",
      "training_ds: {(30, 30): 35557, (21, 30): 69656, (21, 21): 39609, (12, 12): 21746, (12, 21): 48107, (12, 30): 43746}\n"
     ]
    }
   ],
   "source": [
    "reload(dataset)\n",
    "\n",
    "small_eval = True\n",
    "\n",
    "eval_split, train_split = output_ds.split_by_challenge(\n",
    "    np.random.default_rng(seed=42),\n",
    "    n_min=2 if small_eval else 100,\n",
    ")\n",
    "\n",
    "\n",
    "size_cuts = [12, 21, 30]\n",
    "#size_cuts = [8,12,16,24,30]\n",
    "#size_cuts = [30]\n",
    "\n",
    "eval_ds,training_ds = [dataset.BucketedDataset.make(\n",
    "    s,\n",
    "    set(itertools.product(size_cuts, size_cuts)) if s is not {} else [(30,30)],\n",
    "    challenges=challenge_order,\n",
    ") for s in [eval_split, train_split]]\n",
    "\n",
    "for k,v in dict(\n",
    "    eval_ds=eval_ds,\n",
    "    training_ds=training_ds,\n",
    ").items():\n",
    "    print(f\"{k}: { {kk:vv.n_examples for kk,vv in v.buckets.items()} }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e4876b2-2015-43f1-b6f4-7d58e96204b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(solver_trainer)\n",
    "\n",
    "config = solver_trainer.ArcSolverConfig(\n",
    "    seed = 42,\n",
    "    \n",
    "    batch_size = 16,\n",
    "    ref_batch = 16,\n",
    "    minibatch_size = 16,\n",
    "    base_cell_cost = 10, \n",
    "        \n",
    "    learning_rate = 1e-5,\n",
    "    max_num_epochs = 1,\n",
    "    max_num_ref_batches = 128,\n",
    "\n",
    "    warmup_steps = 64,\n",
    "    checkpoint_every_steps = 16,\n",
    "    \n",
    "    mode=\"flat\",\n",
    "    remat=True,\n",
    "    unroll=None,\n",
    "\n",
    "    eval_every_ref_batch = 2,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53b2f01d-f728-47f2-983f-0a323564e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_devices = jax.local_device_count()\n",
    "\n",
    "minibatch_size_fn = dataset.MinibatchSizeFunction(\n",
    "    reference_minibatch_size=config.minibatch_size,\n",
    "    reference_image_size=config.reference_image_size,\n",
    "    base_cost=config.base_cell_cost,\n",
    "    granularity=num_devices,  # Ensure divisibility for pmap\n",
    ")\n",
    "\n",
    "batch_spec = dataset.BatchSpec(\n",
    "    target_batch_weight=config.batch_size,\n",
    "    reference_image_size=config.reference_image_size,\n",
    "    # each image gets equal weight\n",
    "    area_weight_exponent=None,\n",
    ")\n",
    "\n",
    "collator = dataset.BucketedCollator.make(\n",
    "    dataset=training_ds,\n",
    "    batch_spec=batch_spec,\n",
    "    minibatch_size=minibatch_size_fn,\n",
    "    seed=42, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52574434-e275-4a6b-b746-a11bae47fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_src = dataset.OnDemandBucketDataset(\n",
    "    input_ds,\n",
    "    bucket_shapes = tuple(sorted(training_ds.buckets.keys(),key=lambda sh:(sh[0]*sh[1],abs(sh[0]-sh[1])))),\n",
    "    challenges = challenge_order,\n",
    "    weight_fun = lambda area: None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f1e664c-8d6e-45ae-8467-87c2842b0e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(arc_solver)\n",
    "\n",
    "model_config = {\n",
    "    k:v\n",
    "    for k,v in mae.configs[\"tiny\"].items()\n",
    "    if k not in {\"decoder_cell_infusion\"}\n",
    "}\n",
    "model_config.update(\n",
    "    num_program_tokens = 4,\n",
    "    num_latent_programs = len(challenge_order),\n",
    ")\n",
    "\n",
    "solver = arc_solver.ARCSolver(\n",
    "    **model_config,\n",
    "    dtype=jnp.float32,\n",
    "    rngs=nnx.Rngs(42),\n",
    ")\n",
    "width = solver.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a18a3a8-afaf-4cda-b339-86cd5bbc6923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading encoder from checkpoint: gs://576e2361-arc-agi-2/aiplatform-custom-training-2025-10-23-13:37:52.100/checkpoints/20251023-1137-vertex-ai-mae-tiny-4xL4/20251023-1137-vertex-ai-mae-tiny-4xL4-chkp-007568-final.msgpack.xz\n",
      "Encoder loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import etils.epath\n",
    "chkp_path = etils.epath.Path(\n",
    "    \"gs://576e2361-arc-agi-2/aiplatform-custom-training-2025-10-23-13:37:52.100/checkpoints/20251023-1137-vertex-ai-mae-tiny-4xL4/20251023-1137-vertex-ai-mae-tiny-4xL4-chkp-007568-final.msgpack.xz\"\n",
    ")\n",
    "\n",
    "print(f\"Loading encoder from checkpoint: {chkp_path}\")\n",
    "with chkp_path.open(\"rb\") as fh:\n",
    "    encoder_checkpoint = saving.load_model(fh)\n",
    "nnx.update(solver.encoder, encoder_checkpoint.state.model.encoder)\n",
    "print(\"Encoder loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cca168-a2b6-4b12-a3a1-d85825147786",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = solver_trainer.ArcSolverTrainer.make(\n",
    "    config=config,\n",
    "    model=solver,\n",
    "    collator=collator,\n",
    "    inputs_src=input_src,\n",
    "    num_devices = num_devices,\n",
    "    rngs = nnx.Rngs(42),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43fa53a-8971-4524-bc44-90c3765b92a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = trainer.run_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3994284f-d769-47f9-bdab-f4dfd17a667c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf19721-bbe8-4bb5-9075-5e5bb1c9e1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
