{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ee69f0d-7d82-4e20-af16-ec5052013a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import lzma\n",
    "import os\n",
    "import dataclasses\n",
    "import itertools\n",
    "import functools\n",
    "from importlib import reload\n",
    "from pathlib import Path\n",
    "from types import MappingProxyType, SimpleNamespace\n",
    "\n",
    "import cbor2\n",
    "import attrs\n",
    "import tqdm.auto\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import nnx\n",
    "import optax\n",
    "import jaxtyping as jt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from arc25 import symmetry, tools as arc25_tools\n",
    "from arc25.symmetry import D4, transform_vector\n",
    "from arc25 import serialisation\n",
    "from arc25.dsl.types import Vector, Dir4\n",
    "from arc25.vision2.symrep import SymDecompBase, SplitSymDecomp, SymDecompDims, standard_rep, RepSpec\n",
    "from arc25.vision2.fields import FieldDims, CoordinateGrid\n",
    "from arc25.vision2.linear import SpaceSymmetricLinear, SpaceSymmetricTensor, SymmetryMappingSpec, SymDecompLinear\n",
    "from arc25.vision2 import fields, attention, encoder, transformer, mae, swiglu, arc_solver\n",
    "from arc25.training import saving, dataset, mae as mae_trainer, knn_eval, linear_probe, arc_solver as solver_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb29360-f3d7-4c0c-ba88-5665a46f757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"XLA_FLAGS\"]=\"--xla_force_host_platform_device_count=2\"\n",
    "os.environ[\"EPATH_USE_TF\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37284a09-443f-485a-a794-b50d8b83fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_root = Path(\"..\").resolve()\n",
    "data_root = proj_root / \"data\"\n",
    "model_dir = data_root / \"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bbf64f7-671a-40cd-a2e4-a0db869710ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518152\n"
     ]
    }
   ],
   "source": [
    "src_dataset = dataset.ImagesDataset.load_compressed_cbor(\n",
    "    data_root/\"repack/re-arc.cbor.xz\",\n",
    "    filter=lambda iop,ex:  iop.input.shape == iop.output.shape,\n",
    ")\n",
    "challenge_order = tuple(sorted(src_dataset.challenges))\n",
    "print(len(src_dataset.examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c4ef52b-7baf-4de0-8898-1cc3dcb7fd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring 3 unpaired output images\n",
      "training_ds: {(30, 30): 35457, (21, 30): 69445, (21, 21): 39496, (12, 12): 21685, (12, 21): 47940, (12, 30): 43611}\n"
     ]
    }
   ],
   "source": [
    "reload(dataset)\n",
    "\n",
    "small_eval = True\n",
    "\n",
    "eval_split, train_split = src_dataset.split_by_challenge(\n",
    "    np.random.default_rng(seed=42),\n",
    "    n_min=10 if small_eval else 100,\n",
    ")\n",
    "\n",
    "input_ds, output_ds = train_split.split_input_output()\n",
    "\n",
    "size_cuts = [12, 21, 30]\n",
    "#size_cuts = [8,12,16,24,30]\n",
    "#size_cuts = [30]\n",
    "\n",
    "training_ds, = [dataset.BucketedDataset.make(\n",
    "    s,\n",
    "    set(itertools.product(size_cuts, size_cuts)) if s is not {} else [(30,30)],\n",
    "    challenges=challenge_order,\n",
    ") for s in [output_ds]]\n",
    "\n",
    "for k,v in dict(\n",
    "    training_ds=training_ds,\n",
    ").items():\n",
    "    print(f\"{k}: { {kk:vv.n_examples for kk,vv in v.buckets.items()} }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e4876b2-2015-43f1-b6f4-7d58e96204b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(solver_trainer)\n",
    "\n",
    "config = solver_trainer.ArcSolverConfig(\n",
    "    seed = 42,\n",
    "    \n",
    "    batch_size = 16,\n",
    "    ref_batch = 16,\n",
    "    minibatch_size = 16,\n",
    "    base_cell_cost = 10, \n",
    "        \n",
    "    learning_rate = 1e-5,\n",
    "    max_num_epochs = 1,\n",
    "    max_num_ref_batches = 128,\n",
    "\n",
    "    warmup_steps = 64,\n",
    "    checkpoint_every_steps = 16,\n",
    "    \n",
    "    mode=\"flat\",\n",
    "    remat=True,\n",
    "    unroll=None,\n",
    "\n",
    "    eval_every_ref_batch = 2,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53b2f01d-f728-47f2-983f-0a323564e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_devices = jax.local_device_count()\n",
    "\n",
    "minibatch_size_fn = dataset.MinibatchSizeFunction(\n",
    "    reference_minibatch_size=config.minibatch_size,\n",
    "    reference_image_size=config.reference_image_size,\n",
    "    base_cost=config.base_cell_cost,\n",
    "    granularity=num_devices,  # Ensure divisibility for pmap\n",
    ")\n",
    "\n",
    "batch_spec = dataset.BatchSpec(\n",
    "    target_batch_weight=config.batch_size,\n",
    "    reference_image_size=config.reference_image_size,\n",
    "    # each image gets equal weight\n",
    "    area_weight_exponent=None,\n",
    ")\n",
    "\n",
    "collator = dataset.BucketedCollator.make(\n",
    "    dataset=training_ds,\n",
    "    batch_spec=batch_spec,\n",
    "    minibatch_size=minibatch_size_fn,\n",
    "    seed=42, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52574434-e275-4a6b-b746-a11bae47fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_src = dataset.OnDemandBucketDataset(\n",
    "    input_ds,\n",
    "    bucket_shapes = tuple(sorted(training_ds.buckets.keys(),key=lambda sh:(sh[0]*sh[1],abs(sh[0]-sh[1])))),\n",
    "    challenges = challenge_order,\n",
    "    weight_fun = lambda area: None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f1e664c-8d6e-45ae-8467-87c2842b0e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(arc_solver)\n",
    "\n",
    "model_config = {\n",
    "    k:v\n",
    "    for k,v in mae.configs[\"tiny\"].items()\n",
    "    if k not in {\"decoder_cell_infusion\"}\n",
    "}\n",
    "model_config.update(\n",
    "    num_program_tokens = 4,\n",
    "    num_latent_programs = len(challenge_order),\n",
    ")\n",
    "\n",
    "solver = arc_solver.ARCSolver(\n",
    "    **model_config,\n",
    "    dtype=jnp.float32,\n",
    "    rngs=nnx.Rngs(42),\n",
    ")\n",
    "width = solver.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a18a3a8-afaf-4cda-b339-86cd5bbc6923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading encoder from checkpoint: /Users/yves/git-private/arc-2025/data/models/20251023-1137-vertex-ai-mae-tiny-4xL4-chkp-006912.msgpack.xz\n",
      "Encoder loaded successfully\n"
     ]
    }
   ],
   "source": [
    "chkp_path = model_dir / \"20251023-1137-vertex-ai-mae-tiny-4xL4-chkp-006912.msgpack.xz\"\n",
    "print(f\"Loading encoder from checkpoint: {chkp_path}\")\n",
    "encoder_checkpoint = saving.load_model(chkp_path)\n",
    "nnx.update(solver.encoder, encoder_checkpoint.state.model.encoder)\n",
    "print(\"Encoder loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1cca168-a2b6-4b12-a3a1-d85825147786",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = solver_trainer.ArcSolverTrainer.make(\n",
    "    config=config,\n",
    "    model=solver,\n",
    "    collator=collator,\n",
    "    inputs_src=input_src,\n",
    "    eval_dataset = eval_split,\n",
    "    num_devices = num_devices,\n",
    "    rngs = nnx.Rngs(42),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f97b1764-784f-4fb9-a41b-32e53402be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.with_progress_bars = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a43fa53a-8971-4524-bc44-90c3765b92a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ArcSolverTrainer ---\n",
      "Run: 20251026-1016-ArcSolverTrainer\n",
      "Devices: 2 Ã— cpu\n",
      "Training batch data weight: 16 (1 optimizer step)\n",
      "Reference step data weight: 16 (~1.00 optimizer steps)\n",
      "Total steps: 128\n",
      "Evaluation: every 2 reference steps\n",
      "----------------------------\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1301b3a98114762b9ef43c3a6267d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing _compute_grads for shape dict(cell_weight=(4,21,21), input_sizes=(4,2), inputs=(4,21,21), latent_program_idx=(4), output_masks=(4,21,21), outputs=(4,21,21)) (kw=dict(mode='flat', remat=True, unroll=None))\n",
      "Tracing _compute_grads for shape dict(cell_weight=(5,12,30), input_sizes=(5,2), inputs=(5,12,30), latent_program_idx=(5), output_masks=(5,12,30), outputs=(5,12,30)) (kw=dict(mode='flat', remat=True, unroll=None))\n",
      "Tracing _apply_update\n",
      "Tracing _compute_grads for shape dict(cell_weight=(5,12,30), input_sizes=(5,2), inputs=(5,12,30), latent_program_idx=(5), output_masks=(5,12,30), outputs=(5,12,30)) (kw=dict(mode='flat', remat=True, unroll=None))\n",
      "Tracing _compute_grads for shape dict(cell_weight=(2,30,30), input_sizes=(2,2), inputs=(2,30,30), latent_program_idx=(2), output_masks=(2,30,30), outputs=(2,30,30)) (kw=dict(mode='flat', remat=True, unroll=None))\n",
      "Tracing _apply_update\n",
      "Tracing _compute_grads for shape dict(cell_weight=(4,21,21), input_sizes=(4,2), inputs=(4,21,21), latent_program_idx=(4), output_masks=(4,21,21), outputs=(4,21,21)) (kw=dict(mode='flat', remat=True, unroll=None))\n",
      "\n",
      "[Step 2] Preparing input embeddings for evaluation...\n",
      "WARNING: Ignoring 3 unpaired input images\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba21f8c2c76540e3aab7b9050f6e7bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing _embed_inputs for shape dict(input_sizes=(2,48,2), inputs=(2,48,12,12)) (kw=dict(mode='flat', remat=True, unroll=None, deterministic=True))\n",
      "Tracing _embed_inputs for shape dict(input_sizes=(2,9,2), inputs=(2,9,12,21)) (kw=dict(mode='flat', remat=True, unroll=None, deterministic=True))\n",
      "Tracing _embed_inputs for shape dict(input_sizes=(2,128,2), inputs=(2,128,12,21)) (kw=dict(mode='flat', remat=True, unroll=None, deterministic=True))\n",
      "Tracing _embed_inputs for shape dict(input_sizes=(2,112,2), inputs=(2,112,12,30)) (kw=dict(mode='flat', remat=True, unroll=None, deterministic=True))\n",
      "Tracing _embed_inputs for shape dict(input_sizes=(2,100,2), inputs=(2,100,21,21)) (kw=dict(mode='flat', remat=True, unroll=None, deterministic=True))\n",
      "Tracing _embed_inputs for shape dict(input_sizes=(2,44,2), inputs=(2,44,21,30)) (kw=dict(mode='flat', remat=True, unroll=None, deterministic=True))\n",
      "Tracing _embed_inputs for shape dict(input_sizes=(2,128,2), inputs=(2,128,21,30)) (kw=dict(mode='flat', remat=True, unroll=None, deterministic=True))\n",
      "Tracing _embed_inputs for shape dict(input_sizes=(2,84,2), inputs=(2,84,30,30)) (kw=dict(mode='flat', remat=True, unroll=None, deterministic=True))\n",
      "Embedding inputs for evaluation completed in 167.0s\n",
      "\n",
      "[Step 2] Running evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ca111c30a644429a2d9d376af03b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing _evaluate for shape dict(cell_weight=(2,48,12,12), embeddings=(2, 48), latent_program_idx=(2,48), output_masks=(2,48,12,12), output_sizes=(2,48,2), outputs=(2,48,12,12)) (kw=dict(mode='flat', remat=True, unroll=None, deterministic=True))\n",
      "Tracing _evaluate for shape dict(cell_weight=(2,9,12,21), embeddings=(2, 9), latent_program_idx=(2,9), output_masks=(2,9,12,21), output_sizes=(2,9,2), outputs=(2,9,12,21)) (kw=dict(mode='flat', remat=True, unroll=None, deterministic=True))\n",
      "Tracing _evaluate for shape dict(cell_weight=(2,128,12,21), embeddings=(2, 128), latent_program_idx=(2,128), output_masks=(2,128,12,21), output_sizes=(2,128,2), outputs=(2,128,12,21)) (kw=dict(mode='flat', remat=True, unroll=None, deterministic=True))\n",
      "Tracing _evaluate for shape dict(cell_weight=(2,112,12,30), embeddings=(2, 112), latent_program_idx=(2,112), output_masks=(2,112,12,30), output_sizes=(2,112,2), outputs=(2,112,12,30)) (kw=dict(mode='flat', remat=True, unroll=None, deterministic=True))\n",
      "Tracing _evaluate for shape dict(cell_weight=(2,100,21,21), embeddings=(2, 100), latent_program_idx=(2,100), output_masks=(2,100,21,21), output_sizes=(2,100,2), outputs=(2,100,21,21)) (kw=dict(mode='flat', remat=True, unroll=None, deterministic=True))\n",
      "Tracing _evaluate for shape dict(cell_weight=(2,44,21,30), embeddings=(2, 44), latent_program_idx=(2,44), output_masks=(2,44,21,30), output_sizes=(2,44,2), outputs=(2,44,21,30)) (kw=dict(mode='flat', remat=True, unroll=None, deterministic=True))\n",
      "Tracing _evaluate for shape dict(cell_weight=(2,128,21,30), embeddings=(2, 128), latent_program_idx=(2,128), output_masks=(2,128,21,30), output_sizes=(2,128,2), outputs=(2,128,21,30)) (kw=dict(mode='flat', remat=True, unroll=None, deterministic=True))\n",
      "Tracing _evaluate for shape dict(cell_weight=(2,84,30,30), embeddings=(2, 84), latent_program_idx=(2,84), output_masks=(2,84,30,30), output_sizes=(2,84,2), outputs=(2,84,30,30)) (kw=dict(mode='flat', remat=True, unroll=None, deterministic=True))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yves/git-private/arc-2025/src/arc25/training/arc_solver.py:525: RuntimeWarning: invalid value encountered in divide\n",
      "  k: np.asarray(v) / np.maximum(1,eval_data.per_class_total_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation completed in 62.4s: cell_accuracy: 0.722 loss: 2.061 pair_accuracy: 0.003 class_accuracy_histogram: [261.000,0.000,2.000,0.000,0.000,1.000,0.000,0.000,0.000,0.000]\n",
      "Tracing _compute_grads for shape dict(cell_weight=(2,21,30), input_sizes=(2,2), inputs=(2,21,30), latent_program_idx=(2), output_masks=(2,21,30), outputs=(2,21,30)) (kw=dict(mode='flat', remat=True, unroll=None))\n",
      "\n",
      "[Step 4] Running evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a12e384ef124f189fbe840c003c093c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation completed in 44.8s: cell_accuracy: 0.722 loss: 2.058 pair_accuracy: 0.003 class_accuracy_histogram: [261.000,0.000,2.000,0.000,0.000,1.000,0.000,0.000,0.000,0.000]\n",
      "Tracing _compute_grads for shape dict(cell_weight=(12,12,12), input_sizes=(12,2), inputs=(12,12,12), latent_program_idx=(12), output_masks=(12,12,12), outputs=(12,12,12)) (kw=dict(mode='flat', remat=True, unroll=None))\n",
      "\n",
      "[Step 6] Running evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e0a624871a4d939a034371b05feaaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training interrupted by user\n",
      "\n",
      "--- Training Finished ---\n",
      "Total time: 544.9s\n",
      "Average throughput: -0.3 weight/s\n"
     ]
    }
   ],
   "source": [
    "stats = trainer.run_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebf19721-bbe8-4bb5-9075-5e5bb1c9e1a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1306 1306\n",
      "[0 5 0 5 5 0 5 5 4 5 5 5 5 0 5 5 5 5 0 5 0 0 5 5 5 0 5 5 0 5 0 5 5 5 5 0 5\n",
      " 0 0 5 5 5 5 5 5 0 5 0 0 5 5 5 5 5 5 0 0 5 5 5 5 5 5 5 0 5 0 5 5 5 5 0 5 5\n",
      " 5 5 5 5 0 5 5 5 0 5 5 5 5 0 5 5 0 5 5 5 5 0 5 5 5 0 5 5 0 0 5 0 0 0 0 5 0\n",
      " 5 5 0 0 0 5 5 5 5 0 5 0 0 5 5 5 5 5 0 5 5 5 0 0 5 5 0 5 5 5 0 5 0 5 0 5 5\n",
      " 0 5 5 0 0 5 5 5 5 5 0 5 4 5 5 0 5 5 5 5 5 0 5 0 5 0 5 5 0 0 5 0 5 5 0 0 0\n",
      " 0 5 0 0 5 5 5 5 0 0 5 5 5 5 5 0 5 5 5 0 5 0 5 0 0 0 5 0 5 5 0 5 0 5 5 0 5\n",
      " 0 5 5 5 0 5 5 5 0 5 0 4 0 0 5 0 0 5 5 0 5 0 5 5 0 5 0 5 5 5 0 5 5 5 0 5 0\n",
      " 5 5 5 0 0 5 5 5 5 0 5 0 5 5 0 0 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0 0 5 5 5 0 0\n",
      " 5 5 5 0 5 5 5 0 5 5 0 0 5 0 0 5 5 5 0 0 5 0 0 5 0 5 5 5 2 0 0 5 5 5 5 5 5\n",
      " 1 5 5 5 5 0 5 5 5 5 5 5 0 0 5 5 5 0 4 5 5 0 5 5 5 4 0 5 5 5 5 0 0 5 5 5 5\n",
      " 5 0 5 5 5 0 0 5 5 5 5 5 5 3 5 0 5 0 5 5 0 5 0 0 0 0 5 0 0 0]\n",
      "1306\n"
     ]
    }
   ],
   "source": [
    "cache = trainer._eval_data_cache\n",
    "print(cache.total_weight, cache.per_class_total_weight.sum())\n",
    "print(cache.per_class_total_weight)\n",
    "print(sum(w.sum() if (w:=mb.get(\"weight\")) is not None else mb[\"latent_program_idx\"].size for mb in cache.minibatches))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62740b3-8c98-4e15-a237-5b51f411f15e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
