{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e92cc294-fc57-4ca6-a250-317eeeba70b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import lzma\n",
    "import os\n",
    "from pathlib import Path\n",
    "from types import MappingProxyType, SimpleNamespace\n",
    "\n",
    "import cbor2\n",
    "import attrs\n",
    "import tqdm.auto\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import nnx\n",
    "import optax\n",
    "import jaxtyping as jt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from arc25.symmetry import SymOp, transform_vector\n",
    "from arc25 import serialisation\n",
    "from arc25.dsl.types import Vector, Dir4\n",
    "from arc25.vision.symrep import SymRep, SymDecomp, SymDecompDims, standard_rep\n",
    "from arc25.vision.linear import SymmetricLinear\n",
    "from arc25.vision.rope import QKV, attention_RoPE_with_global\n",
    "from arc25.vision.fields import Field, FieldDims\n",
    "from arc25.vision.attention import FieldAttention\n",
    "from arc25.vision.classification import ARCClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62411ecc-c33b-4af9-b2b6-71b6674fd2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"XLA_FLAGS\"]=\"--xla_force_host_platform_device_count=8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cc87dae-dc9a-4644-83fa-362591a0f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_root = Path(\"..\").resolve()\n",
    "data_root = proj_root / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88c231a9-b644-4e2c-8b58-0390f28bb7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with lzma.LZMAFile(data_root/\"re-arc.cbor.xz\",\"rb\") as fh:\n",
    "    src_data = serialisation.deserialise(cbor2.load(fh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d849b25-dad7-461b-a0e4-97af2114f58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "850658f95a734c1286a5cdb943044096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 258 out of 800000 due to out-of-range shape\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>shape</th>\n",
       "      <th>size</th>\n",
       "      <th>grouping_shape</th>\n",
       "      <th>challenge</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[7, 7, 7, 7, 6, 7, 7, 7, 7], [7, 7, 7, 7, 7, ...</td>\n",
       "      <td>(6, 9)</td>\n",
       "      <td>54</td>\n",
       "      <td>(8, 16)</td>\n",
       "      <td>a85d4709</td>\n",
       "      <td>input</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[4, 4, 4, 4, 4, 4, 4, 4, 4], [3, 3, 3, 3, 3, ...</td>\n",
       "      <td>(6, 9)</td>\n",
       "      <td>54</td>\n",
       "      <td>(8, 16)</td>\n",
       "      <td>a85d4709</td>\n",
       "      <td>output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6], [6, 6, ...</td>\n",
       "      <td>(15, 12)</td>\n",
       "      <td>180</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>a85d4709</td>\n",
       "      <td>input</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3, 3, ...</td>\n",
       "      <td>(15, 12)</td>\n",
       "      <td>180</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>a85d4709</td>\n",
       "      <td>output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,...</td>\n",
       "      <td>(2, 24)</td>\n",
       "      <td>48</td>\n",
       "      <td>(8, 24)</td>\n",
       "      <td>a85d4709</td>\n",
       "      <td>input</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image     shape  size  \\\n",
       "0  [[7, 7, 7, 7, 6, 7, 7, 7, 7], [7, 7, 7, 7, 7, ...    (6, 9)    54   \n",
       "1  [[4, 4, 4, 4, 4, 4, 4, 4, 4], [3, 3, 3, 3, 3, ...    (6, 9)    54   \n",
       "2  [[6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6], [6, 6, ...  (15, 12)   180   \n",
       "3  [[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3, 3, ...  (15, 12)   180   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,...   (2, 24)    48   \n",
       "\n",
       "  grouping_shape challenge    type  \n",
       "0        (8, 16)  a85d4709   input  \n",
       "1        (8, 16)  a85d4709  output  \n",
       "2       (16, 16)  a85d4709   input  \n",
       "3       (16, 16)  a85d4709  output  \n",
       "4        (8, 24)  a85d4709   input  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = []\n",
    "size_cuts = np.r_[8,16,24,30]\n",
    "#size_cuts = np.r_[20,30]\n",
    "skipped = []\n",
    "for k,v in tqdm.auto.tqdm(src_data.items()):\n",
    "    for i,iop in enumerate(v):\n",
    "        for kk in [\"input\",\"output\"]:\n",
    "            vv = getattr(iop,kk)\n",
    "            if any(s>30 for s in vv.shape):\n",
    "                skipped.append(vv)\n",
    "                continue\n",
    "            gs = tuple(int(size_cuts[np.searchsorted(size_cuts,s)]) for s in vv.shape)\n",
    "            dataset.append(dict(\n",
    "                image = vv._data,\n",
    "                shape = vv.shape,\n",
    "                size = int(np.prod(vv.shape)),\n",
    "                grouping_shape = gs,\n",
    "                challenge = k,\n",
    "                type = kk,\n",
    "            ))\n",
    "print(f\"Skipped {len(skipped)} out of {len(skipped)+len(dataset)} due to out-of-range shape\")\n",
    "datasrc = pd.DataFrame(dataset)\n",
    "datasrc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f8caa81-c37b-4578-a2ad-20eccd1d2b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group (8, 8)   has  92827 with an average utilisation of 31 %, wasting 4117.9k cells\n",
      "Group (8, 16)  has  37446 with an average utilisation of 53 %, wasting 2269.0k cells\n",
      "Group (8, 24)  has  27492 with an average utilisation of 61 %, wasting 2076.1k cells\n",
      "Group (8, 30)  has  17736 with an average utilisation of 65 %, wasting 1495.0k cells\n",
      "Group (16, 8)  has  36507 with an average utilisation of 53 %, wasting 2207.4k cells\n",
      "Group (16, 16) has  85430 with an average utilisation of 62 %, wasting 8356.8k cells\n",
      "Group (16, 24) has  68870 with an average utilisation of 68 %, wasting 8495.4k cells\n",
      "Group (16, 30) has  46297 with an average utilisation of 72 %, wasting 6172.2k cells\n",
      "Group (24, 8)  has  26534 with an average utilisation of 62 %, wasting 1951.6k cells\n",
      "Group (24, 16) has  69817 with an average utilisation of 68 %, wasting 8618.7k cells\n",
      "Group (24, 24) has  83898 with an average utilisation of 73 %, wasting 12947.7k cells\n",
      "Group (24, 30) has  51217 with an average utilisation of 78 %, wasting 8178.9k cells\n",
      "Group (30, 8)  has  17327 with an average utilisation of 66 %, wasting 1405.7k cells\n",
      "Group (30, 16) has  46049 with an average utilisation of 72 %, wasting 6109.3k cells\n",
      "Group (30, 24) has  50982 with an average utilisation of 78 %, wasting 8163.9k cells\n",
      "Group (30, 30) has  41313 with an average utilisation of 83 %, wasting 6445.5k cells\n",
      "Total waste: 89.0M cells vs 223.7M useful cells\n",
      "Maximum batch size / minimum group size: 17327\n"
     ]
    }
   ],
   "source": [
    "total_waste = 0\n",
    "total_cells = 0\n",
    "min_grp = 1000000\n",
    "for gs,grp in datasrc.groupby(\"grouping_shape\"):\n",
    "    s = gs[0]*gs[1]*grp.shape[0]\n",
    "    n = grp[\"size\"].sum()\n",
    "    util = n/s\n",
    "    waste = s-n\n",
    "    total_waste += waste\n",
    "    total_cells += n\n",
    "    min_grp = min(min_grp, grp.shape[0])\n",
    "    print(f\"Group {str(gs):8s} has {grp.shape[0]:6} with an average utilisation of {util*100:.0f} %, wasting {waste*1e-3:.1f}k cells\")\n",
    "print(f\"Total waste: {total_waste*1e-6:.1f}M cells vs {total_cells*1e-6:.1f}M useful cells\")\n",
    "print(f\"Maximum batch size / minimum group size: {min_grp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5953f000-c97a-4105-a73f-45d82ae9bf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CategoricalIndex(['007bbfb7', '00d62c1b', '017c7c7b', '025d127b', '045e512c',\n",
       "                   '0520fde7', '05269061', '05f2a901', '06df4c85', '08ed6ac7',\n",
       "                   ...\n",
       "                   'f8b3ba0a', 'f8c80d96', 'f8ff0b80', 'f9012d9b', 'fafffa47',\n",
       "                   'fcb5c309', 'fcc82909', 'feca6190', 'ff28f65a', 'ff805c23'],\n",
       "                  categories=['007bbfb7', '00d62c1b', '017c7c7b', '025d127b', ..., 'fcc82909', 'feca6190', 'ff28f65a', 'ff805c23'], ordered=False, dtype='category', length=400),\n",
       " CategoricalIndex(['input', 'output'], categories=['input', 'output'], ordered=False, dtype='category'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xarray as xa\n",
    "\n",
    "challenge_index = pd.CategoricalIndex(sorted(datasrc.challenge.unique()))\n",
    "itype_index = pd.CategoricalIndex(sorted(datasrc.type.unique()))\n",
    "challenge_index, itype_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59d45510-d366-4989-843e-73bc629dcbe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(\n",
       "    --jp-content-font-color0,\n",
       "    var(--pst-color-text-base rgba(0, 0, 0, 1))\n",
       "  );\n",
       "  --xr-font-color2: var(\n",
       "    --jp-content-font-color2,\n",
       "    var(--pst-color-text-base, rgba(0, 0, 0, 0.54))\n",
       "  );\n",
       "  --xr-font-color3: var(\n",
       "    --jp-content-font-color3,\n",
       "    var(--pst-color-text-base, rgba(0, 0, 0, 0.38))\n",
       "  );\n",
       "  --xr-border-color: var(\n",
       "    --jp-border-color2,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 10))\n",
       "  );\n",
       "  --xr-disabled-color: var(\n",
       "    --jp-layout-color3,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 40))\n",
       "  );\n",
       "  --xr-background-color: var(\n",
       "    --jp-layout-color0,\n",
       "    var(--pst-color-on-background, white)\n",
       "  );\n",
       "  --xr-background-color-row-even: var(\n",
       "    --jp-layout-color1,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 5))\n",
       "  );\n",
       "  --xr-background-color-row-odd: var(\n",
       "    --jp-layout-color2,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 15))\n",
       "  );\n",
       "}\n",
       "\n",
       "html[theme=\"dark\"],\n",
       "html[data-theme=\"dark\"],\n",
       "body[data-theme=\"dark\"],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: var(\n",
       "    --jp-content-font-color0,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 1))\n",
       "  );\n",
       "  --xr-font-color2: var(\n",
       "    --jp-content-font-color2,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 0.54))\n",
       "  );\n",
       "  --xr-font-color3: var(\n",
       "    --jp-content-font-color3,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 0.38))\n",
       "  );\n",
       "  --xr-border-color: var(\n",
       "    --jp-border-color2,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 10))\n",
       "  );\n",
       "  --xr-disabled-color: var(\n",
       "    --jp-layout-color3,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 40))\n",
       "  );\n",
       "  --xr-background-color: var(\n",
       "    --jp-layout-color0,\n",
       "    var(--pst-color-on-background, #111111)\n",
       "  );\n",
       "  --xr-background-color-row-even: var(\n",
       "    --jp-layout-color1,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 5))\n",
       "  );\n",
       "  --xr-background-color-row-odd: var(\n",
       "    --jp-layout-color2,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 15))\n",
       "  );\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 0 20px 0 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: inline-block;\n",
       "  opacity: 0;\n",
       "  height: 0;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "  border: 2px solid transparent !important;\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:focus + label {\n",
       "  border: 2px solid var(--xr-font-color0) !important;\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: \"►\";\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: \"▼\";\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: \"(\";\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: \")\";\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: \",\";\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  border-color: var(--xr-background-color-row-odd);\n",
       "  margin-bottom: 0;\n",
       "  padding-top: 2px;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "  border-color: var(--xr-background-color-row-even);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  border-top: 2px dotted var(--xr-background-color);\n",
       "  padding-bottom: 20px !important;\n",
       "  padding-top: 10px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in + label,\n",
       ".xr-var-data-in + label,\n",
       ".xr-index-data-in + label {\n",
       "  padding: 0 1px;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-data > pre,\n",
       ".xr-index-data > pre,\n",
       ".xr-var-data > table > tbody > tr {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked + label > .xr-icon-file-text2,\n",
       ".xr-var-data-in:checked + label > .xr-icon-database,\n",
       ".xr-index-data-in:checked + label > .xr-icon-database {\n",
       "  color: var(--xr-font-color0);\n",
       "  filter: drop-shadow(1px 1px 5px var(--xr-font-color2));\n",
       "  stroke-width: 0.8px;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 39MB\n",
       "Dimensions:     (idx: 41313, row: 30, col: 30, dim: 2)\n",
       "Coordinates:\n",
       "  * dim         (dim) object 16B &#x27;row&#x27; &#x27;col&#x27;\n",
       "Dimensions without coordinates: idx, row, col\n",
       "Data variables:\n",
       "    images      (idx, row, col) int8 37MB 6 6 6 6 6 6 6 6 6 ... 0 0 0 0 0 0 0 0\n",
       "    sizes       (idx, dim) int64 661kB 29 30 29 30 28 27 ... 29 26 25 28 25 28\n",
       "    challenges  (idx) int64 331kB 261 261 261 261 261 ... 233 233 233 233 233\n",
       "    itype       (idx) int64 331kB 0 1 0 1 0 1 0 1 0 1 0 ... 0 1 0 1 0 1 0 1 0 1</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-19b8212b-bae8-45a4-994e-9797b60dccd5' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-19b8212b-bae8-45a4-994e-9797b60dccd5' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span>idx</span>: 41313</li><li><span>row</span>: 30</li><li><span>col</span>: 30</li><li><span class='xr-has-index'>dim</span>: 2</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-19390b9e-dd14-4b41-ade7-328c08c7a940' class='xr-section-summary-in' type='checkbox'  checked><label for='section-19390b9e-dd14-4b41-ade7-328c08c7a940' class='xr-section-summary' >Coordinates: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>dim</span></div><div class='xr-var-dims'>(dim)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>&#x27;row&#x27; &#x27;col&#x27;</div><input id='attrs-068e37d4-ef04-412e-9d72-c72aafdb662c' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-068e37d4-ef04-412e-9d72-c72aafdb662c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ac50d85a-2852-4135-bb79-a95672eabfcb' class='xr-var-data-in' type='checkbox'><label for='data-ac50d85a-2852-4135-bb79-a95672eabfcb' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;row&#x27;, &#x27;col&#x27;], dtype=object)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-113d1c9b-6d9a-4289-887c-3b2189c07969' class='xr-section-summary-in' type='checkbox'  checked><label for='section-113d1c9b-6d9a-4289-887c-3b2189c07969' class='xr-section-summary' >Data variables: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>images</span></div><div class='xr-var-dims'>(idx, row, col)</div><div class='xr-var-dtype'>int8</div><div class='xr-var-preview xr-preview'>6 6 6 6 6 6 6 6 ... 0 0 0 0 0 0 0 0</div><input id='attrs-d5eb7c4c-9ddd-46a6-9225-58b1e17c5660' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-d5eb7c4c-9ddd-46a6-9225-58b1e17c5660' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-63f84c31-1023-4fee-abe8-96a31996f433' class='xr-var-data-in' type='checkbox'><label for='data-63f84c31-1023-4fee-abe8-96a31996f433' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[[6, 6, 6, ..., 6, 6, 6],\n",
       "        [6, 6, 6, ..., 6, 6, 6],\n",
       "        [6, 6, 6, ..., 6, 6, 6],\n",
       "        ...,\n",
       "        [6, 6, 6, ..., 6, 9, 6],\n",
       "        [6, 6, 6, ..., 6, 6, 6],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[3, 3, 3, ..., 3, 3, 3],\n",
       "        [4, 4, 4, ..., 4, 4, 4],\n",
       "        [4, 4, 4, ..., 4, 4, 4],\n",
       "        ...,\n",
       "        [3, 3, 3, ..., 3, 3, 3],\n",
       "        [2, 2, 2, ..., 2, 2, 2],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[8, 8, 8, ..., 0, 0, 0],\n",
       "        [8, 8, 8, ..., 0, 0, 0],\n",
       "        [8, 8, 8, ..., 0, 0, 0],\n",
       "        ...,\n",
       "...\n",
       "        ...,\n",
       "        [5, 5, 5, ..., 0, 0, 0],\n",
       "        [5, 5, 5, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[2, 2, 2, ..., 2, 0, 0],\n",
       "        [2, 2, 2, ..., 2, 0, 0],\n",
       "        [2, 2, 2, ..., 2, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[2, 2, 2, ..., 2, 0, 0],\n",
       "        [2, 2, 2, ..., 2, 0, 0],\n",
       "        [2, 2, 2, ..., 2, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], shape=(41313, 30, 30), dtype=int8)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>sizes</span></div><div class='xr-var-dims'>(idx, dim)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>29 30 29 30 28 ... 26 25 28 25 28</div><input id='attrs-c42f044e-617b-46bd-9f26-a90693bbb7da' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-c42f044e-617b-46bd-9f26-a90693bbb7da' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-7e967e8f-91b2-4e9a-80ba-82ddf6f7ab6a' class='xr-var-data-in' type='checkbox'><label for='data-7e967e8f-91b2-4e9a-80ba-82ddf6f7ab6a' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[29, 30],\n",
       "       [29, 30],\n",
       "       [28, 27],\n",
       "       ...,\n",
       "       [29, 26],\n",
       "       [25, 28],\n",
       "       [25, 28]], shape=(41313, 2))</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>challenges</span></div><div class='xr-var-dims'>(idx)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>261 261 261 261 ... 233 233 233 233</div><input id='attrs-5bb44942-6529-424c-98c6-06d7fef6421d' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-5bb44942-6529-424c-98c6-06d7fef6421d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-dd22eb4f-badd-4da8-84ca-128f364fdf51' class='xr-var-data-in' type='checkbox'><label for='data-dd22eb4f-badd-4da8-84ca-128f364fdf51' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([261, 261, 261, ..., 233, 233, 233], shape=(41313,))</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>itype</span></div><div class='xr-var-dims'>(idx)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0 1 0 1 0 1 0 1 ... 0 1 0 1 0 1 0 1</div><input id='attrs-2e75396a-92fe-496c-aef6-ea4fe87b01c3' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-2e75396a-92fe-496c-aef6-ea4fe87b01c3' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-25d4ad2f-ace6-4097-b3de-ae0028356197' class='xr-var-data-in' type='checkbox'><label for='data-25d4ad2f-ace6-4097-b3de-ae0028356197' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([0, 1, 0, ..., 1, 0, 1], shape=(41313,))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-67b7c4dc-cceb-42bb-9fb2-eb11065f9971' class='xr-section-summary-in' type='checkbox'  ><label for='section-67b7c4dc-cceb-42bb-9fb2-eb11065f9971' class='xr-section-summary' >Indexes: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>dim</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-3d461b47-164a-436f-956c-2b073b146d2f' class='xr-index-data-in' type='checkbox'/><label for='index-3d461b47-164a-436f-956c-2b073b146d2f' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;row&#x27;, &#x27;col&#x27;], dtype=&#x27;object&#x27;, name=&#x27;dim&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-b42468ca-4dfe-4b23-bc4d-c7e9c83a2b9f' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-b42468ca-4dfe-4b23-bc4d-c7e9c83a2b9f' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset> Size: 39MB\n",
       "Dimensions:     (idx: 41313, row: 30, col: 30, dim: 2)\n",
       "Coordinates:\n",
       "  * dim         (dim) object 16B 'row' 'col'\n",
       "Dimensions without coordinates: idx, row, col\n",
       "Data variables:\n",
       "    images      (idx, row, col) int8 37MB 6 6 6 6 6 6 6 6 6 ... 0 0 0 0 0 0 0 0\n",
       "    sizes       (idx, dim) int64 661kB 29 30 29 30 28 27 ... 29 26 25 28 25 28\n",
       "    challenges  (idx) int64 331kB 261 261 261 261 261 ... 233 233 233 233 233\n",
       "    itype       (idx) int64 331kB 0 1 0 1 0 1 0 1 0 1 0 ... 0 1 0 1 0 1 0 1 0 1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_data = {}\n",
    "for gs,grp in datasrc.groupby(\"grouping_shape\"):\n",
    "    n = grp.shape[0]\n",
    "    images = np.zeros((n,)+gs,\"i1\")\n",
    "    sizes = np.zeros((n,2),int)\n",
    "    challenges = np.zeros((n,),int)\n",
    "    itype = np.zeros((n,),int)\n",
    "    for i,(_,row) in enumerate(grp.iterrows()):\n",
    "        h,w = row[\"shape\"]\n",
    "        images[i,:h,:w] = row.image\n",
    "        sizes[i,:] = h,w\n",
    "        challenges[i] = challenge_index.get_loc(row.challenge)\n",
    "        itype[i] = itype_index.get_loc(row.type)\n",
    "    data = xa.Dataset(\n",
    "        dict(\n",
    "            images = ((\"idx\",\"row\",\"col\"), images),\n",
    "            sizes = ((\"idx\",\"dim\"), sizes),\n",
    "            challenges = ((\"idx\",),challenges),\n",
    "            itype = ((\"idx\",),itype),\n",
    "        ),\n",
    "        coords = dict(\n",
    "            dim = pd.Index([\"row\",\"col\"]),\n",
    "        ),\n",
    "    )\n",
    "    padded_data[gs] = data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "441c05cc-d8ec-4bdb-a8de-3d2333b0eda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(batch_size: int, rngs:nnx.Rngs):\n",
    "    weights = {}\n",
    "    for gs,data in padded_data.items():\n",
    "        weights[gs] = data.idx.size\n",
    "    logits = np.log(np.array(list(weights.values())))\n",
    "    keys = tuple(weights.keys())\n",
    "    rng = rngs\n",
    "    warmup = 0\n",
    "    while True:\n",
    "        if warmup is None or warmup>=len(keys):\n",
    "            warmup = None\n",
    "            gs = keys[rng.categorical(logits)]\n",
    "        else:\n",
    "            gs = keys[warmup]\n",
    "            warmup += 1\n",
    "        data = padded_data[gs]\n",
    "        assert data.idx.size >= batch_size\n",
    "        i = set()\n",
    "        while len(i) < batch_size:\n",
    "            j = rng.randint((batch_size-len(i),),0,data.idx.size)\n",
    "            i.update(int(v) for v in j)\n",
    "        i = np.array(sorted(i))\n",
    "        images = data.images.to_numpy()[i]\n",
    "        sizes = data[\"sizes\"].to_numpy()[i]\n",
    "        labels = data.challenges.to_numpy()[i]\n",
    "        yield dict(\n",
    "            inputs = dict(image=images, size=sizes),\n",
    "            label = labels,\n",
    "        ), warmup is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1beebdf2-e4ab-4908-943a-21cc6826bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2820c741-633e-4a27-b768-8aca53432dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class ModelConfig:\n",
    "    num_classes: int = 1000\n",
    "    embed_dim: int = 256\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainConfig:\n",
    "    \"\"\"Configuration for the training script.\"\"\"\n",
    "    seed: int = 42\n",
    "    global_batch_size: int = 128  # across all devices\n",
    "    ref_batch: int = 1024 # all learning rates refer to this batch size\n",
    "    # Optimiser\n",
    "    learning_rate: float = 3e-4\n",
    "    warmup_steps: int = 500\n",
    "    betas: tuple[float, float] = (0.9, 0.999)\n",
    "    eps: float = 1e-8\n",
    "    weight_decay: float = 0.05\n",
    "    grad_clip_norm: float = 1.0\n",
    "    # Schedule    \n",
    "    # in units of ref_batch images!\n",
    "    num_train_steps: int = 1000\n",
    "    # in units of ref_batch images!\n",
    "    warmup_steps: int = 10\n",
    "    log_every_steps: int = 50\n",
    "\n",
    "    # TODO: EMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b9fef38-c371-43f1-a1c5-0b8850239c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.tree_util.register_dataclass\n",
    "@dataclass(frozen=True)\n",
    "class TrainState:\n",
    "    \"\"\"A frozen dataclass to hold the training state.\"\"\"\n",
    "    model_def: nnx.GraphDef = dataclasses.field(metadata=dict(static=True))\n",
    "    model_state: nnx.State\n",
    "    tx: optax.GradientTransformation = dataclasses.field(metadata=dict(static=True))\n",
    "    opt_state: optax.OptState\n",
    "    # ema_params: nnx.Params\n",
    "\n",
    "    @classmethod\n",
    "    def make(\n",
    "        cls,\n",
    "        model: nnx.Module,\n",
    "        config: TrainConfig,\n",
    "        *,\n",
    "        rngs: nnx.Rngs,\n",
    "    ) -> typing.Self:\n",
    "        \"\"\"Initializes the model, optimizer, and the combined training state.\"\"\"\n",
    "\n",
    "        step_scale = (config.global_batch_size / config.ref_batch)\n",
    "        # Create the learning rate schedule (warmup + cosine decay is standard for ViTs)\n",
    "        # with Linear LR scaling\n",
    "        lr = config.learning_rate * step_scale\n",
    "        zero_lr = lr * 0.001\n",
    "        lr_schedule = optax.warmup_cosine_decay_schedule(\n",
    "            init_value=zero_lr,\n",
    "            peak_value=config.learning_rate,\n",
    "            warmup_steps=int(round(config.warmup_steps/step_scale)),\n",
    "            decay_steps=int(round((config.num_train_steps - config.warmup_steps)/step_scale)),\n",
    "            end_value=zero_lr,\n",
    "        )\n",
    "    \n",
    "        # Create the AdamW optimizer with gradient clipping\n",
    "        tx = optax.chain(\n",
    "            optax.clip_by_global_norm(config.grad_clip_norm),\n",
    "            optax.adamw(learning_rate=lr_schedule, weight_decay=config.weight_decay)\n",
    "        )\n",
    "    \n",
    "        # Split the model into its static definition (GraphDef) and dynamic state (State)\n",
    "        model_def, model_state = nnx.split(model)\n",
    "        \n",
    "        # Initialize optimizer state from the model's parameters\n",
    "        opt_state = tx.init(model_state.filter(nnx.Param))\n",
    "        \n",
    "        return cls(\n",
    "            model_def=model_def,\n",
    "            model_state=model_state,\n",
    "            tx=tx,\n",
    "            opt_state=opt_state\n",
    "        )\n",
    "\n",
    "\n",
    "def train_step(state: TrainState, batch: dict[str, jax.Array]) -> tuple[TrainState, dict[str, jax.Array]]:\n",
    "    \"\"\"\n",
    "    Performs a single training step, including forward pass, loss, gradients,\n",
    "    and parameter updates. This function is designed to be pmapped.\n",
    "    \"\"\"\n",
    "    # Reconstruct the model from the graph definition and the current state\n",
    "    model = nnx.merge(state.model_def, state.model_state)\n",
    "    \n",
    "    def loss_fn(model) -> tuple[jax.Array, jax.Array]:\n",
    "        \"\"\"Calculates loss and accuracy.\"\"\"\n",
    "        inputs = batch[\"inputs\"]\n",
    "        image = inputs[\"image\"]\n",
    "        size = inputs[\"size\"]\n",
    "        logits = model(image,size)\n",
    "        print(f\"{image.shape=} {logits.shape=}\")\n",
    "        loss = optax.softmax_cross_entropy_with_integer_labels(\n",
    "            logits=logits, labels=batch[\"label\"],\n",
    "            #label_smoothing=cfg.label_smoothing,\n",
    "        ).mean()\n",
    "        accuracy = jnp.mean(jnp.argmax(logits, axis=-1) == batch[\"label\"])\n",
    "        return loss, accuracy\n",
    "\n",
    "    # Use nnx.grad with return_value=True to get gradients, loss, and accuracy\n",
    "    # in a single pass, avoiding re-computation.\n",
    "    grad_fn = nnx.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, accuracy), grads = grad_fn(model)\n",
    "\n",
    "    # === Multi-GPU Synchronization ===\n",
    "    # Average gradients and metrics across all devices.\n",
    "    # This is the core of data-parallel training.\n",
    "    grads = jax.lax.pmean(grads, axis_name='devices')\n",
    "    loss = jax.lax.pmean(loss, axis_name='devices')\n",
    "    accuracy = jax.lax.pmean(accuracy, axis_name='devices')\n",
    "    \n",
    "    # Update optimizer state and model parameters\n",
    "    updates, new_opt_state = state.tx.update(grads, state.opt_state, state.model_state.filter(nnx.Param))\n",
    "    \n",
    "    # Create the new model state by applying the updates\n",
    "    new_model_params = optax.apply_updates(state.model_state.filter(nnx.Param), updates)\n",
    "    # new_model_state = state.model_state.merge(new_model_params)\n",
    "    nnx.update(model, new_model_params)\n",
    "    _, new_model_state = nnx.split(model)\n",
    "\n",
    "    # Create a new, immutable TrainState object with the updated state\n",
    "    new_state = TrainState(\n",
    "        model_def=state.model_def,\n",
    "        model_state=new_model_state,\n",
    "        tx=state.tx,\n",
    "        opt_state=new_opt_state,\n",
    "    )\n",
    "    \n",
    "    metrics = dict(loss=loss, accuracy=accuracy)\n",
    "    return new_state, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7de7ffd-0929-4f3e-b4c7-909087fa4e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "def main(model, config: TrainConfig):\n",
    "    \"\"\"The main entry point for the training script.\"\"\"\n",
    "    # Detect available devices (GPUs/TPUs)\n",
    "    num_devices = jax.local_device_count()\n",
    "    is_multi_device = num_devices > 1\n",
    "\n",
    "    per_device_batch_size = config.global_batch_size // num_devices\n",
    "    config = dataclasses.replace(config, global_batch_size=per_device_batch_size*num_devices)\n",
    "\n",
    "    step_scale = (config.global_batch_size / config.ref_batch)\n",
    "    \n",
    "    print(f\"--- ARC ViT Pre-training ---\")\n",
    "    print(f\"Detected {num_devices} devices: {jax.devices()}\")\n",
    "    print(f\"Mode: {'Single-device' if not is_multi_device else 'Multi-device (DDP)'}\")\n",
    "    print(f\"Per-device batch size: {per_device_batch_size}\")\n",
    "    print(f\"Global batch size: {config.global_batch_size}\")\n",
    "    print(\"----------------------------\\n\")\n",
    "\n",
    "    # Setup PRNG key\n",
    "    rngs = nnx.Rngs(config.seed)\n",
    "\n",
    "    # 1. Setup Data Pipeline\n",
    "    # ...\n",
    "\n",
    "    # 2. Initialize Training State\n",
    "    state = TrainState.make(\n",
    "        model,\n",
    "        config,\n",
    "        rngs=rngs,\n",
    "    )\n",
    "\n",
    "    # 3. Parallelize the training step and state for multi-device training\n",
    "    # jax.pmap compiles the function for parallel execution across devices.\n",
    "    # The 'devices' axis_name is used for cross-device communication (e.g., pmean).\n",
    "    p_train_step = nnx.pmap(train_step, axis_name='devices')\n",
    "    \n",
    "    # Replicate the initial state across all devices.\n",
    "    state = jax.device_put_replicated(state, jax.local_devices())\n",
    "    \n",
    "    # 4. Start the training loop\n",
    "    print(\"Starting training...\")\n",
    "    start_time = time.monotonic()\n",
    "    start_imgs = 0\n",
    "    \n",
    "    # Get an iterator for the dataset\n",
    "    ds_iter = iter(make_dataset(config.global_batch_size, rngs=rngs))\n",
    "\n",
    "    try:\n",
    "        was_warmup = True\n",
    "        stats = {k:[] for k in [\"step\",\"refstep\",\"images\",\"loss\",\"accuracy\",\"images_per_sec\"]}\n",
    "        for step in (pbar := tqdm.auto.trange(int(round(config.num_train_steps/step_scale)))):\n",
    "            # Fetch the next batch of data\n",
    "            batch,is_warmup = next(ds_iter)\n",
    "            batch = jax.tree.map(lambda v:v.reshape(num_devices,-1,*v.shape[1:]),batch)\n",
    "            if was_warmup and not is_warmup:\n",
    "                was_warmup = False\n",
    "                start_time = time.monotonic()\n",
    "                start_imgs = step*config.global_batch_size  \n",
    "            \n",
    "            # Execute one parallel training step\n",
    "            state, metrics = p_train_step(state, batch)\n",
    "    \n",
    "            metrics_cpu = jax.device_get(jax.tree.map(lambda x: x[0], metrics))\n",
    "            elapsed_time = time.monotonic() - start_time\n",
    "            images_per_sec = (step+1)*config.global_batch_size / elapsed_time\n",
    "            for k,v in dict(\n",
    "                step=step,\n",
    "                refstep=step*step_scale,\n",
    "                images = step*config.global_batch_size,\n",
    "                images_per_sec=images_per_sec,\n",
    "                **metrics_cpu\n",
    "            ).items():\n",
    "                stats[k].append(v)\n",
    "            pbar.set_postfix(\n",
    "                loss=f\"{metrics_cpu['loss']:.4f}\",\n",
    "                accuracy=f\"{metrics_cpu['accuracy']:.4f}\",\n",
    "                imps=f\"{images_per_sec:.2f}\",\n",
    "            )\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    finally:\n",
    "        nnx.update(model, state.model_state)\n",
    "\n",
    "    print(\"\\n--- Training Finished ---\")\n",
    "    stats = {k:np.array(v) for k,v in stats.items()}\n",
    "    stats = pd.DataFrame(stats)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "847c36d2-3558-4cec-91b0-2beeec1703a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = FieldDims.make(\n",
    "    inv_fac = 4,\n",
    "    context = 64,\n",
    "    hdrs = 32,\n",
    "    cells = 32,\n",
    ")\n",
    "arc_cls = ARCClassifier(\n",
    "    hidden_size = dims,\n",
    "    mha_features = 256,\n",
    "    mlp_width_factor = 4,\n",
    "    num_heads = 4,\n",
    "    num_classes = 400,\n",
    "    num_layers = 12,\n",
    "    rngs = nnx.Rngs(0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb2cae-8adb-437a-ae5a-6eed6451f550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ARC ViT Pre-training ---\n",
      "Detected 8 devices: [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3), CpuDevice(id=4), CpuDevice(id=5), CpuDevice(id=6), CpuDevice(id=7)]\n",
      "Mode: Multi-device (DDP)\n",
      "Per-device batch size: 2048\n",
      "Global batch size: 16384\n",
      "----------------------------\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a50520e5c743bd8b58933adca1f4fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape=(2048, 8, 8) logits.shape=(2048, 400)\n"
     ]
    }
   ],
   "source": [
    "stats = main(arc_cls, TrainConfig(\n",
    "    global_batch_size = 16*1024,\n",
    "    num_train_steps = 500*400,\n",
    "    warmup_steps = 10*400,\n",
    "    learning_rate = 3e-5,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4fd383-a3ff-46ac-8965-c906a4d0f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,axes = plt.subplots(2,1,figsize=(8,8))\n",
    "ax = axes[0]\n",
    "ax.semilogy(stats.refstep, stats.loss)\n",
    "ax = axes[1]\n",
    "ax.plot(stats.refstep, stats.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9c830f-2a09-42d5-ab53-f95fc1d6ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TrainState.make(\n",
    "    arc_cls,\n",
    "    TrainConfig(),\n",
    "    rngs=nnx.Rngs(0),\n",
    ")\n",
    "state.tx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f80525-0e5b-4ae9-ae91-89a252682438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
